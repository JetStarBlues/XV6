---------------------------------------------------------------------------------------------
OS Intefaces
---------------------------------------------------------------------------------------------

System calls

	. fork   () ...................... Create a process
	. exit   () ...................... Terminate the current process
	. wait   () ...................... Wait for a child process to exit
	. kill   ( pid ) ................. Terminate process pid
	. getpid () ...................... Return the current process's pid
	. sbrk   ( n ) ................... Grow process's memory by n bytes

	. open   ( filename, flags ) ..... Open a file; the flags indicate read/write
	. read   ( fd, buf, n ) .......... Read n bytes from an open file into buf
	. write  ( fd, buf, n ) .......... Write n bytes to an open file
	. close  ( fd ) .................. Release open file fd
	. dup    ( fd ) .................. Duplicate fd
	. chdir  ( dirname ) ............. Change the current directory
	. mkdir  ( dirname ) ............. Create a new directory
	. mknod  ( name, major, minor ) .. Create a device file
	. fstat  ( fd ) .................. Return info about an open file
	. link   ( f1, f2 ) .............. Create another name (f2) for the file f1
	. unlink ( filename ) ............ Remove a file

	. exec   ( filename, *argv ) ..... Load a file and execute it
	. pipe   ( p ) ................... Create a pipe and return fd's in p

	. sleep  ( n ) ................... Sleep for n clock ticks


Process and memory

	. process consists of
		. user-space memory (instructions, data, stack)
		. per process state that is private to the kernel??
	. Xv6 can time-share processes?
		. transparently switches the available CPU among the set of
		  processes waiting to execute
	. When a process is not executing Xv6 saves its CPU registers,
	  restoring them when it next runs the process
	. The kernel associates a process identifier (PID) with each process.


	~~~ Fork, wait, exit ~~~

	. A process may create a new process using the _fork_ system call.
	. Fork creates a new 'child' process with exactly the same memory
	  contents as the 'parent'
	. Fork retuns in both the parent and the child??
		. in the parent, fork returns the child's pid
		. in the child, fork returns zero
	. For example:

		int pid = fork();

		if ( pid > 0 )
		{
			printf( "parent: child=%d\n", pid );

			pid = wait();

			printf( "child %d is done\n", pid );
		}
		else if ( pid == 0 )
		{
			printf( "child: exiting\n" );

			exit();
		}
		else
		{
			printf( "fork error\n" );
		}

		. The _exit_ system call causes the calling process to stop executing
		  and to release resources such as memory and open files
		. The _wait_ system call returns the pid of an exited child of the
		  current process?
		  If none of the caller's children has exited, wait waits for one
		  to do so...
		. The following statements might come out in either order depending on
		  whether the parent or child gets to their printf first:

		      parent: child=9000
		      child: exiting

		. After the child exits, the parent's wait returns causin the parent to print

		      parent: child 900 is done

		. Although the child initially has the same memory contents as the parent,
		  the parent and child are executing with different memory and registers.
		  Changing a variable in one does not affect the other.
		  For example, when the return value of 'wait' above is stored into 'pid'
		  in the parent, it remains unchanged in the child (still zero it started as)


	~~~ Exec ~~~

	. The _exec_ system call replaces the calling process's memory with a new
	  memory image loaded from a file stored in the file system...
	. This file must have a particular format which specifies:
		. which part of the file holds instructions
		. which part of the file holds data
		. which instruction to start
		. etc
	. Xv6 uses the ELF format
	. When exec succeeds, it *does not* return to the calling program.
	  Instead, the instructions loaded from the file start executing at the
	  entry point declared in the ELF header
	. Exec takes two arguments:
		. the name of the file containg the executable
		. an array of string arguments
	. For example:

		char *argv[ 3 ];

		argv[ 0 ] = "echo";
		argv[ 1 ] = "hello";
		argv[ 2 ] = 0;

		exec( "/bin/echo", argv );

		printf( "exec error\n" );

		. This fragment replaces the calling program with an instance of the
		  program /bin/echo running with an argument list [ "echo", "hello" ]
		. Most programs ignore the first argument, which is conventionally the name
		  of the program


	~~~ Shell and exec ~~~

	. The Xv6 shell uses the above fragment to run programs on behalf of users

		while ( getcmd( buf ... ) >= 0 )
		{
			...

			if ( fork() == 0 )
			{
				runcmd( parsecmd( buf ) );
			}

			wait();
		}

	. The main loop reads a line of input from the user with 'getcmd'
	. Then it calls 'fork', which creates a copy of the sheell process
	. The parent calls 'wait' while the child runs the command with exec
	. At some point, the program (ex echo) will call exit, which will
	  cause the parent to return from 'wait'


	~~~ Memory ~~~

	. Xv6 allocates most user-space memory implicitly:
		. fork allocates the memory required for the child's copy of
		  the parent's memory
		. exec allocates enough memory to hold the executable file
	. A process that needs more memory at run-time (perhaps for malloc??)
	  can call _sbrk( n )_ to grow its data memory by n bytes.
	  sbrk returns the location of the new memory


	~~~ Users ~~~

	. Xv6 does not provide a notion of users or of protecting one use
	  from another. All processes run as root.


IO and File descriptors

	. A file descriptor is a small integer representing a kernel-managed object
	  that a process may read from or write to
	. A process may obtain a file descriptor by:
		. opening a file, directory, or device
		. creating a pipe
		. duplicating an existing descriptor
	. The file descriptor interface abstracts away the differences between files,
	  pipes, and devices, making them all look like streams of bytes

	. Internally, the kernel uses the fd as an index into a per-process table,
	  such that every process has a private scope of fds starting at zero
	. By convention, a process,
		. reads from fd 0,               standard input,  stdin
		. writes output to fd 1,         standard output, stdout
		. writes error messages to fd 2, standard error,  stderr
	. The shell exploits this convention to impliment IO redirection and pipelines??
	. The shell ensures that it always has three file descriptors open...


	~~~ Read, write ~~~

	. The _read_ and _write_ system calls read bytes from and write bytes to
	  open files named by file descriptors

	. 'read( fd, buf, n)' reads at most n bytes from fd, copies them into buf,
	  and returns number of bytes read
	. Each fd that refers to a files has an offset associated with it??
	. read reads data from the current offset and then advances that offset
	  by the number of bytes read.
	  A subsequent read will return the bytes following the first read.
	. When there are no more bytes to be read, read returns zero, to signal
	  the end of the file

	. 'write( fd, buf, n)' writes n bytes from buf to the fd and returns
	  the number of bytes written
	  Fewer than n bytes are writen only when an error occurs.
	. Like read, write writes data at the current file offset and
	  advances it accordingly

	. The following fragment (which forms the essence of cat) copies
	  data from its stdin to its stdout. If an error occurs, it
	  writes a message to its stderror

		char buf[ 512 ];
		int n;

		for ( ;; )
		{
			n = read( 0, buf, sizeof buf );    // read stdin

			if ( n == 0 )
			{
				break;
			}

			if ( n < 0 )
			{
				fprintf( 2, "read error\n" );  // write stderr
				exit();
			}

			if ( write( 1, buf, n ) != n )     // write stdout
			{
				fprintf( 2, "write error\n" );
				exit();
			}
		}

		. In the snippet above, cat does not know whether it is reading
		  from / writing to a file, console, or a pipe.


	~~~ Close ~~~

	. _close_ releases a file descriptor, making it free for reuse by
	  a future open, pipe, or dup system call


	~~~ IO redirection ~~~

	. A newly allocated fd is always the *lowest numbered unused* descriptor
	  of the current process
	. fork copies the parent's fd table along with its memory, so that
	  the child starts with exactly the same files open as the parent
	. exec replaces the calling process's memory but preserves its file table
	. This behaviour allows the shell to implement IO redirection by
	  	1. forking,
	  	2. reopening chosen fds,
	  	3. and then executing the new program
	. Below is a simplified snippet of code, showing what the shell
	  runs for the command "cat < input.txt"

		char *argv[ 2 ];

		argv[ 0 ] = "cat";
		argv[ 1 ] = 0;

		if ( fork() == 0 )
		{
			close( 0 );                     // close stdout, fd0

			open( "input.txt", O_RDONLY );  // becomes new stdout, fd0

			exec( "cat", argv );
		}

		. After the child closes fd 0, 'open' is guaranteed to use
		  fd 0 for the newly opened "input.txt"

	. Although fork copies the fd table, each underlying file offset
	  is still shared between parent and child.
	. For example:

		if ( fork() == 0 )            // child
		{
			write( 1, "hello ", 6 );
			exit();
		}
		else                          // parent
		{
			wait();
			write( 1, "world\n", 6 );
		}

		. At the end of this fragment, the file attached to
		  fd 1 will contain "hello world\n"
		. The write in the parent (which thanks to wait, runs only
		  after the child is done), picks up where the child left off.
		. This behaviour helps produce sequential output from
		  sequencs of shell commands ex. "(echo hello; echo world) > output.txt"


	~~~ Dup ~~~

	. _dup_ duplicates an existing fd, returning a new one that refers
	  to the same underlying IO object.
	. Both fds share an offset, just as they would in the fds duplicated by fork
	. For example, as an alternate to the above snippet:

		fd = dup( 1 );

		write( 1, "hello", 6 );
		write( fd, "world\n", 6 );

	. dup allows shells to implement commands such as
	  
	  	"ls existing-file non-existing-file > tmp.txt 2>&1"

	  	. The "2>&1" tells ??
	      I.e. send stderror to where ever stdout is being redirected
	    . Both the name of the existing file and the error
	      message for the non-existing file will show up in file "tmp.txt"

	...

	. Two fds share an offset if they are derived from the same orignal fd
	  via fork or dup.
	  Otherwise, fds *do not share offsets* even if they result from open calls
	  for the same file.


Pipes

	. a pipe is a small kernel buffer exposed to processes as a pair
	  of file descriptors, one for reading and one for writing
	. pipes provide a way for processes to communicate

	. The following example runs the program wc (word count) with
	  stdin connected to the read end of a pipe

		int   p    [ 2 ];
		char *argv [ 2 ];

		argv[ 0 ] = "wc";
		argv[ 1 ] = 0;

		pipe( p );            // creates a new pipe and records its
		                      // read fd in p[0] and its write fd in p[1]

		// child
		if ( fork() == 0 )
		{
			close( 0 );       // close stdin

			dup( p[ 0 ] );    // stdin = p[ 0 ]  (pipe's read end)

			close( p[ 0 ] );  // close fd referring to pipe's read end
			close( p[ 1 ] );  // close fd referring to pipe's write end

			exec( "/bin/wc", argv );
		}

		// parent
		else
		{
			close( p[ 0 ] );                        // close fd referring to pipe's read end

			write( p [ 1 ], "hello world\n", 12 );  // write to pipe

			close( p[ 1 ] );                        // close fd referring to pipe's write end
		}

		. After the fork, both parent and hcild have file descriptors
		  referring to the created pipe
		. The child:
			. dups the read end of the pipe onto its fd 0 (stdin),
			. closes its copy of the pipe's file descriptors...
			  (as they are no longer needed?),
			. and execs wc
			. when wc reads from stdin, it reads from p[ 0 ]
		. The parent:
			. closes the read end of the pipe (not used...)
			. writes "hello world\n" to the write end of the pipe,
			. the closes it when done
		. If no data is available, a read on a pipe waits for either:
		  	. data to be written or,
		  	. all fds referring to the pipe's write end (p[1])
		  	  to be closed.
		  	  In this case, read returns 0, just as if the end of a data
		  	  file had been reached.
		. The fact that a pipe read blocks until it is impossible for
		  new data to arrive is one reason that it's important for the
		  child to close the write end of the pipe before executing wc above

	. The Xv6 shell implementes pipelines in a similar way to the
	  snippet above. For example, "grep fork sh.c | wc -l"

		pipe( p );  // connects left end to right end.
		            // left end writes to p[1]
		            // right end reads from p[0]

		// left end
		if ( fork() == 0 )
		{
			close( 1 );
			dup( p[ 1 ] );  // stdout = p[1]

			close( p[ 0 ] );
			close( p[ 1 ] );

			runcmd( pcmd->left );
		}

		// right end
		if ( fork() == 0 )
		{
			close( 0 );
			dup( p[ 0 ] );  // stdin = p[0]

			close( p[ 0 ] );
			close( p[ 1 ] );

			runcmd( pcmd->right );
		}

		close( p[ 0 ] );
		close( p[ 1 ] );

		wait();
		wait();

		. The child process:
			. creates a pipe to connect the left end of the pipeline
			  with the right end,
			. then calls fork and 'runcmd' for both the left and right
			  ends of the pipeline
			. and waits for both to finish

		. The right end of the pipeline may be a command that itself
		  includes a pipe (ex. "a | b | c"), which itself forks two new
		  child processes
		. Thus the shell may create a tree of processes. The leaves of
		  this tree are commands, and the nodes processes that wait
		  until the left and right children are complete

	. Pipes may not seem any more powerful than temporary files.
	  For example,

		echo hello world | wc

		echo hello world > temp.txt;  wc < temp.txt

	. However, they have at least four advantages over temporary
	  files in this situation:

		1. automatically clean themselves up.
		   With file redirection, the shell would have to be
		   careful to remove "temp.txt" when done
		2. can pass arbitrary long streams of data.
		   Whereas file redirection requires enough free space on
		   disk to store all the data.
		3. allow for parallel execution of pipeline stages.
		   Whereas the file approach requires the first program to
		   finish before the second starts ??
		4. if implementing inter-process communication, pipes'
		   *blocking* reads and writes are more efficient than the
		   non-blocking semantics of files.

	. If one application in a pipeline fails, the kernel generats
	  and end-of-file for the next process in the pipeline


File system

	. The Xv6 file system provides:
		. data files - uninterrupted byte arrays
		. directories - named references to data files and other directories
	. The directories form a tree, starting at a special directory
	  called 'root'
	. A path like "/a/b/c" refers to the file or directory named "c"
	  inside the directory named "b" inside the directory named "a"
	  inside the root directory "/"
	. Paths that don't begin with "/" are evaluated relative to the
	  calling process's current directory, which can be changed
	  with the _chdir_ system call
	. Both these code fragments open the same file:

		// Style 1
		chdir( "/a" );
		chdir( "b" );
		open( "c", O_RDONLY );

		// Style 2
		open( "/a/b/c", O_RDONLY );

		. The first style changes the process's current directory
		  to "/a/b"
		. The second style neither refers to nor changes the
		  process's current directory


	~~~ Creating a new file or directory ~~~

	. There are multiple system calls to create a new file or directory:
		. _mkdir_ creates a new directory
		. _open_ with the O_CREATE flag creates a new data file
		. _mknod_ creates a new device file
	. For example:

		mkdir( "/dir" );

		fd = open( "/dir/file", O_CREATE | O_WRONLY );
		close( fd );

		mknod( "/console", 1, 1 );


	~~~ Mknod ~~~

	. _mknod_ creates a file in the file system but the file has no contents.
	. Instead, the file's metadata marks it as a *device* file and records
	  the major and minor device numbers (the two arguments to mknod) which
	  uniquely identify a kernel device
	. When a process later opens the file, the kernel diverts read and write
	  system calls to the kernel device implementation instead of passing
	  the to the file system


	~~~ Fstat ~~~

	. _fstat_ retrieves information about the object a file descriptor
	  refers to.
	. It fills in a "struct stat" defined in stat.h as:

		#define T_DIR  1   // Directory
		#define T_FILE 2   // File
		#define T_DEV  3   // Device

		struct stat
		{
			short type;   // Type of file
			int   dev;    // File system's disk device
			uint  ino;    // Inode number
			short nlink;  // Number of links to file
			uint  size;   // Size of file in bytes
		};


	~~~ Link, unlink ~~~

	. A file's name is distinct from the file itself.
	  The same underlying file, called an *inode* can have multiple names
	  called *links*

	. _link_ system call creates another file system name referring to
	  the same inode as an existing file.
	. For example, this snippet creates a new file named both "a" and "b":

		open( "a", O_CREATE | O_WRONLY );
		link( "a", "b" );

	. Reading from or writing to "a" is the same as to "b"
	. Each inode is identified by a unique inode number.
	  It is possible to determine that "a" and "b" refer to the same
	  underlying contents by inspecting the result of _fstat_:
	  both will return same inode number and link count (in this case 2).

	. _unlink_ removes a name from the file system
	. The file's inode and the disk space holding its content are
	  only freed when:
		. the file's link count is zero,
		. and no file descriptors refer to it
	. For example:

		unlink( "a" );

		. Leaves the inode and dfile content accessible as "b"

	. A temporary inode that will be cleaned up when the process closes
	  fd or exits can be created as follows:

		fd = open( "/tmp/file.txt", O_CREATE | O_RDWR );
		unlink( "/tmp/file.txt" );

		. By removing link, the file's link count is now zero.
		. The only thing keeping it alive is the file descriptor refering to it


	~~~ ... ~~~

	. Shell commands for file system operations are implemented as
	  user-level programs such as 'mkdir', 'ln', 'rm' etc.
	  This allows anyone to extend the shell with new user commands
	  by just adding a new user-level program??
	. One exception is 'cd' which is built into the shell.
	  cd must change the current working directory of the shell itself.
	  If cd were run as a regular command, then the shell would fork a
	  child process, the child process would run cd, and cd would change
	  the child's working directory, not the shell's.


Real world

	. The Unix system call interfaces has been standardized through the
	  Portable Operating System Interface (POSIX)
	. Xv6 is not POSIX compliant:
		. it misses some system calls e.g. lseek
		. partially implements system calls it does have
		. many more
	. Xv6 is a monolithic kernel
	. Xv6 runs on x86 processors (Intel 80386 or later),
	  and much of it's low-level functionality (ex. process implementation)
	  is x86-specific


---------------------------------------------------------------------------------------------
OS organization
---------------------------------------------------------------------------------------------

Intro

	. A key requirement for an OS is to support several activities at once
	. For example using fork, a process can start a new process.
	. The OS must fulfill three requirements:
		. multiplexing
			. The OS must time-share the resources of the computer among
			  these processes
		. isolation
			. The OS must also arrange for isolation between the processes.
			  That is, if one process has a bug and fails, it shouldn't
			  affect processes that don't depend on it
		. interaction
			. The OS must also facilitate interaction between processes,
			  for example pipelines


Abstracting physical resources

	. We work on the assumption that applications do not trust each other
	  (ex. bugs, malicious) and thus a need for isolation.
	. This is in contrast to a co-operative time sharing approach where
	  each application is well behaved and periodically gives up the
	  processor so that other applications can run
	. To this end, applications are forbidden from directly accessing
	  sensitive hardware resources, and instead the resources are
	  abstracted into services.
	. For example:

		...
		. Applications interact with a file system through
		  'open', 'read', 'write', 'close' system calls
		  instead of reading/writing to raw disk sectors.
		. The OS is the one to manage the disk.

		...
		. Switching hardware processors? among processes,
		  saving and restoring register state as necessary,
		  so that applications are oblivious to time-sharing.
		. For example, CPU still shared even if an application
		  is stuck in an infinite loop

		...
		. Processes use 'exec' to build up their memory image,
		  instead of directly interacting with physical memory.
		. This allows the OS to decide where to place a process in memory.
		  If memory is tight, the OS might even store some of
		  the process's data on disk.

		...
		. Many forms of interaction among Unix processes occur via
		  file descriptors
		. E.g. pipelines, ...


User mode, kernel mode, and system calls

	. Strong isolation...
		. If an application makes a mistake, we don't want the OS to fail
		  Instead, the OS should be able to clean up the failed application
		  and continue running other applications
		. Applications shouldn't be able to modify (or even read) the
		  OS's data structures or instructions

	. Processors provide hardware support for isolation
	. x86 for example has two modes in which it can execute instructions:
	  kernel mode and user mode
	. In kernel mode, the processor is allowed to execute privileged instructions
	  such as reading and writing to IO devices (disk, etc.)
	. If an application in user mode attempts to execute a privileged instruction,
	  then the processor doesn't execute the instruction.
	  Instead it switches to kernel mode so that the software in kernel
	  mode can clean up the application, because it did something it
	  shouldn't be doing

	. Processors provide a special instruction that switches the processor
	  from user mode to kernel mode and enters the kernel at an entry
	  point specified by the kernel
	. In x86, 'int' is used for this

	. Once the processor has switched to kernel mode, the kernel can:
		. validate the arguments of the system call,
		. decide whether the application is allowed to perform the
		  requested operation,
		. and then deny it or execute it.
	. It is important that the kernel sets the entry point for
	  transitions. A malicious application for example could enter
	  the kernel at a point where the validation of arguments is skipped.


Kernel organization

	~~~ Monolithic kernel ~~~

	. Entire operating system resides in the kernel so that all
	  system calls run in kernel mode
	. Entire OS runs with full hardware privilege
	. Ex Linux, Xv6
	. Pro - easy for different parts of the OS to cooperate.
	        For example, might ave a buffer cache that can be shared
	        by both the file system and virtual memory system
	. Con - interfaces between different parts of the OS are often complex??
	. Con - kernel mode errors often cause ... stop working and require reboot


	~~~ Microkernel ~~~

	. To reduce the risk of mistakes in kernel, OS designer can minimize
	  amount of OS code that runs in kernel mode, and execute the bulk
	  of it in user mode - microkernel
	. Ex Minix
	. OS services run as user space processes called 'servers'.
	. The kernel provides an inter-process communication mechanism to
	  send messages from one user-mode process to another...
	. For example, if an application like 'shell' wants to read a file,
	  it sends a message to the 'file server' and waits for a response

	. The kernel interface consists of a few low-level functions for:
		. starting functions
		. sending messages
		. accessing device hardware
		. etc.?
	. In this orginaztion style, most of the OS resides in user-level servers


Process overview

	. In Xv6, the process is the unit of isolation
	. The kernel must implement process abstraction with care because
	  a buggy or malicious application may ...
	. Mechanisms used by the kernel to implement processes include:
		. user/kernel mode flag
		. address spaces
		. time-slicing for threads

	. To help enforce isolation, the process abstraction provides the
	  illusion to a program that it has its own private machine...
	. A process provides a program with what appears to be:
		. a private memory system, or address space?
		. its own CPU


	~~~ Page tables ~~~

	. Xv6 uses page tables (which are implemented by hardware??) to
	  give each process its own address space.
	. The x86 page table translates (maps) a virtual address
	  (the address that a x86 instruction manipualtes) to
	  a physical address (the address the CPU sends to main memory)

	. Xv6 maintains a separate page table for each process that
	  defines the process's address space

	             0xFFFF_FFFF ->  -------------------
	                             memory mapped
	                             IO devices 
	  (DEVSPACE) 0xFE00_0000 ->  -------------------
	                             ...
	                             free memory
	                             ...
	             0x8040_0000 ->  -------------------  <-
	                             kernel rodata          |
	                             -------------------    |
	                             kernel text            |
	             0x8010_0000 ->  -------------------    | kernel
	                             bootloader, ?          |
	  (KERNBASE) 0x8000_0000 ->  -------------------  <-
	                             program data & heap    |
	                             -------------------    |
	              (PAGESIZE)     user stack             | user
	                             -------------------    |
	                             user rodata            |
	                             -------------------    |
	                             user text              |
	             0x0000_0000 ->  -------------------  <-

	. The address space includes the process's user memory
	  starting at virtual address zero
		. instructions come first,
		. followed by global variables,
		. then the stack,
		. then the "heap" area (for malloc) that the process
		  can expand as needed
		. then the kernel's instructions and data

	. A process's page table also serves as the record of the addresses
	  of the physical pages allocated to store the process's memory??


	~~~ ... ~~~

	. The kernel maintains many pieces of state for each process,
	  which it gathers into a 'struct proc'.
	  A process's most important pieces of kernel state are its:
		. page table
		. kernel stack
		. run state

		// Per-process state
		struct proc
		{
			uint              sz;                // Size of process memory (bytes)
			pde_t            *pgdir;             // Page table
			char             *kstack;            // Bottom of kernel stack for this process
			enum procstate    state;             // Process state
			int               pid;               // Process ID
			struct proc      *parent;            // Parent process
			struct trapframe *tf;                // Trap frame for current syscall
			struct context   *context;           // swtch() here to run process
			void             *chan;              // If non-zero, sleeping on chan
			int               killed;            // If non-zero, have been killed
			struct file      *ofile [ NOFILE ];  // Open files
			struct inode     *cwd;               // Current directory
			char              name [ 16 ];       // Process name (debugging)
		};


	. Each process has a thread of execution that executes the process's
	  instructions.
	. A thread can be suspended and later resumed
	. To switch between processes, the kernel suspends the currently
	  running thread and resumes another process's thread

	. Much of the state of a thread (local varialbes, function call return
	  address) is stored on the thread's stacks...
	. Each process has two stacks:
		. user stack
		. kernel stack (p->kstack)
	. When a process is executing user instructions, only its user stack
	  is used. The kernel stack is empty.
	. When the process enters kernel mode (ex. system call or interrupt),
	  the kernel code executes on the process's kernel stack.
	. Because the kernel stack is separate from the user stack, it can
	  execute even if a process has wrecked its user stack

	. When a process makes a system call:
		. the processor switches to the kernel stack,
		. raises the hardware privilege level,
		. and starts executing the kernel instructions that implement the
		  system call
	. When the system call completes, the kernel returns to user space:
		. the hardware lowers privilege level,
		. switches back to the user stack,
		. and resumes executing user instructions just after the
		  system call instruction

	. A process's thread can 'block' in the kernel to wait for IO, and
	  resume were it left off when the IO has finished

	. p->state indicates whether the process is allocated, ready to run,
	  running, waiting for IO, or exiting.

		enum procstate
		{
			UNUSED,
			EMBRYO,
			SLEEPING,
			RUNNABLE,
			RUNNING,
			ZOMBIE
		};

	. p->pgdir holds the process's page table in the format that
	  x86 expects.


The beginning

	. Let's look at how:
		. the kernel creates the first address space (for itself)
		. the kernel creates and starts the first process
		. that process performs the first system call


Creating the first address space

	. The first step in providing strong isolation is setting
	  up the kernel to run in its own address space
	. When a PC powers on, it initializes itself?, and then
	  loads a "boot loader" from disk into memory and executes it
	  starting at "entry" (entry.S)
	. The x86 paging hardware is not enabled when the kernel starts.
	  Virtual addresses map directly to physical addresses.


	~~~ ... ~~~

	. The boot loader loads the Xv6 kernel into memory at
	  physical address 0x0010_0000
	. It does not load the kernel at 0x8010_0000 (where the kernel
	  expects its instructions and data to be) because there may
	  not be any physical memory at that address in a small machine
	. It does not load the kernel at 0x0 because in x86?, the
	  address range 0x000A_0000 .. 0x0010_0000 contains IO devices??
	  https://wiki.osdev.org/Memory_Map_(x86)

	. To allow the rest of? the kernel to run, 'entry' sets up a
	  page table that maps virtual addresses starting at
	  0x8000_0000 (KERNBASE) to physical address starting at 0x0

	  | virtual addr |                  | physical addr |

	  0xFFFF_FFFF ->  ------------------
		              ...
		              ------------------
		              free memory       
	  0x8040_0000 ->  ------------------  <- 0x0040_0000
		              text and data     
	  0x8010_0000 ->  ------------------  <- 0x0010_0000
		              BIOS, ?
	  0x8000_0000 ->  ------------------  <- 0x0000_0000


	. The entry page table is defined in "main.c"

		__attribute__( ( __aligned__( PGSIZE ) ) )
		pde_t entrypgdir [ NPDENTRIES ] = {

			// Map VA's [0, 4MB ) to PA's [0, 4MB )
			[ 0 ]                    = ( 0 ) | PTE_P | PTE_W | PTE_PS,

			// Map VA's [KERNBASE, KERNBASE+4MB ) to PA's [0, 4MB )
			[ KERNBASE >> PDXSHIFT ] = ( 0 ) | PTE_P | PTE_W | PTE_PS,
		};


		/// mmu.h ///

		// Page table/directory entry flags.
		#define PTE_P  0x001   // Present
		#define PTE_W  0x002   // Writeable
		#define PTE_U  0x004   // User
		#define PTE_PS 0x080   // Page Size


	. entry[0]? maps virtual addresses 0 .. 0x0040_0000 to
	  physical addresses 0 .. 0x0040_0000
	. This mapping is required as long as entry is executing
	  at low address, but will eventually be removed

	. entry[512]? maps virtual address KERNBASE .. KERNBASE + 0x0040_0000 to
	  physical addresses 0 .. 0x0040_0000
	. This mapping will be used by the kernel after 'entry'
	  has finished
	. It maps the high virtual address the kernel expects to
	  find its instructions and data to the low physical address
	  where the boot loader loaded them
	. This mapping restricts the kernel instructions and data
	  to 4 Mbytes (0x0040_0000)

		  KERNBASE >> PDXSHIFT
		= 0x80000000 >> 22
		= 512


	~~~ Set page directory ~~~

	. "entry.S" first loads the physical address of "entrypgdir"
	  into the control register (cr3)
	. The symbol 'entrypgdir' refers to an address in high memory.
	  The macro V2P_WO subtracts KERNBASE in order to get the
	  physical address

		/// entry.S ///

		movl  $( V2P_WO( entrypgdir ) ), %eax
		movl  %eax, %cr3


		/// memlayout.h ///

		#define V2P_WO ( x ) ( ( x ) - KERNBASE )


	~~~ Enable paging hardware ~~~

	. To enable paging hardware, Xv6 sets the CR0_PG flag in
	  the control register (cr0)

		movl  %cr0, %eax
		orl   $( CR0_PG | CR0_WP ), %eax
		movl  %eax, %cr0


	~~~ Transfer to kernel's C code and run it in high memory ~~~

	. First makes the stack pointer (esp) point to the memory
	  location to be used as a stack
	. Then jumps to main.
	  An indirect jump is needed because the assembler would
	  otherwise generate a PC-relative direct jump...

		/// entry.S ///

		entry:

			...

			movl $( stack + KSTACKSIZE ), %esp

			mov $main, %eax
			jmp *%eax

		.comm stack, KSTACKSIZE  // allocate space...


		/// param.h ///

		#define KSTACKSIZE 4096  // size of per-process kernel stack


	. Now the kernel is running in high addresses in the
	  function "main" ("main.c")

Creating the first process

	. We will now look at how the kernel creates user-level
	  processes and ensures that they are strongly isolated


	~~~ allocproc, kernel stack ~~~

	. After main initializes several devices and subsytems,
	  it creates the first process by calling "userinit"
	. userinit's first action is to call "allocproc"

	. "allocproc" job is to:
		. allocate a slot (a struct proc) in the process table, and
		. to initialize the parts of the process's state
		  required for its kernel thread to execute ??

	. allocproc is called for each new process, while
	  userinit is called only once for the very first process
	. allocproc is written so that it can also be used by 'fork'

	. allocproc sets up the new process with a specially prepared
	  kernel stack and set of kernel registers that will cause ? to
	  "return" to user space when it first runs

	. allocproc first scans the "proc" table for a slot with state UNUSED 

		for ( p = ptable.proc; p < &ptable.proc[ NPROC ]; p += 1 )
		{
			if ( p->state == UNUSED )
			{
				goto found;
			}
		}

	. When it finds an unused slot, allocproc sets the state to
	  EMBRYO, to mark it as used and gives the process a unique pid

		p->state = EMBRYO;
		p->pid   = nextpid;

		nextpid += 1;

	. Next it tries to allocate a kernel stack for the process's
	  kernel thread.
	. If the memory allocation fails, allocproc changes the
	  state back to UNUSED and return zero to signal failure.

		if( ( p->kstack = kalloc() ) == 0 )
		{
			p->state = UNUSED;

			return 0;
		}

		sp = p->kstack + KSTACKSIZE;


	. Now allocproc must setup the kernel stack to look like we entered the
	  kernel through an interrupt:

	           ->  ---------------  <-- p->kstack + KSTACKSIZE
	          |    ss
	          |    ---------------
	          |    esp
	trapframe |    ---------------
	          |    ...
	          |    ---------------
	          |    edi
	           ->  ---------------  <-- p->tf
	               trapret
	           ->  ---------------  <-- p->tf - 4; address forkret will return to (trapret)
	          |    eip (forkret)
	          |    ---------------  <-- the process will start executing at p->context->eip (forkret)
	          |    ebp (0)
	          |    ---------------
	  context |    ebx (0)
	          |    ---------------
	          |    esi (0)
	          |    ---------------
	          |    edi (0)
	           ->  ---------------  <-- p->context
	               ...
	               empty
	               ...
	               ---------------  <-- p->kstack


	. It does this as follows:

		/// proc.c ///

		// Leave room for trap frame.
		sp -= sizeof *p->tf;
		p->tf = ( struct trapframe* )sp;

		// Set up new context to start executing at forkret,
		// which returns to trapret.
		sp -= 4;
		*( uint* )sp = ( uint )trapret;

		// Setup register contents that 
		sp -= sizeof *p->context;
		p->context = ( struct context* )sp;

		memset( p->context, 0, sizeof *p->context );

		p->context->eip = ( uint )forkret;


		/// proc.h ///

		struct context
		{
			uint edi;
			uint esi;
			uint ebx;
			uint ebp;
			uint eip;
		};

	. The code sets up program counter return values that will
	  cause the kernel thread to first execute 'forkret'
	  and then 'trapret'
	. The kernel thread will start executing with the
	  register contents (edi, esi, ebx, ebp, eip) in p->context.
	  Since p->context->eip is set to 'forkret', that is where
	  the kernel thread will start executing

		// A fork child's very first scheduling by scheduler()
		// will swtch here.  "Return" to user space.
		void forkret ( void )
		{
			static int first = 1;

			...

			if ( first )
			{
				// Some initialization functions must be run in the context
				// of a regular process ( e.g., they call sleep ), and thus cannot
				// be run from main().
				first = 0;

				iinit( ROOTDEV );

				initlog( ROOTDEV );
			}

			// Return to "caller", actually trapret ( see allocproc ).
		}

	. 'forkret' will return to whatever address is at the
	  bottom of the stack.
	  allocproc has placed the address of 'trapret' here
	. trapret restores user registers from values stored
	  at the top of the kernel stack, and jumps into the process??

		trapret:

			popal
			popl   %gs
			popl   %fs
			popl   %es
			popl   %ds
			addl   $0x8, %esp  # trapno and errcode
			iret

	. The context switch code (swtch.S) sets the stack pointer
	  to point just beyond the end of p->context,
	  where in this case, allocproc has placed the address of trapret
	. Control transfers from user software to the kernel via
	  an interrupt mechanism which is used by system calls,
	  interrupts, and exceptions
	. Whenever control transfers into the kernel while a
	  process is running, the hardware and Xv6 "trap entry code"??
	  save user registers onto the process's kernel stack

		/// x86.h ///

		// Layout of the trap frame built on the stack by the
		// hardware and by trapasm.S, and passed to trap().
		struct trapframe
		{
			// registers as pushed by pusha
			uint edi;
			uint esi;
			uint ebp;
			uint oesp;  // useless & ignored
			uint ebx;
			uint edx;
			uint ecx;
			uint eax;

			// rest of trap frame
			ushort gs;
			ushort padding1;
			ushort fs;
			ushort padding2;
			ushort es;
			ushort padding3;
			ushort ds;
			ushort padding4;
			uint   trapno;

			// below here defined by x86 hardware
			uint   err;
			uint   eip;
			ushort cs;
			ushort padding5;
			uint   eflags;

			// below here only when crossing rings, such as from user to kernel
			uint   esp;
			ushort ss;
			ushort padding6;
		};


		/// trapasm.S ///

		alltraps:

			# Build trap frame.
			pushl   %ds
			pushl   %es
			pushl   %fs
			pushl   %gs
			pushal
			
			# Set up data segments.
			movw    $( SEG_KDATA << 3 ), %ax
			movw    %ax, %ds
			movw    %ax, %es

			# Call trap( tf ), where tf = %esp
			pushl   %esp
			call    trap
			addl    $4, %esp

		# Return falls through to trapret...
		trapret:

			popal
			popl   %gs
			popl   %fs
			popl   %es
			popl   %ds
			addl   $0x8, %esp  # trapno and errcode
			iret


	. after allocproc, 'userinit' writes values to the
	  trapframe at the top of the stack that make it look
	  just like what would be there if the process had entered
	  the kernel via an interrupt.
	. This allows the ordinary code (?) for returning from the
	  kernel back to the process's user code to work.

		memset( p->tf, 0, sizeof( *p->tf ) );

		p->tf->cs     = ( SEG_UCODE << 3 ) | DPL_USER;
		p->tf->ds     = ( SEG_UDATA << 3 ) | DPL_USER;
		p->tf->es     = p->tf->ds;
		p->tf->ss     = p->tf->ds;
		p->tf->eflags = FL_IF;
		p->tf->esp    = PGSIZE;
		p->tf->eip    = 0;  // beginning of initcode.S

		. %cs to contain a segment selector for SEG_UCODE,
		  %ds,es,ss  '''                        SEG_UDATA,
		  all running at user privilege level (DPL_USER)
		. The %eflags bit FL_IF is set to allow hardware interrupts
		. %esp (stack pointer) is set to the process's largest
		  valid virtual address, p->sz??
		. %eip (instruction pointer) is set to the entry point
		  of initcode (address 0)

	. Now the kernel stack is completely prepared
	  (see above diagram)


	~~~ page table, address space ~~~

	. The first process is going to execute a small
	  program (initcode.S)
	. The process needs:
		. physical memory in which to store this program.
		. a page table that maps user-space addresses to
		  that memory

	. userinit calls 'setupkvm' to create a page table for
	  the process

		if ( ( p->pgdir = setupkvm() ) == 0 )
		{
			panic( "userinit: out of memory?" );
		}


	. The initial contents of the first process's user-space
	  memory are the compiled form of 'initcode.S'
	. As part of the kernel build process, the linker embeds
	  the 'initcode' binary in the kernel and defines
	  two special symbols:
		. _binary_initcode_start: indicates location of binary
		. _binary_initcode_size : indicates size of binary in bytes

		https://www.devever.net/~hl/incbin
		https://stackoverflow.com/a/53243725

	. userinit copies the contents of the 'initcode' binary
	  into the new process's memory by calling 'inituvm'
	. inituvm:
		. allocates one page of physical memory,
		. maps virtual address zero to that memory,
		. and copies the binary to that page...


		/// proc.c ///

		inituvm(

			p->pgdir,
			_binary_initcode_start,
			( int )_binary_initcode_size
		);

		p->sz = PGSIZE;


		/// vm.c ///

		// Load the initcode into address 0 of pgdir.
		// sz must be less than a page.
		void inituvm ( pde_t *pgdir, char *init, uint sz )
		{
			char *mem;

			...

			mem = kalloc();

			memset( mem, 0, PGSIZE );

			mappages( pgdir, 0, PGSIZE, V2P( mem ), PTE_W | PTE_U );

			memmove( mem, init, sz );
		}


	~~~ ready ~~~

	. Once the process is initialized, userinit marks it as
	  available for scheduling by setting:

		p->state = RUNNABLE;


Running the first process

	. Now that the first process's state is prepared, it is time
	  to run it

	. After 'main' calls 'userint', it calls 'mpmain'
	. 'mpmain' then calls 'scheduler' to start running the process


	~~~ scheduler ~~~

	. Changing page tables while executing in the kernel works
	  because 'setupkvm' causes all processes' page tables to
	  have identical mappings for kernel code and data

	. scheduler looks for a process with p->state set to RUNNABLE,
	  and there's only one: our first process
	. It sets the per-cpu variable 'proc' to the process it found


	~~~ switchuvm ~~~

	. It then calls 'switchuvm' to tell the hardware to start using the
	  target process's page table

		for ( ;; )
		{
			for ( p = ptable.proc; p < &ptable.proc[ NPROC ]; p += 1 )
			{
				if ( p->state != RUNNABLE )
				{
					continue;
				}

				c->proc = p;

				switchuvm( p );

				...
			}
		}

	. 'switchuvm' also sets up a task state segment? SEG_TSS that
	  instructs the hardware to execute system calls and interrupts
	  on the process's kernel stack??

		// Switch TSS and h/w page table to correspond to process p.
		void switchuvm ( struct proc *p )
		{
			mycpu()->gdt[ SEG_TSS ] = SEG16(

				STS_T32A,                   // type
				&mycpu()->ts,               // base address
				sizeof( mycpu()->ts ) - 1,  // limit
				0                           // descriptor privilege level
			);

			mycpu()->gdt[ SEG_TSS ].s = 0;  // 0 = system, 1 = application

			// ?
			mycpu()->ts.ss0  = SEG_KDATA << 3;
			mycpu()->ts.esp0 = ( uint )p->kstack + KSTACKSIZE;

			// setting IOPL=0 in eflags *and* iomb beyond the tss segment limit
			// forbids I/O instructions ( e.g., inb and outb ) from user space
			mycpu()->ts.iomb = ( ushort ) 0xFFFF;

			// ?
			ltr( SEG_TSS << 3 );

			// switch to process's address space
			lcr3( V2P( p->pgdir ) );
		}


	. scheduler now sets p->state to RUNNING and calls 'swtch'
	  to perform a context switch to the target process's kernel thread

		p->state = RUNNING;

		swtch( &( c->scheduler ), p->context );


	~~~ swtch ~~~

	. swtch first saves the current registers.
	. The current context is not a process but rather a special
	  per-cpu scheduler context, so scheduler tells swtch to save
	  the current hardware's registers in per-cpu storage
	  (cpu->scheduler) rather than in any process's kernel thread
	  context.

	. swtch then loads the saved registers of the target kernel
	  thread (p->context)

		swtch:

			movl   4( %esp ), %eax  # eax = old; c->scheduler
			movl   8( %esp ), %edx  # edx = new; p->context

			# Save old callee-saved registers
			pushl  %ebp
			pushl  %ebx
			pushl  %esi
			pushl  %edi

			# Switch stacks
			movl   %esp, ( %eax )  # [old] = esp; update pointer c->scheduler 
			movl   %edx, %esp      #   esp = new; use pointer p->context

			# Load new callee-saved registers
			popl   %edi
			popl   %esi
			popl   %ebx
			popl   %ebp

			ret

	. The final 'ret' instruction pops the target process's
	  'eip' from the stack, finishing the context switch
	. Now the processor is running on the kernel stack of process p


	~~~ forkret ~~~

	. allocproc had previously set initproc's
	  p->context->eip to forkret, so the ret starts executing there
	. On the first invocation (this one), forkret runs initialization
	  functions that cannot be run from main because they must be
	  run in the context of a regular process with its own kernel stack

		// A fork child's very first scheduling by scheduler()
		// will swtch here.  "Return" to user space.
		void forkret ( void )
		{
			static int first = 1;

			...

			if ( first )
			{
				// Some initialization functions must be run in the context
				// of a regular process ( e.g., they call sleep ), and thus cannot
				// be run from main().
				first = 0;

				iinit( ROOTDEV );

				initlog( ROOTDEV );
			}

			// Return to "caller", actually trapret ( see allocproc ).
		}


	~~~ trapret ~~~

	. When allocproc returns, allocproc has arranged for trapret
	  to begin executing
	. trapret uses pop instructions to restore registers from the
	  trap frame just as swtch did with the kernel context

		trapret:

			popal
			popl   %gs
			popl   %fs
			popl   %es
			popl   %ds
			addl   $0x8, %esp  # trapno and errcode
			iret

		. popal restores the general purpose registers
		. addl skips over two fields (trapno and errcode)
		. iret pops %eip, %cs, %flags, %esp, and %ss from the stack
		. see "struct trapframe"

	. The contents of the trap frame hae been transferred to the
	  CPU state, so the processor continues at tf->eip


	~~~ ... ~~~

	. For initproc, tf->eip points to virtual address zero, the
	  first instruction of initcode.S

	. At this point %eip holds zero, %esp holds 4096 ?? TODO

		/// proc.c - userinit ///

		p->tf->esp = PGSIZE;
		p->tf->eip = 0;  // beginning of initcode.S


	. These are virtual addresses in the process's address space
	. The CPU's paging hardware will translate them into physical addresses

	. inituvm has setup the process's page table so that virtual address
	  zero refers to the physical memory allocated for this process
	. It has also seta flag (PTE_U) that tells the paging hardware
	  to allow user code to acess that memory

		void inituvm ( pde_t *pgdir, char *init, uint sz )
		{
			char *mem;

			...

			mem = kalloc();

			memset( mem, 0, PGSIZE );

			mappages( pgdir, 0, PGSIZE, V2P( mem ), PTE_W | PTE_U );

			memmove( mem, init, sz );
		}

	. The fact that userinit has setup the low bits of %cs?
	  to run the process's user code at DPL_USER means that
	  the user code can only use pages with PTE_U set, and cannot
	  modify sensitive hardware registers such as %cr3.
	  The process is constrained to using its own memory.

		p->tf->cs = ( SEG_UCODE << 3 ) | DPL_USER;
		p->tf->ds = ( SEG_UDATA << 3 ) | DPL_USER;


The first system call: exec

	. Let's look at how a user-level process re-enters the kernel
	  to ask for services that it cannot perform itself.


	~~~ initcode.S ~~~

	. The first thing that initcode.S does, is to invoke the
	  exec system call

		# exec( char *path, char *argv[] )
		# exec( init, argv )
		start:

			pushl $argv
			pushl $init
			pushl $0     # where caller pc would be
			movl  $SYS_exec, %eax
			int   $T_SYSCALL

		# char init[] = "/init\0";
		init:

			.string "/init\0"

		# char *argv[] = { init, 0 };
		.p2align 2
		argv:

			.long init
			.long 0


	. It begins by pushing three values on the stack:
		. $argv
		. $init
		. 0
	. Then sets %eax to $SYS_exec
	. Then executes 'int T_SYSCALL'
	  If all goes well, exec never returns


	~~~ exec ~~~

	. exec starts running the program named $init,
	  which is a pointer to a null-terminated string.
	  FYI, this executes /usr/prog/init.c
	. The other argument "argv" is the array of
	  command-line arguments. The zero at the end of the
	  array marks its end.

	. We will cover the details of exec in more detail,
	  but at a high level, it replaces initcode with the
	  /init binary loaded from the file system.


	~~~ init ~~~

	. init creates a new console device file if needed.
	. It then opens the device as file descriptors 0, 1, 2.

		if ( open( "console", O_RDWR ) < 0 )
		{
			mknod( "console", 1, 1 );

			open( "console", O_RDWR );
		}

		dup( 0 );  // stdout
		dup( 0 );  // stderr

	. init then starts a console shell, and
	  handles orphaned zombies until the shell exits ??

		for ( ;; )
		{
			printf( 1, "init: starting sh\n" );

			pid = fork();

			if ( pid < 0 )
			{
				printf( 1, "init: fork failed\n" );
				exit();
			}

			if ( pid == 0 )
			{
				exec( "sh", argv );

				printf( 1, "init: exec sh failed\n" );
				exit();
			}

			// ??
			while ( ( wpid = wait() ) >= 0 && wpid != pid )
			{
				printf( 1, "zombie!\n" );
			}
		}


	. The system is up!


	~~~ Road to startup ~~~


	BIOS -> bootasm.start() -> bootmain() -> entry() -> main()

	main()
	     |--> ...
	     |
	     |--> userinit()
	     |             |--> allocproc()
	     |             |              |--> kalloc()
	     |             |
	     |             |--> setupkvm()
	     |             |            |--> kalloc()
	     |             |            |--> mappages()
	     |             |
	     |             |--> inituvm()
	     |                          |--> kalloc()
	     |                          |--> mappages()
	     |
	     |--> mpmain() -> scheduler() -> swtch() -> forkret() -> trapret() -> initcode.start() -> init.main()


---------------------------------------------------------------------------------------------
Page tables
---------------------------------------------------------------------------------------------

Paging hardware

	. A x86 page table is logically an array of 2^20 page table
	  entries (PTEs)
	. Each PTE contains:
		. a 20bit physical page number (PPN)
	  	. seven flags
	. The paging hardware translates a virtual address by:
		. using its top 20 bits to index into the page table to
		  find a PTE
		. then replacing the virtual address's top 20 bits with
		  the value (PPN) retrieved from the PTE
	. Thus the page table gives the OS control over V2P address
	  translations at the granularity of aligned chunks of
	  4096 bytes. (2^(32-20) = 2^12)
	. Such a chunk is called a page.


	. A page table is stored in physical memory as a two-level tree.
	. The root of the tree is a 4096 byte page directory that
	  contains 1024 PTE-like references to page tables
	. The hardware uses the top 10 bits of the VAaddr to select
	  a page directory entry
	. The next 10 bits of the Vaddr are used to select a PTE
	  from the page table that the page directory refers to
	. This two-level structure allows a page table to omit
	  entire pages?? in he case where large ranges of virtual
	  addresses have no mappings...?

		Virtual address

			31..22 - page directory entry (used to pick a page table)
			21..12 - page table entry     (used to picke a PTE)
			11..0  - offset


		Physical address

			31..12 - PPN
			11..0  - offset


		CR3

			Holds physical base address of page directory ??


		Page directory (points to page tables)

			         -----------
			         PTN | Flags
			1023 ->  -----------
			         ...
			         -----------
			         PTN | Flags
			   1 ->  -----------
			         PTN | Flags
			   0 ->  -----------


		PDE

			31..12 - page table number (PTN)
			11..7  - reserved
			     6 - unused (set to zero)
			     5 - accessed
			     4 - cache disabled
			     3 - 1 = write-through, 0 = write-back
			     2 - user
			     1 - writeable
			     0 - present


		Page table

			         -----------
			         PPN | Flags
			1023 ->  -----------
			         ...
			         -----------
			         PPN | Flags
			   1 ->  -----------
			         PPN | Flags
			   0 ->  -----------


		PTE

			31..12 - physical page number (PPN)
			11..7  - reserved
			     6 - dirty
			     5 - accessed
			     4 - cache disabled
			     3 - 1 = write-through, 0 = write-back
			     2 - user      (PTE_U)
			     1 - writeable (PTE_W)
			     0 - present   (PTE_P)


	. If either the PDE or PTE is not present, the paging
	  hardware raises a fault 

	. Each PTE contains flag bits that tell the paging hardware
	  how the associated virtual address is allowed to be used
	. PTE_P indicates whether the PTE is present.
	  If not set, a reference to the page causes a fault
	. PTE_W controls whether user program is allowd to use the page.
	  If not set, only the kernel is allowd to use the page.


Process address space

	. Each process has a separate page table
	. A process's user memory starts at virtual address zero and
	  can grow up to KERNBASE, allowing a process to address up
	  to 2GB of memory

	. When a process asks Xv6 for more memory, Xv6:
		. first finds free physical pages to provide the storage,
		. then, adds PTE's to the process's page table that point
		  to the new physical pages...
	. Xv6 sets the PTE_U, PTE_W, PTE_P flags in these PTEs
	. Most processes do not used the entire address space.
	  For unused PTEs, the PTE_P flag is clear

	. PHYSTOP??

	. Each process sees its memory as having contiguous virtual
	  addresses whereas the physical memory can be non-contiguous


	. Virtual

	             0xFFFF_FFFF ->  -------------------
	                             memory mapped
	                             IO devices 
	  (DEVSPACE) 0xFE00_0000 ->  -------------------
	                             ...
	                             free memory
	                             ...
	             0x8040_0000 ->  -------------------  <-
	                             kernel rodata          |
	                             -------------------    |
	                             kernel text            |
	             0x8010_0000 ->  -------------------    | kernel
	                             bootloader, ?          |
	  (KERNBASE) 0x8000_0000 ->  -------------------  <-
	                             program data & heap    |
	                             -------------------    |
	              (PAGESIZE)     user stack             | user
	                             -------------------    |
	                             user rodata            |
	                             -------------------    |
	                             user text              |
	             0x0000_0000 ->  -------------------  <-

	. Physical

	             0xFFFF_FFFF ->  -------------------
	                             memory mapped
	                             IO devices 
	             (PHYSTOP) ? ->  -------------------
	                             ...
	                             free memory
	                             ...
	             0x0040_0000 ->  -------------------
	                             kernel rodata
	                             -------------------
	                             kernel text
	    (EXTMEM) 0x0010_0000 ->  -------------------
	                             IO devices
	                       ? ->  -------------------
	                             boot loader (512 bytes)
	             0x0000_7C00 ->  -------------------
	                             ?
	             0x0000_0000 ->  -------------------


Creating an address space

	. main calls 'kvmalloc' to create and switch to a page table
	  with mappings above KERNBASE required for the kernel to run

		// Allocate one page table for the machine for the
		// kernel address space for scheduler processes.
		void kvmalloc ( void )
		{
			kpgdir = setupkvm();

			switchkvm();
		}

	~~~ setupkvm ~~~

	. Most of the work happens in 'setupkvm'
	. It first allocates a page of memory to hold the
	  page directory

		if ( ( pgdir = ( pde_t* )kalloc() ) == 0 )
		{
			return 0;
		}

		memset( pgdir, 0, PGSIZE );


	. It then calls mappages to install?? the translations that
	  the kernel needs, which are describe in 'kmap' array
	. The translation includes:
		. the kernel's instructions and data
		. physical memory up to PHYSTOP??
		. and memory ranges which are actually IO devices
	. setupkvm does not install any mappings for the user memory,
	  this will happen later (inituvm?)

		/// proc.c - kmap ///

		extern char data [];  // defined by kernel.ld

		// This table defines the kernel's mappings, which are
		// present in every process's page table.
		static struct kmap
		{
			void *virt;
			uint  phys_start;
			uint  phys_end;
			int   perm;

		} kmap[] = {

			// I/O space
			{
				( void* )KERNBASE,
				0,
				EXTMEM,
				PTE_W
			},
			// Kernel text + rodata
			{
				( void* )KERNLINK,
				V2P( KERNLINK ),
				V2P( data ),
				0
			},
			// Kernel data + memory
			{
				( void* )data,
				V2P( data ),
				PHYSTOP,
				PTE_W
			},
			// More devices
			{
				( void* )DEVSPACE,
				DEVSPACE,
				0,
				PTE_W
			}
		};


		/// proc.c - setupkvm ///

		for ( k = kmap; k < &kmap[ NELEM( kmap ) ]; k += 1 )
		{
			if (
				mappages(

					pgdir,                        // page directory
					k->virt,                      // virtual address start
					k->phys_end - k->phys_start,  // size
					( uint )k->phys_start,        // physical address start
					k->perm                       // permissions
				) < 0 )
			{
				freevm( pgdir );

				return 0;
			}
		}

		return pgdir;


	~~~ mappages ~~~

	. mappages installs mappings into a page table for a range of
	  virtual address to a corresponding range of physical addresses
	. It does this this separately for each virtual address in the
	  range, at page intervals?
	. For each virtual address to be mapped:
		. it calls 'walkpgdir' to find the address of the PTE
		  for that adddress
		. it then initializes the PTE to hold:
			. the relevant physical page number (PPN)
			. desired permissions (PTE_W, PTE_U)
			. sets PTE_P to mark the PTE as valid

		a    = ( char* )PGROUNDDOWN(   ( uint )va );
		last = ( char* )PGROUNDDOWN( ( ( uint )va ) + size - 1 );

		for ( ;; )
		{
			if ( ( pte = walkpgdir( pgdir, a, 1 ) ) == 0 )
			{
				return - 1;
			}

			if ( *pte & PTE_P )
			{
				panic( "remap" );
			}

			*pte = pa | permissions | PTE_P;

			if ( a == last )
			{
				break;
			}

			a  += PGSIZE;
			pa += PGSIZE;
		}


	~~~ walkpgdir ~~~

	. walkpgdir mimics the actions of the x86 paging hardware
	  as it looks up the PTE for a virtual address
	. It uses the upper 10 bits to find the page directory entry
	. If the PDE is not present, then the required page table
	  has not yet been allocated.
	  If the 'alloc' argument is set, walkpdir allocates it and
	  puts its physical address in the page directory
	. Finally, it uses the next 10 bits of the virtual address
	  to find the address of the PTE in the page table page


		/// vm.c ///

		static pte_t * walkpgdir( pde_t *pgdir, const void *va, int alloc )
		{
			pde_t *pde;
			pte_t *pgtab;

			pde = &pgdir[ PDX( va ) ];  // get pde index from va

			if ( *pde & PTE_P )
			{
				pgtab = ( pte_t* )P2V( PTE_ADDR( *pde ) );
			}
			else
			{
				if( ! alloc || ( pgtab = ( pte_t* )kalloc() ) == 0 )
				{
					return 0;
				}

				// Make sure all those PTE_P bits are zero.
				memset( pgtab, 0, PGSIZE );

				// The permissions here are overly generous, but they can
				// be further restricted by the permissions in the page table
				// entries, if necessary.
				*pde = V2P( pgtab ) | PTE_P | PTE_W | PTE_U;
			}

			return &pgtab[ PTX( va ) ];  // get pte index from va
		}


		/// mmu.h ///

		#define PTXSHIFT   12    // offset of PTX in a linear address
		#define PDXSHIFT   22    // offset of PDX in a linear address

		// page directory index
		#define PDX( va ) ( ( ( uint )( va ) >> PDXSHIFT ) & 0x3FF )

		// page table index
		#define PTX( va ) ( ( ( uint )( va ) >> PTXSHIFT ) & 0x3FF )


Physical memory allocation

	. The kernel must allocate and free physical memory at run-time for:
		. page tables
		. process user memory
		. kernel stacks
		. pipe buffers
	. Xv6 uses the physical memory between the end of the kernel
	  and PHYSTOP for run-time allocation
	. It allocates and frees whole 4096-byte pages at a time

	. It keeps track of which pages are free by threading a
	  linked list through the pages themselves.
	. Allocation consists of removing a page from the linked list
	. Freeing consists of adding the freed page to the list

	. There is a bootstrap problem.
	. All of physical memory must be mapped in order for the
	  alllocator to initialize the free list.
	. But creating a page table with these mappings involves
	  alllocating page-table pages??
	. Xv6 solves this problem by using a separate page allocator
	  during entry??, which allocates memory just after the end
	  of the kernel's data segment??
	. This allocator does not support freeing and is limited by
	  the 4 Mbytes mapping in the entrypgdir??, but that is sufficient
	  to allocate the first kernel page table???


Physical memory allocation - Code

	. The allocator's data structure is a list of physical memory
	  pages that are available for allocation
	. Each free page's list element is a "struct run"

		struct run
		{
			struct run *next;
		};

	. Where does the allocator get the memory to hold that data
	  structure? It stores each free page's run structure in the
	  free page itself.

	. The free list is protected by a spin lock.
	. The list and the lock are wrapped in a struct to make clear
	  the lock protects the fields in the struct...

		struct
		{
			struct spinlock lock;
			int             use_lock;
			struct run     *freelist;

		} kmem;

	. main calls 'kinit1' and 'kinit2' to initialize the allocator

		extern char end [];  // first address after kernel loaded from ELF file

		...

		int main ( void )
		{
			kinit1( end, P2V( 4 * 1024 * 1024 ) );  // phys page allocator
			...
			kinit2( P2V( 4 * 1024 * 1024 ), P2V( PHYSTOP ) );  // must come after startothers()
			...
		}

	. The reason for two calls is that for much of main, one cannot
	  use locks or memory above 4 Mbytes
	. The call to kinit1 sets up for lock-less allocation in the
	  first 4 Mbytes (4 * 1024 * 1024)
	. The call to kinit2 enables locking and arranges for memory to
	  be allocatable

		// Initialization happens in two phases.
		// 1. main() calls kinit1() while still using entrypgdir to place just
		// the pages mapped by entrypgdir on free list.
		// 2. main() calls kinit2() with the rest of the physical pages
		// after installing a full page table that maps them on all cores.
		void kinit1 ( void *vstart, void *vend )
		{
			initlock( &kmem.lock, "kmem" );

			kmem.use_lock = 0;

			freerange( vstart, vend );
		}

		void kinit2 ( void *vstart, void *vend )
		{
			freerange( vstart, vend );

			kmem.use_lock = 1;
		}

	. main ought to determine how much physical memory is available,
	  but this is difficult on x86? Insetead it assumes the machine
	  has PHYSTOP bytes of physical memory, and uses all the memory
	  between the end of the kernel and PHYSTOP

	. kinit1 and kinit2 call 'freerange' to add memory to the free
	  list via per-page calls to 'kfree'
	. A PTE can only refer to a physical address that is aligned on
	  a 4096-byte boundary, so freerange uses PGROUNDUP to ensure
	  that it frees only aligned physical addresses

		void freerange ( void *vstart, void *vend )
		{
			char *p;

			p = ( char* )PGROUNDUP( ( uint )vstart );

			for ( ; p + PGSIZE <= ( char* )vend; p += PGSIZE )
			{
				kfree( p );
			}
		}

	. The allocator sometimes treats addresses as integeres in
	  order to perform arithmetic on them.
	  And sometimes as pointers to read and write memory.
	. This is the main reason that the allocator code is full of
	  C type casts.
	. The other reason is that freeing and allocation inherently
	  change the type of the memory?


	~~~ kfree ~~~

	. The function kfree begins by setting every byte in the
	   memory being freed to the value 1
	. This will cause code that uses memory after freeing it
	  (uses "dangling references") to rad garbage instead of
	  the old valid contents.
	  Hopefully this causes such code to break faster.

		memset( v, 1, PGSIZE );

	. kfree then casts "v" to a pointer to "struct run",
	  records the old start of the free list in "r->next",
	  and sets the free list equal to r

		r = ( struct run* )v;

		r->next = kmem.freelist;

		kmem.freelist = r;


	~~~ kalloc ~~~

	. kalloc removes and returns the first element in the
	  free list.

		char* kalloc ( void )
		{
			struct run *r;

			r = kmem.freelist;

			if ( r )
			{
				kmem.freelist = r->next;
			}

			return ( char* )r;
		}


Use part of an address space

	  (KERNBASE) 0x8000_0000 ->  -------------------
	                             heap
	                             -------------------
	              (PAGESIZE)     stack
	                             -------------------
	                             guard page
	                             -------------------
	                             rodata
	                             -------------------
	                             text
	             0x0000_0000 ->  -------------------

	. Each user process starts at address zero
	. The bottom of the address space contains the text for
	  the user program, its data, and its stack.
	. The heap is above the stack so that the heap can expand
	  when the process calls 'sbrk'

	. The stack is a single page (4096 bytes)
	. To guard a stack from growing beyond this size, a
	  guard page is placed right below the stack. The page is not
	  mapped and so if the stack overflows, the hardware will
	  generate an exception.
	. A real-world OS might instead allocate more space for the
	  stack so that it can grow beyond one page


sbrk

	. 'sbrk' is the system call for a process to shrink or grow
	  its memory - sbrk( nBytes )
	. It is implemented by the function 'growproc'

		int sys_sbrk ( void )
		{
			int addr;
			int n;

			...

			addr = myproc()->sz;

			if ( growproc( n ) < 0 )
			{
				return - 1;
			}

			return addr;
		}


	~~~ growproc ~~~

	. If nBytes is positive, growproc allocates one or more
	  physical pages and maps them at the top of the process's
	  address space
	. If nBytes is negative, growproc unmaps one or more
	  pages from the process's address space and frees the
	  corresponding physical pages.
	. To make these changes, Xv6 modifies the process's page
	  table via 'allocuvm' and 'deallocuvm'

		int growproc ( int n )
		{
			uint sz;
			struct proc *curproc = myproc();

			sz = curproc->sz;

			if( n > 0 )
			{
				if( ( sz = allocuvm( curproc->pgdir, sz, sz + n ) ) == 0 )
				{
					return - 1;
				}
			}
			else if( n < 0 )
			{
				if( ( sz = deallocuvm( curproc->pgdir, sz, sz + n ) ) == 0 )
				{
					return - 1;
				}
			}

			curproc->sz = sz;

			switchuvm( curproc );

			return 0;
		}


	. The x86 hardware caches page tables entries in a
	  Translation Look-aside Buffer (TLB), and when Xv6 changes
	  the page tables, it must invalidate the cached entries
	. Xv6 invalidates stale cached entries by reloading cr3 (swithcuvm),
	  the register that holds the address of the current page table


exec

	. exec is the system call that creats the user part of an
	  address space
	. it initializes the user part of an address space from
	  a file stored in the filesystem

	. exec opens the named binary path using 'namei'

		struct elfhdr  elf;
		struct inode  *ip;

		...

		ip = namei( path )


	. Then it reads the ELF header

		if ( readi( ip, ( char* )&elf, 0, sizeof( elf ) ) != sizeof( elf ) )
		{
			goto bad;
		}


	. An ELF binary consists of:
		. an ELF header - "struct elfhdr"
		. followed by a sequence of program section headers - "stuct proghdr"
	. Each 'proghdr' describes a section of the application that
	  must be loaded into memory
	. Xv6 programs have only one ph, but other systems might have
	  separate sections for instructions and data

		struct elfhdr
		{
			uint   magic;       // must equal ELF_MAGIC

			uchar  elf [ 12 ];  // 1 - 32bit, 2 - 64bit
			                    // 1 - little endian, 2 - big endian
			                    // ...
			                    // target OS e.g. System V, Linux
			                    // ...

			ushort type;        // object file type e.g. EXEC, DYN
			ushort machine;     // ISA e.g. x86, MIPS, ARM, RISC-V
			uint   version;     // ...

			uint   entry;       // entry point where process starts executing
			uint   phoff;       // points to start of program header table
			uint   shoff;       // points to start of section header table

			uint   flags;       // ...

			ushort ehsize;      // size of this elf header

			ushort phentsize;   // size of program header entry
			ushort phnum;       // number of entries in program header table

			ushort shentsize;   // size of section header entry
			ushort shnum;       // number of entries in section header table
			ushort shstrndx;    // index of the section	header table entry that contains the section names
		};

		struct proghdr
		{
			uint type;    // type of segment e.g. LOAD, DYNAMIC
			uint off;     // offset of the segment in the file image
			uint vaddr;   // virtual address of the segment in memory
			uint paddr;   // physical address of the segment in memory 
			uint filesz;  // size in bytes of the segment in the file image
			uint memsz;   // size in bytes of the segment in memory
			uint flags;   // ...
			uint align;   // 0 or 1 no alignment
		};

	. It then makes a quick check that the file probably contains an
	  ELF binary.
	. An ELF binary starts with the four-byte magic number:

		#define ELF_MAGIC 0x464C457F  // 0x7F 'E' 'L' 'F' in little endian

	. If the ELF header has the right magic number, exec assumes the
	  binary is well-formed

		if ( elf.magic != ELF_MAGIC )
		{
			goto bad;
		}


	. exec allocates a new page table with no user mappings using
	  setupkvm

		pgdir = setupkvm()


	. exec then allocates memory for each ELF segment with 'allocuvm',
	  and loads each segment into memory with 'loaduvm'

		sz = 0;

		for ( i = 0, off = elf.phoff; i < elf.phnum; i += 1, off += sizeof( ph ) )
		{
			readi( ip, ( char* )&ph, off, sizeof( ph ) )

			...

			sz = allocuvm( pgdir, sz, ph.vaddr + ph.memsz )

			...

			loaduvm( pgdir, ( char* )ph.vaddr, ip, ph.off, ph.filesz )

			...
		}


	. The program section header's filesz might be less than memsz
	  indicating that the gap between them should be filled with
	  zeros rather than read from the file.
	. For example, in _init, filesz is 15 bytes less than memsz


	. readelf -a _init

		ELF Header:
		  Magic:   7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00
		  Class:                             ELF32
		  Data:                              2's complement, little endian
		  Version:                           1 (current)
		  OS/ABI:                            UNIX - System V
		  ABI Version:                       0
		  Type:                              EXEC (Executable file)
		  Machine:                           Intel 80386
		  Version:                           0x1
		  Entry point address:               0x0
		  Start of program headers:          52 (bytes into file)
		  Start of section headers:          7684 (bytes into file)
		  Flags:                             0x0
		  Size of this header:               52 (bytes)
		  Size of program headers:           32 (bytes)
		  Number of program headers:         2
		  Size of section headers:           40 (bytes)
		  Number of section headers:         15
		  Section header string table index: 12

		...

		Program Headers:
		  Type           Offset   VirtAddr   PhysAddr   FileSiz MemSiz  Flg Align
		  LOAD           0x000074 0x00000000 0x00000000 0x00b7d 0x00b8c RWE 0x4
		  GNU_STACK      0x000000 0x00000000 0x00000000 0x00000 0x00000 RWE 0x10

		...

	. ph would look like,

		ph->type   = ELF_PROG_LOAD
		ph->off    = 0x00000074
		ph->vaddr  = 0x00000000
		ph->paddr  = 0x00000000
		ph->filesz = 0x00000b7d
		ph->memsz  = 0x00000b8c
		ph->flags  = ELF_PROG_FLAG_READ | ELF_PROG_FLAG_WRITE | ELF_PROG_FLAG_EXEC
		ph->align  = 4


	~~~ loaduvm ~~~

	. loaduvm uses walkpgdir to find the physical address of
	  the allocated memory at which to write each page of the
	  ELF segment...
	. loaduvm uses readi to read from the file...

		int loaduvm ( pde_t *pgdir, char *addr, struct inode *ip, uint offset, uint sz )
		{
			uint   i, pa, n;
			pte_t *pte;

			...

			for ( i = 0; i < sz; i += PGSIZE )
			{
				if ( ( pte = walkpgdir( pgdir, addr + i, 0 ) ) == 0 )
				{
					panic( "loaduvm: address should exist" );
				}

				pa = PTE_ADDR( *pte );

				if ( sz - i < PGSIZE )
				{
					n = sz - i;
				}
				else
				{
					n = PGSIZE;
				}

				if ( readi( ip, P2V( pa ), offset + i, n ) != n )
				{
					return - 1;
				}
			}

			return 0;
		}


	~~~ exec ~~~

	. Now exec allocates and initializes the user stack

	. It allocates just one stack page.

	. exec places an inaccessible page just below the stack page,
	  so that programs that stack overflow will fault
	. This inaccessible page allows Xv6 to deal with arguments
	  that are too large.
	  In that situation, the 'copyout' function that exec uses
	  to copy arguments to the stack will notice that the
	  destination page is not accessible and return -1

		/// exec.c ///

		// Allocate two pages at the next page boundary.
		// Make the first inaccessible. Use the second as the user stack.
		sz = PGROUNDUP( sz );

		if ( ( sz = allocuvm( pgdir, sz, sz + 2 * PGSIZE ) ) == 0 )
		{
			goto bad;
		}

		clearpteu( pgdir, ( char* )( sz - 2 * PGSIZE ) );

		sp = sz;


		/// vm.c ////

		// Clear PTE_U on a page. Used to create an inaccessible
		// page beneath the user stack.
		void clearpteu ( pde_t *pgdir, char *uva )
		{
			pte_t *pte;

			pte = walkpgdir( pgdir, uva, 0 );

			...

			*pte &= ~ PTE_U;
		}


	. exec copies the argument strings to the top of the stack,
	  one at a time, recording the pointers to them in 'ustack'
	. It places a null pointer at the end of what will be the
	  argv list passed to main?
	. The first three entries in ustack are:
		. the fake return PC
		. argc
		. argv pointer

	. TODO: not sure about push order...
	. Ex. exec( "/init\0", [ "/init\0", 0 ] )  ??

	       ---->  ---------------
	      |       0
	stack |       't'
	      |       'i'
	      |       'n'
	      |       'i'
	      |       '/'              argv[0]
	      |       ---------------
	      |       x                argv[1] if existed
	      |       ---------------
	      |       x                argv[2] if existed
	      |   ->  ---------------
	      |  |    0                end of argv
	'ustack' |    ---------------
	      |  |    x                argv[2] pointer if existed ...
	      |  |    ---------------
	      |  |    x                argv[1] pointer if existed ...
	      |  |    ---------------
	      |  |    argv[0] pointer  ...
	      |  |    ---------------
	      |  |    ??               argv pointer?
	      |  |    ---------------
	      |  |    1                argc
	      |  |    ---------------
	      |  |    0xffffffff       fake return PC
	      |   ->  ---------------
	      |       ...
	       ---->  ---------------


	/// exec.c ///

		// Push argument strings, prepare rest of stack in ustack.
		for ( argc = 0; argv[ argc ]; argc += 1 )
		{
			...

			// ? why & ~ 3? multiples of 4?
			sp = ( sp - ( strlen( argv[ argc ] ) + 1 ) ) & ~ 3;

			copyout(

				pgdir,
				sp,
				argv[ argc ],
				strlen( argv[ argc ] ) + 1
			)

			ustack[ 3 + argc ] = sp;
		}

		ustack[ 3 + argc ] = 0;  // mark end of arguments

		ustack[ 0 ] = 0xffffffff;             // fake return PC
		ustack[ 1 ] = argc;
		ustack[ 2 ] = sp - ( argc + 1 ) * 4;  // argv pointer

		sp -= ( 3 + argc + 1 ) * 4;

		copyout(

			pgdir,
			sp,
			ustack,
			( 3 + argc + 1 ) * 4
		)


	/// vm.c ///

	int copyout ( pde_t *pgdir, uint va, void *p, uint len )
	{
		char *buf, *pa0;
		uint  n, va0;

		buf = ( char* )p;

		while ( len > 0 )
		{
			va0 = ( uint )PGROUNDDOWN( va );

			pa0 = uva2ka( pgdir, ( char* )va0 );

			...

			n = PGSIZE - ( va - va0 );

			...

			memmove( pa0 + ( va - va0 ), buf, n );

			len -= n;
			buf += n;

			va = va0 + PGSIZE;
		}

		...
	}


	. exec must wait to free the old image until it is sure the
	  system call will succeed. If the old image is gone, the
	  system call cannot return -1 to it.

	. once the image is complete, exec can install the
	  new image and free the old one

		oldpgdir = curproc->pgdir;

		curproc->pgdir   = pgdir;
		curproc->sz      = sz;
		curproc->tf->eip = elf.entry;  // main
		curproc->tf->esp = sp;

		switchuvm( curproc );

		freevm( oldpgdir );


	~~~ security ~~~

	. exec loads bytes from the ELF file into memory at addresse
	  specified by the ELF file
	. Users or processes can place whatever addresses they want
	  int an ELF file.
	. Thus exec is risky because the addresses in the ELF file
	  can refer to the kernel, accidentally or on purpose
	. Xv6 performs a number of checks to avoid these risks, but
	  it is likely it does not do a complete job


Real world

	. Xv6 doesn't implement:
		. stuff don't care about
		. automatically extending stacks
	. A "real" kernel alllocator would need to handle both
	  small and large allocations. Xv6 just does one size
	  for all.


---------------------------------------------------------------------------------------------
Traps, interrupts, and drivers
---------------------------------------------------------------------------------------------

System calls, exceptions, and interrupts

	. Three cases where control must be transferred from a user
	  program to the kernel:
		. system call
		. exception (ex divide by zero, attempting to access
		  memory for a PTE that is not present)
		. interrupt
	. The kernel handles all interrupts rather than user processes
	  because in most cases, only the kernel has the required
	  privilege

	. The OS must arrange for the following to happen:
		. save processor's registers
		. setup for execution in kernel
		. choose a place for the kernel to start executing
		. the kernel must be able to retrieve information about
		  the event e.g. system call arguments

	. An interrupt stops the normal processor loop and starts
	  executing a new sequence called an interrupt handler
	. Before starting the interrupt handler, the processor saves
	  its registers, so that the OS can restore them when it
	  returns from the interrupt


x86 protection

	. x86 has four protection levels, numbered 0 (most privilege)
	  to 3 (least)
	. In practice, most OSs use only 0 (kernel) and 3 (user)
	. The current privilege level (CPL) by which the processor
	  executes instructions is stored in %cs register

	. x86 interrupt handlers are defined in the interrupt
	  descriptor table (IDT)
	. The IDT has 256 entries, each giving the %cs and %eip to
	  be used when handling the corresponding interrupt

	. To make a system call, a program invokes the "int n"
	  instruction, where n specifies the index into the IDT
	. The int instruction performs the following steps:

		. fetch the n'th descriptor from the IDT
		. check that CPL is <= DPL (privilege level in the
		  interrupt descriptor)
		. save %esp and %ss in CPU-internal registers, but only
		  if the target segment selector's PL < CPL
		. load %ss and %esp from a task segment descriptor
		. push %ss
		. push %esp
		. push %eflags
		. push %cs
		. push %eip
		. clear the IF bit in %eflags, but only on an interrupt
		. set %cs and %eip to the values in the descriptor

	. The check, CPL <= DPL allows the kernel to forbid
	  int calls to inappropriate IDT entries
	. For example if a user program tries calling a
	  forbidden interrupt, for example of an IO device,
	  it will fail because the interrupt
	  descriptor would have a DPL of 0 (kernel).
	. The int instead is treated as "int 13" which is a
	  general protection fault

	. The int instruction cannot use the user stack to save values,
	  becaue the process may not have a valid stack pointer.
	  Instead, the hardware uses the stack specified in the
	  task segment, which is set by the kernel??

	. Kernel stack after an int instruction

		sp from task ->  -----------  <-
		segment          ss             |
		                 -----------    | only present on
		                 esp            | privilege change
		                 -----------  <-
		                 eflags
		                 -----------
		                 cs
		                 -----------
		                 eip          <- address specified in IDT entry
		                 -----------
		                 error code
		         esp ->  -----------
		                 ...
		                 -----------


	. %eip is pointing to the address specified in the descriptor
	. The instruction at that address is the next instruction
	  to be executed, and the first instruction of the handler for
	  int n.

	. An OS can use the 'iret' instruction to return from an
	  'int' instruction.
	. iret pops the saved values by int from the stack, and resumes
	  execution at the saved %eip


The first system call

	. Previously, we ended with initcode.S invoking a system
	  call 'exec'
	. The process pushed the arguments for an exec call on the
	  processor's stack, and put the system call number in %eax

		start:

			pushl $argv
			pushl $init
			pushl $0     # where caller pc would be
			movl  $SYS_exec, %eax
			int   $T_SYSCALL

	. The system call numbers match the entries in the syscalls
	  array, a table of function pointers

		/// syscall.h ///

		// System call numbers
		#define SYS_fork     1
		#define SYS_exit     2
		#define SYS_wait     3
		#define SYS_pipe     4
		#define SYS_read     5
		#define SYS_kill     6
		#define SYS_exec     7
		#define SYS_fstat    8
		#define SYS_chdir    9
		#define SYS_dup     10
		#define SYS_getpid  11
		#define SYS_sbrk    12
		#define SYS_sleep   13
		#define SYS_uptime  14
		#define SYS_open    15
		#define SYS_write   16
		#define SYS_mknod   17
		#define SYS_unlink  18
		#define SYS_link    19
		#define SYS_mkdir   20
		#define SYS_close   21


		/// syscall.c ///
		static int ( *syscalls[] )( void ) = {

			[ SYS_fork   ] sys_fork,
			[ SYS_exit   ] sys_exit,
			[ SYS_wait   ] sys_wait,
			[ SYS_pipe   ] sys_pipe,
			[ SYS_read   ] sys_read,
			[ SYS_kill   ] sys_kill,
			[ SYS_exec   ] sys_exec,
			[ SYS_fstat  ] sys_fstat,
			[ SYS_chdir  ] sys_chdir,
			[ SYS_dup    ] sys_dup,
			[ SYS_getpid ] sys_getpid,
			[ SYS_sbrk   ] sys_sbrk,
			[ SYS_sleep  ] sys_sleep,
			[ SYS_uptime ] sys_uptime,
			[ SYS_open   ] sys_open,
			[ SYS_write  ] sys_write,
			[ SYS_mknod  ] sys_mknod,
			[ SYS_unlink ] sys_unlink,
			[ SYS_link   ] sys_link,
			[ SYS_mkdir  ] sys_mkdir,
			[ SYS_close  ] sys_close,
		};

	. Also see "usys.S"


	. We need to arrange that:
		. the int instruction switches the processor from user
		  to kernel mode
		. that the kernel invokes the right kernel function
		  (ex. sys_exec)
		. that the kernel can retrieve the arguments for the syscall


Assembly trap handlers

	. Xv6 must setup the x86 hardware to do something sensible
	  when it encounters an int instruction, which causes the
	  processor to generate a trap
	. x86 allows for 256 different interrupts:
		. 0-31 are defined for software exceptions
	. Xv6 maps 32 hardware interrupts to the range 32-63
	. Xv6 uses interrupt 64 as the system call interrupt

		#define T_DIVIDE      0  // divide error
		#define T_DEBUG       1  // debug exception
		#define T_NMI         2  // non-maskable interrupt
		#define T_BRKPT       3  // breakpoint
		#define T_OFLOW       4  // overflow
		#define T_BOUND       5  // bounds check
		#define T_ILLOP       6  // illegal opcode
		#define T_DEVICE      7  // device not available
		#define T_DBLFLT      8  // double fault
		// #define T_COPROC   9  // reserved (not used since 486)
		#define T_TSS        10  // invalid task switch segment
		#define T_SEGNP      11  // segment not present
		#define T_STACK      12  // stack exception
		#define T_GPFLT      13  // general protection fault
		#define T_PGFLT      14  // page fault
		// #define T_RES     15  // reserved
		#define T_FPERR      16  // floating point error
		#define T_ALIGN      17  // aligment check
		#define T_MCHK       18  // machine check
		#define T_SIMDERR    19  // SIMD floating point error

		// These are arbitrarily chosen, but with care not to overlap
		// processor defined exceptions or interrupt vectors.
		#define T_SYSCALL     64  // system call
		#define T_DEFAULT    500  // catchall

		#define T_IRQ0        32  // IRQ 0 corresponds to int T_IRQ


	~~~ tvinit ~~~

	. tvinit sets up the 256 entries in the table "idt"
	. Interrupt "i" is handled by the code at the address in
	  "vectors[i]"
	. tvint handles T_SYSCALL specially: it specifies the gate
	  is of type "trap" by passing a value of 1 as the second
	  argument to SETGATE.
	  Trap gates do not clear the IF flag, allowing other interrupts
	  to occur during the system call handler
	. tvinit also sets the system call gate privilege to DPL_USER

		struct gatedesc idt     [ 256 ];
		extern uint     vectors [];  // in vectors.S: array of 256 entry pointers

		void tvinit ( void )
		{
			int i;

			for ( i = 0; i < 256; i += 1 )
			{
				SETGATE( idt[ i ], 0, SEG_KCODE << 3, vectors[ i ], 0 );
			}

			// If system call, do not disable interrupts.
			// Also set privilege level to DPL_USER.
			SETGATE( idt[ T_SYSCALL ], 1, SEG_KCODE << 3, vectors[ T_SYSCALL ], DPL_USER );

			initlock( &tickslock, "time" );
		}

	. When changing protection levels, the kernel shouldn't use
	  the stack of the user's process because it may not be valid.
	  The user process may be malicious or contain an error that
	  causes %esp to contain an address that is not part of it's
	  user memory??
	. Xv6 programs the x86 hardware to perform a stack switch on
	  a trap by setting up a task segment descriptor through
	  which the hardware loads a stack segment selector and a new
	  value for %esp

	. The function switchuvm stores the address? at the top
	  of the kernel stack of the user process into the
	  task segment descriptor??

		// ?
		mycpu()->ts.ss0  = SEG_KDATA << 3;
		mycpu()->ts.esp0 = ( uint )p->kstack + KSTACKSIZE;


	. When a trap occurs, if it was executing in user mode,
	  the x86 processor:
		. loads %esp and %ss from the task segment descriptor,
		. and pushes the old user %esp and %ss onto the new stack

	. x86 then pushes the %eflags, %cs, and %eip registers
	. For some traps (ex page fault), x86 also pushes an error
	  number

	. x86 then loads %eip and %cs from the relevant IDT entry

	. Kernel stack after an int instruction

		sp from task ->  -----------  <-
		segment          ss             |
		(cpu->ts.esp0)   -----------    | only present on
		                 esp            | privilege change
		                 -----------  <-
		                 eflags
		                 -----------
		                 cs
		                 -----------
		                 eip
		                 -----------
		                 error code
		         esp ->  -----------
		                 ...
		                 -----------


	~~~ vectors.pl ~~~

	. Xv6 uses a Perl script (vectors.pl) to generate the
	  entry points that the IDT entries point to (vectors.S)
	. Each entry:
		. pushes an error code (0) if the processor didn't
		. pushes the interrupt(trap) number,
		. then jumps to 'alltraps'

		/// vectors.S ///

		.globl vector0
		vector0:
			pushl $0
			pushl $0
			jmp alltraps

		...

		.globl vector8
		vector8:
			pushl $8
			jmp alltraps

		...

		.data

			.globl vectors
			vectors:

				.long vector0
				.long vector1
				...
				.long vector255


	~~~ alltraps ~~~

	. 'alltraps' continues to save processor registers.
	. It pushes %ds, %es, %fs, %gs, and the general purpose regs

		alltraps:

			# Build trap frame.
			pushl   %ds
			pushl   %es
			pushl   %fs
			pushl   %gs
			pushal

			...

	. The result of this effort is that the kernel now contains
	  a "struct trapframe" containing the processor's registers
	  at the time of the trap

	. Kernel stack looks like this now:

	        ->         cpu->ts.esp0  ->  -----------  <-                 <-
	       |  (top of kernel stack)      ss             | only present     |
	       |                             -----------    | on privilege     |
	       |                             esp            | upgrade (u to k) |
	       |                             -----------  <-                   |
	       |                             eflags                            | pushed
	       |                             -----------                       | by x86
	       |                             cs                                |
	       |                             -----------                       |
	       |                             eip                               |
	       |                             -----------                       |
	  trap |                             error code   <- can be pushed     |
	 frame |                                             by trap vector    |
	       |                             -----------  <--------------------
	       |                             
	       |                             trapno       <--------------------  pushed by
	       |                                                                 trap vector
	       |                             -----------  <--------------------
	       |                             ds                                |
	       |                             -----------                       |
	       |                             es                                |
	       |                             -----------                       |
	       |                             fs                                |
	       |                             -----------                       |
	       |                             gs                                |
	       |                             -----------                       |
	       |                             eax                               |
	       |                             -----------                       | pushed by
	       |                             ecx                               | alltraps
	       |                             -----------                       |
	       |                             edx                               |
	       |                             -----------                       |
	       |                             ebx                               |
	       |                             -----------                       |
	       |                             o_esp                             |
	       |                             -----------                       |
	       |                             ebp                               |
	       |                             -----------                       |
	       |                             esi                               |
	       |                             -----------                       |
	       |                             edi                               |
	        ->                   esp ->  -----------  <--------------------
	                     (kernel sp)     ...
	                                     
	                                     empty
	                                     
	                                     ...
	                       p->kstack ->  -----------
	        (bottom of kernel stack)


	. The trap frame contains all the information necessary
	  to restore the user mode processor registers when the
	  kernel returns to the current process

	. For our case study, the %eax saved holds the system call
	  number (SYS_exec) for the kernel to inspect later

	. With the registers saved, alltraps can finish setting
	  up the processor to run kernel C code
	. Since the x86 processor sets the %cs and %ss before
	  entering the handler, alltraps sets %ds and %es

		# Set up data segments.
		movw  $( SEG_KDATA << 3 ), %ax
		movw  %ax, %ds
		movw  %ax, %es

	. Once the segments are set properly, alltraps can
	  call the C trap handler 'trap'
	. It pushes %esp (which points to the trapframe it just
	  created) onto the stack as an argument to trap
	. Then it calls trap

		# Call trap( tf ), where tf = %esp
		pushl  %esp
		call   trap
		addl   $4, %esp

	. After trap returns, alltraps pops the argument
	  off the stack by adding to the stack pointer
	. alltraps then starts executing the code at label
	  "trapret" which restors user mode registers and
	  then iret jumps back into user space

		trapret:

			popal
			popl   %gs
			popl   %fs
			popl   %es
			popl   %ds
			addl   $0x8, %esp  # trapno and errcode
			iret


	~~~ kernel mode traps ~~~

	. Traps can occur while the kernel is executing
	. In this case, x86 does not:
		. switch stacks...
		. save the stack pointer (%esp)...
		. save the stack segment selector (%ss)...
	. Otherwise, the same steps occur as in traps from user mode
	. When iret later restores a kernel mode %cs,
	  x86 continues executing in kernel mode?


C trap handler

	. 'trap' looks at the hardware trap number tf->trapno
	  to decide why it has been called and what needs to be done
	. If the trap is T_SYSCALL, 'trap' calls the system call
	  handler, 'syscall'

		if ( tf->trapno == T_SYSCALL )
		{
			...

			myproc()->tf = tf;

			syscall();

			...

			return;
		}


	. After checking for a system call, 'trap' looks for
	  hardware interrupts
	. spurious?

	. If the trap is not a system call, and not a hardware
	  interrupt, trap assumes it was caused by incorrect
	  behaviour (ex. divide by zero) as part of the code that
	  was executing before the trap.
	. If the code that caused the trap was a user program,
	  Xv6 prints details and then sets proc->killed to remember
	  to clean up the user process
	. If t was the kernel running, there must be a bug in the
	  kernel. Trap prints details about the surprise and then
	  calls 'panic'

		switch ( tf->trapno )
		{
			case T_IRQ0 + IRQ_TIMER:

				...

			case T_IRQ0 + IRQ_IDE:

				...

			case T_IRQ0 + IRQ_KBD:

				...

			case T_IRQ0 + IRQ_COM1:

				...

			case T_IRQ0 + 7:
			case T_IRQ0 + IRQ_SPURIOUS:

				...

			default:

				if ( myproc() == 0 || ( tf->cs & 3 ) == 0 )
				{
					// In kernel, it must be our mistake.
					cprintf(

						"unexpected trap %d from cpu %d eip %x ( cr2=0x%x )\n",
						tf->trapno, cpuid(), tf->eip, rcr2()
					);

					panic( "trap" );
				}

				// In user space, assume process misbehaved.
				cprintf(

					"pid %d %s: trap %d err %d on cpu %d\n"
					"eip: 0x%x addr: 0x%x --kill proc\n",
					myproc()->pid, myproc()->name,
					tf->trapno, tf->err, cpuid(),
					tf->eip, rcr2()
				);

				myproc()->killed = 1;
		}


System calls

	. User calls to system calls generate traps
	. See "usys.S":

		.globl fork
		fork:
			movl $SYS_fork, %eax
			int  $T_SYSCALL
			ret

		.globl exit
		exit:
			movl $SYS_exit, %eax
			int  $T_SYSCALL
			ret

		...


	. For traps, 'trap' invokes 'syscall'
	. syscall loads the system call number from the trap frame,
	  which contains the saved %eax
	. syscall then indexes into the system call table
	  and invokes the appropriate entry

		void syscall ( void )
		{
			int          num;
			struct proc *curproc = myproc();

			num = curproc->tf->eax;

			curproc->tf->eax = syscalls[ num ]();

			...
		}


	. syscall record the return value of the system call function
	  in %eax
	. When the trap returns to user space, it will load the
	  values from curproc->tf into the machine registers.
	. Thus when exec returns, it will return the value that
	  the system call handler returned
	. Convention for syscall return values:
		. negative numbers for errors
		. positive numbers for succcess


	~~~ Finding syscall arguments ~~~

	. Helper functions 'argint', 'argptr', 'argstr', and
	  'argfd' retrieve the n'th system call argument as either
	  an integer, pointer, a string, or a file descriptor

	. argint uses the user-space %esp register to locate the
	  n'th argument
	. %esp points at the return address
	. The arguments are right above it at %esp + 4
	. Thus the n'th argument is at ( %esp + 4 ) + 4 * n

		int argint ( int n, int *iptr )
		{
			return fetchint( ( myproc()->tf->esp ) + 4 + ( 4 * n ), iptr );
		}


	. argint calls 'fetchint' to read the balue at that
	  address from user memory and write it to "*iptr"
	. fetchint can simply cast the address to a pointer
	  because the user and kernel share the same page table.
	  However, the kernel must verify that the address lies
	  within the user part of the adderess space.

		int fetchint ( uint addr, int *ip )
		{
			struct proc *curproc = myproc();

			if ( addr >= curproc->sz || addr + 4 > curproc->sz )
			{
				return - 1;
			}

			*ip = *( int* )( addr );

			return 0;
		}


	. argptr fetches the nth system call argument and checks
	  that this argument is a valid user-space pointer
	. argstr interprets the nth argument as a pointer.
	. argfd uses argint to retrieve a file descriptor number,
	  checks if it is a valid file descriptor, and returns the
	  corresponding "struct file"

	. The system call implementations (sysproc.c and sysfile.c)
	  are typically wrappers.
	. They decode the arguments using the helper functions, and
	  then call the real implementations


Interrupts

	. Let's look at the timer device and timer interrupts.
	. We would like the timer to generate an interrupt say
	  100 times per second

	. Early computers had a simple programmable interrupt
	  controller (PIC)
	. With the advent of multiprocessor PC boards, a new way of
	  handling interrupts was needed...
	. This new approach consists of two parts:
		. IOAPIC     - (ioapic.c) attached to the IO system...
		. local APIC - (lapic.c)  attached to each processor...
	. Xv6 is designed for a board with multiple processors. It
	  ignores interrupts from the PIC, and instead configures the
	  IOAPIC and LAPIC

	. The IOAPIC has a table and the processor can program entries
	  in the table through memory-mapped IO
	. During initializtion, 'ioapicinit':
		. disables all interrupts, and
		. maps interrupt 0 to IRQ0 and so on

		void ioapicinit ( void )
		{
			...

			for ( i = 0; i <= maxintr; i += 1 )
			{
				ioapicwrite( REG_TABLE + 2 * i, INT_DISABLED | ( T_IRQ0 + i ) );

				...
			}
		}


	. Specific devices later enable particular interrupts and
	  specify to whch processor the interrupt should be routed to
	. For example, Xv6 routes keyboard interrupts to cpu0,
	  and disk interrupts to the highest numbered processor
	  on the system

		/// console.c ///

		void consoleinit ( void )
		{
			...
			ioapicenable( IRQ_KBD, 0 );
		}


		/// ide.c ///

		void ideinit ( void )
		{
			...
			ioapicenable( IRQ_IDE, ncpu - 1 );
			...
		}


	. The timer chip is inside the LAPIC so that each processor
	  can receive timer interrupts independently...
	. Xv6 sets it up in 'lapicinit'
	. It tells the LAPIC to periodically generate an interrupt
	  at IRQ_TIMER

		lapicw( TIMER, PERIODIC | ( T_IRQ0 + IRQ_TIMER ) );

	. The time interrupts through vector 32
		. T_IRQ0 + IRQ_TIMER
		  32     + 0

	. When 'trap' is called for a time interrupt, it does
	  two things:
		. increment the ticks variable
		. calls 'wakeup'??
		  wakeup may cause the interrupt to return into a
		  different process

		case T_IRQ0 + IRQ_TIMER:

			...

			ticks += 1;

			wakeup( &ticks );

			...


	. Note the only difference between vector 32 and
	  vector 64 (for system calls) is that vector 32 is an
	  interrupt gate instead of a trap gate.
	. Interrupt gates disable interrupts while handling the
	  current interrupt, while traps do not.


Drivers

	. A driver is the code in an OS that manages a particular device.
	. It tells the device hardware to perform operations,
	  configures the device to generate interrupts when done,
	  and handles the resulting interrupts

	. Driver code can be tricky to write because:
		. a driver executes concurrently with the device it manages
		. the driver must understand the device's interface
		  (e.g. which IO ports do what). The interface can be complex
		  and poorly documented


Disk driver

	. The disk driver copies data from and to the disk
	. Disk hardware traditionally presents the data on the disk as
	  a numbered sequence of 512-byte blocks (also called sectors)
	. The block size that an OS uses for its file system might be
	  different than the sector size that the disk uses
		. Xv6's block size is identical to the disk's

	. To represent a block, Xv6 has a "struct buf"
	. The data stored in this structure is often out of sync with the
	  disk.
	. It might not yet have been read in from disk, or it might
	  have been updated but not yet written out to disk
	. The disk driver must ensure that the rest of Xv6 does not get
	  confused when the structure is out of sync with the disk

		struct buf {

			int               flags;
			uint              dev;
			uint              blockno;
			struct sleeplock  lock;
			uint              refcnt;
			struct buf       *prev;    // LRU cache list
			struct buf       *next;
			struct buf       *qnext;   // disk queue
			uchar             data [ BSIZE ];
		};

		#define B_VALID 0x2  // buffer has been read from disk
		#define B_DIRTY 0x4  // buffer needs to be written to disk


	~~~ IDE device ~~~

	. IDE controller provides access to connected disks
	. Falling out of fashion in favour of SCSI and SATA

	. Xv6 represents fs blocks using "struct buf"
	. BSIZE is identical to the IDE's sector size, thus each buffer
	  represents the contents of one sector on a particular disk
	  device
	. buf->dev holds the device number
	. buf->data is an in-memorry copy of the disk sector
	. buf->flag tracks the relationship between memory and disk:
		. B_VALID means data has been read in
		. B_DIRTY means data needs to be written out

	. The Xv6 disk driver can handle a BSIZE that is a
	  multiple of the device's sector size
	. OSes often use blocks bigger than 512 bytes


	~~~ ideinit ~~~

	. The kernel initializes the disk driver at boot time by
	  calling 'ideinit'
	. ideinit calls ioapicenable to enable the IDE_IRQ interrupt.
	. The interrupt is enabled only on the last CPU.

		ioapicenable( IRQ_IDE, ncpu - 1 );

		idewait( 0 );

	. Next, ideinit probes the disk hardware.
	. It begins by calling 'idewait' to wait for the disk to be
	  able to accept commands
	. A PC motherboard presents the status bits of the disk
	  hardware on IO port 0x1F7.
	. idewait polls the status bits until the busy bit (IDE_BSY)
	  is clear and the ready bit (IDE_DRDY) is set

		static int idewait ( int checkerr )
		{
			...

			while ( ( ( r = inb( 0x1f7 ) ) & ( IDE_BSY | IDE_DRDY ) ) != IDE_DRDY )
			{
				//
			}

			...
		}

	. Now that the disk controller is ready, ideinit can check
	  how many disks are present
	. It assumes disk 0 is present because the boot loader and
	  kernel were both loaded from there
	. It writes to IO port 0x1F6 to select disk 1, and then waits
	  a while for the status bit to show that the disk is ready.
	. If not, ideinit assumes the disk is absent

		outb( 0x1f6, 0xe0 | ( 1 << 4 ) );  // select disk 1

		for ( i = 0; i < 1000; i += 1 )
		{
			if ( inb( 0x1f7 ) != 0 )
			{
				havedisk1 = 1;

				break;
			}
		}


	~~~ iderw ~~~

	. After ideinit, the disk is not used again until the buffer
	  cache calls 'iderw'

		struct buf* bread ( uint dev, uint blockno )
		{
			...

			if ( ( b->flags & B_VALID ) == 0 )
			{
				iderw( b );
			}

			...
		}

		void bwrite ( struct buf *b )
		{
			...

			b->flags |= B_DIRTY;

			iderw( b );
		}

	. iderw writes the buffer to disk if the B_DIRTY flag is set, and
	  reads the buffer from disk if B_VALID is not set (clear)

	. Disk accesses typically take milliseconds, a long time for a
	  processor.
	. The boot loader uses pollling (busy waiting). This is fine
	  because there is nothing else to do.
	. In an OS however, it is more efficient to let another process
	  run and arrange to receive an interrupt when the disk operation
	  has completed
	. iderw keeps a list of pending disk requests, and uses interrupts
	  to find out when each request has finished
	. Although iderw maintans a queue of requests, the simple IDE
	  controller can handle only one operation at a time

	. iderw adds the buffer "b" to the end of the queue

		b->qnext = 0;

		for ( pp = &idequeue; *pp; pp = &( *pp )->qnext )
		{
			//
		}

		*pp = b;


	. If the buffer is at the front of the queue, iderw must send
	  it to the disk hardware by calling 'idestart'??
	. Otherwise the buffer will be started once the buffers ahead
	  of it are taken care of

		if ( idequeue == b )
		{
			idestart( b );
		}

	. idestart issues either a read or a write for the buffer's
	  device and sector, according to the flags
	. If the operation is a write, idestart must supply the
	  data now (using 'outsl') and the interrupt will signal
	  that the data has been written to disk
	. If the operation is a read, the interrupt will signal that
	  the data is ready, and the handler will read it into b

		static void idestart ( struct buf *b )
		{
			...

			outb( ... );

			...

			if ( b->flags & B_DIRTY )
			{
				outb( 0x1f7, write_cmd );
				outsl( 0x1f0, b->data, BSIZE / 4 );
			}
			else
			{
				outb( 0x1f7, read_cmd );
			}
		}	

	. Having added the request to the queue and started it if
	  necessary?, iderw must wait for the result
	. iderw sleeps, waiting for the interrupt handler to record
	  in the buffer's flags that the operation is done
	. While the process is sleeping, Xv6 will schedule other
	  processes to keep the CPU busy

		while ( ( b->flags & ( B_VALID | B_DIRTY ) ) != B_VALID )
		{
			sleep( b, &idelock );
		}

	. Eventually, the disk will finish its operation and trigger
	  an interrupt.
	. trap will call 'ideintr' to handle it

		case T_IRQ0 + IRQ_IDE:

			ideintr();

			...


	. ideintr consults the first buffer in the queue to find out
	  which operation was happening
	. If the buffer was being read into and the disk controller
	  has data waiting, ideintr reads the data into the buffer
	  with 'insl'

		if ( ! ( b->flags & B_DIRTY ) && idewait( 1 ) >= 0 )
		{
			insl( 0x1f0, b->data, BSIZE / 4 );
		}

	. The buffer is now ready.
	. ideintr sets B_VALID and clears B_DIRTY, and
	  wakes up any? process waiting on the buffer?

		b->flags |= B_VALID;
		b->flags &= ~ B_DIRTY;

		wakeup( b );


	. Finally identr must pass the next waiting buffer to the disk

		idequeue = b->qnext;

		...

		if ( idequeue != 0 )
		{
			idestart( idequeue );
		}


---------------------------------------------------------------------------------------------
Locking
---------------------------------------------------------------------------------------------

Intro

	. Xv6 runs on multiprocessors
	. The CPUs share RAM, and Xv6 exploits this sharing to
	  maintain data structures that all CPUs read and write

	. Any code that accesses shred data concurrently must have
	  a strategy for maintaining correctness despite concurrency
	. Concurrency can arise from accesses by multiple cores,
	  multiple threads, or by interrupt code

	. Locking is one strategy used to handle concurrency
	. A lock provides mutual exclusion, ensuring that only one
	  CPU at a time can hold the lock


Race conditions

	. A race condition is s situation in which a memory location
	  is accessed concurrently, and at least one access is a write
	. Leads to:
		. lost update, or
		. a read of incompletely updated data

	. For example, unsecure

		struct list {

			int          data;
			struct list *next;
		}

		struct list *list = 0;

		void insert ( int data )
		{
			struct list *l;

			l = malloc( sizeof *l );

			l->data = data;
			l->next = list;

			list = l;
		}

		. If two CPUs execute "insert" at the same time, ...

	. For example, secure

		struct list {

			int          data;
			struct list *next;
		}

		struct list *list = 0;
		struct lock  listlock;

		void insert ( int data )
		{
			struct list *l;

			acquire( &listlock );

			l = malloc( sizeof *l );

			l->data = data;
			l->next = list;

			list = l;

			release( &listlock );
		}

	. The sequence of instructions between 'acquire' and
	  'release' is often called a "critical section"
	. A lock ensures that only one CPU at a time can
	  operate on the data structure? in the critical section  


Locks

	. Xv6 has two types of locks: spin-locks and sleep-locks

	. Xv6 represents a spin-lock as a "struct spinlock"

		struct spinlock {

			uint        locked;      // Is the lock held?

			// For debugging:
			char       *name;        // Name of lock
			struct cpu *cpu;         // The cpu holding the lock
			uint        pcs [ 10 ];  // The call stack (an array of program counters)
			                         // that locked the lock
		};

	. spinlock->locked is:
		. zero when the lock is available
		. non-zero when it is held


	~~~ acquire ~~~

	. One would think that Xv6 should acquire a lock as follows:

		void acquire ( struct spinlock *lk )
		{
			for ( ;; )  // spin/loop until acquire lock
			{
				if ( ! lk->locked )
				{
					lk->locked = 1;

					break;
				}
			}
		}

	. However, this approach does not guarantee mutual exclusion
	. It could happen that two CPUs simultaneously reach the
	  line "if ( ! lk->locked )" and both seeing the condition
	  as true, each grab the lock by executing "lk->locked = 1"
	. At this point, two different CPUs hold the lock

	. To avoid this situation, we want the two actions
	  "if ( ! lk->locked )" and "lk->locked = 1", to be executed
	  at the same time as one step
	. To accomplish this, Xv6 relies on the x86 "xchg" instruction
	. xchg swaps a word in memory with the contents of a register
	. acquire repeats xchg in a loop:
		. each iteration simulataneously reads lk->locked and
		  sets its value to 1
		. if the lock is already held, lk-locked will already
		  be 1, so the xchg returns 1 and the loop continues
		. if the lock is not held, xchg returns 0 and the
		  loop breaks

		/// spinlock.c ///

		void acquire ( struct spinlock *lk )
		{
			...

			while( xchg( &lk->locked, 1 ) != 0 )
			{
				//
			}

			...
		}


		/// x86.h ///

		static inline uint xchg ( volatile uint *addr, uint newval )
		{
			uint result;

			// The + in "+m" denotes a read-modify-write operand.
			asm volatile(

				"lock; xchgl %0, %1" :
				"+m" ( *addr ), "=a" ( result ) :
				"1" ( newval ) :
				"cc"
			);

			return result;
		}

	. Once the lock is acquired, acquire records for debugging
	  the CPU and the stack trace that acquired the lock.
	. If a process forgets to release a lock, this information
	  can help identify the culprit
	. These debugging fields are protected by the lock? and
	  must only be edited while holding the lock

		lk->cpu = mycpu();

		getcallerpcs( &lk, lk->pcs );


	~~~ release ~~~

	. 'release' is the opposite of acquire:
		. it clears the debugging fields, and
		. releases the lock
	. It too uses an assembly instruction to clear locked,
	  because clearing this field should be atomic (one instruction)

		void release ( struct spinlock *lk )
		{
			...

			lk->pcs[ 0 ] = 0;
			lk->cpu      = 0;

			...

			// Release the lock, equivalent to lk->locked = 0
			asm volatile( "movl $0, %0" : "+m" ( lk->locked ) :  );

			...
		}


	~~~ ... ~~~

	. Xv6's implementation of spin-locks is x86-specific.


Using locks

	. In the disk driver, CPUs can add new requests to the
	  queue concurrently
	. To protect the list, iderw acquires 'idelock' and
	  releases it at the end of the function

		static struct spinlock idelock;

		void ideintr ( void )
		{
			acquire( &idelock );

			...

			release( &idelock );
		}

	. A hard part of using locks is deciding how many locks to use
	  and which data each lock protects
	. It is important for efficiency not to lock too much as
	  locks reduce parallelism

	. Xv6 uses the following locks:

		. buf's b->lock (buf.h)
			. serializes operations on each block buffer

		. bcache.lock (bio.c)
			. protects allocation of block buffer cache entries

		. cons.lock (console.c)
			. serializes access to console hardware,
			  avoids intermixed output

		. ftable.lock (file.c)
			. serializes allocation of a struct file in file table

		. icache.lock (fs.c)
			. protects allocation of inode cache entries

		. inode's ip->lock (file.h)
			. serializes operations on each inode and its content

		. idelock (ide.c)
			. serializes access to disk hardware and disk queue

		. kmem.lock (kalloc.c)
			. serializes allocation of memory

		. log.lock (log.c)
			. serializes operations on the transaction log

		. pipe's p->lock (pipe.c)
			. serializes operations on each pipe

		. ptable.lock (proc.c)
			. serializes context switching, and operations
			  on proc->state and proctable

		. tickslock (trap.c)
			. serializes operations on the ticks counter


Deadlock and lock ordering

	. If a code path through the kernel must hold several
	  locks at the same time, it is important that all code
	  paths acquire the locks in the same order to avoid deadlock
	. For example:
		. suppose a thread_1 executes one code path and
	      acquires lock_a
	    . suppose a thread_2 executs another code path and
	      acquires lock_b
	    . thread_1 then tries to acquire lock_b. It cannot because
	      thread_2 holds it
	    . thread_2 won't release lock_b because it is waiting
	      to acquire lock_a...
	    . Both acquires will block indefinitely because each
	      thread holds the lock needed by the other, but won't
	      release it until its acquire returns
	    . This can be avoided if both threads acquire the locks
	      in the same order

	. The need for a global lock acquisition order means that
	  callers must invoke functions in a way that causes locks
	  to be acquired in the agreed-on order

	. For example, creating a file requires simulataneously holding:
		. a lock on the directory,
		. a lock on the new file's inode,
		. a lock on a disk block buffer,
		. idelock,
		. and ptable->lock
	. To avoid deadlock, file system code always acquires locks in
	  the above order...


Interrupt handlers

	. Xv6 uses spinlocks to protect data that is used by both
	  interrupt handles and threads.
	. For example, a timer interrupt might increment 'ticks' at
	  the same time that a kernel thread reads ticks in 'sys_sleep'.
	. The lock 'tickslock' serializes the two accesses.

		/// trap.c ///

		case T_IRQ0 + IRQ_TIMER:

			acquire( &tickslock );

			ticks += 1;

			...

			release( &tickslock );


		/// sysproc.c ///

		int sys_sleep ( void )
		{
			...

			acquire( &tickslock );

			ticks0 = ticks;

			...

			release( &tickslock );

			...
		}


	. Interrupts can cause deadlocks
	. For example,
		. suppose iderw holds the idelock and then gets
		  interrupted to run ideintr.
		. ideintr would try to acquire idelock, see it was held,
	      and wait for it to be released.
		. In this situation, idelock will never be released.
		  Only iderw can realease it, and it will not continue
		  until ideintr returns

	. To avoid this situation, if a spinlock is used by
	  an interrupt handler, a processor must never hold that
	  lock with interrupts enabled
	. However, interrupts can still occur on other CPUs???
	  An interrupt handler can wait for a thread on another
	  CPU to release a spinlock....???

	. Xv6 re-enables interrupts when a processor holds no spinlocks
	. It must do a little bookkeeping to cope with nested
	  critical sections
	. acquire calls 'pushcli' and release calls 'popcli'
	  to track the nesting level of locks on the current processor
	. When that count reaches zero, popcli restores the interrupt
	  enable state that existed at the start of the outermost
	  critical section

		void pushcli ( void )
		{
			...

			cli();

			// Save interrupt state at start of outermost
			if ( mycpu()->ncli == 0 )
			{
				mycpu()->intena = eflags & FL_IF;
			}

			mycpu()->ncli += 1;  // track depth of pushcli nesting
		}

		void popcli ( void )
		{
			...

			mycpu()->ncli -= 1;

			...

			// Reached outermost, so restore interrupt state
			if ( mycpu()->ncli == 0 && mycpu()->intena )
			{
				sti();
			}
		}


Instruction and memory ordering

	. This chapter has assumed that code executes in the order
	  in which it appears in the program
	. Many compilers and processors however, execute code out of
	  order to acheive higher performance
	. For example if an instruction takes many cycles to complete,
	  a CPU may want to issue the instruction early so
	  that it can overlap with other instructions

	. To tell the hardware and compiler not to perform such
	  re-orderings, Xv6 uses GCC's "__sync_synchronize()"


Sleep locks

	. Sometimes Xv6 needs to hold a lock for a long time
	. For example, the file system keeps a file locked while
	  reading and writing its content on the disk, and these
	  disk operations can take tens of milliseconds
	. Efficieny demands that the processor be yielded while
	  waiting so that other threads can use it
	. This means that Xv6 needs locks that work well when held
	  across context switches...

		struct sleeplock {

			uint            locked;  // Is the lock held?
			struct spinlock lk;      // spinlock protecting this sleep lock

			// For debugging:
			char           *name;    // Name of lock
			int             pid;     // Process holding lock
		};


	. Xv6 sleeplocks support yielding the processor during
	  their critical sections
	. This property poses a design challenge:
		. if thread_1 holds lock_a and has yielded the processor,
		  and thread_2 wishes to acquire lock_a,
		. we have to ensure that thread_1 can execute while
		  thread_2 is waiting??, so that thread_1 can realease
		  lock_a
		. thread_2 cannot use the spinlock acquire function
		  because it would spin with interrupts turned off,
		  which would prevent thread_1 from running???

	. sleeplock's variant of acquire - acquiresleep' - yields
	  the processor while waiting, but does not disable interrupts.
	. At a high level:
		. a sleeplock has "locked" field that is protected by a
		  spinlock
		. acquiresleep's call to 'sleep' atomically yields the
		  CPU and releases the spinlock
		. the result is that other threads can execute while
		  acquiresleep waits

		void acquiresleep ( struct sleeplock *lk )
		{
			acquire( &lk->lk );

			while ( lk->locked )
			{
				sleep( lk, &lk->lk );
			}

			lk->locked = 1;
			lk->pid    = myproc()->pid;

			release( &lk->lk );
		}

	. Because sleeplocks leave interrupts enabled, they cannot
	  be used in interrupt handlers
	. Because acquiresleep may yield the processor, sleeplocks
	  cannot be used inside spinlock critical sections??

	. Xv6 uses spinlocks in most situations
	. It uses sleeplocks only in the file system where it is
	  convenient to be able to hold locks across lengthy disk
	  operations


Limitations of locks

	. Sometimes a function uses data which must be guarded by
	  a lock, but the function is called both from code that
	  already holds the lock and from code that wouldn't otherwise
	  need the lock

	. One way to handle this is to have two variants of the
	  function: one that acquires the lock, and one that expects
	  the calller to already hold the lock
	. For example "wakeup" acquires a needed lock, whereas
	  "wakeup1" expects the caller to hold the lock

	. Another approach is to require the caller to hold the
	  lock regardless of whether the caller needs it or not
	. For example "sched" expects ptable->lock to always be
	  held by its caller

	. A situation in which locks are insufficient is when one
	   thread needs to wait for another thread's update to a
	   data structure
	. For example,
	 	. when a pipe's reader waits for some other thread
	 	  to write the pipe...
	 	. the waiting thread (reader) cannot hold the lock
	 	  on the data, since this would prevent the update (write)
	 	  it is waiting for
	. Instead Xv6 provides a separate mechanism that jointly
	  manages the lock and event wait: see "sleep" and "wakeup"??


Real world

	~~~ Pthreads ~~~

	. Most OSs support POSIX threads (Pthreads) which allow a
	  user process to have several threads running concurrently
	  on different CPUs
	. Pthreads has support for user-level locks, barriers
	  (__sync_synchronize) etc.
	. Pthreads require support from the OS. For example:
		. it should be the case that if one Pthread blocks in
		  a system call?, another Pthread of the same process
		  should be able to run on that processor
		. if a Pthread changes its process's address space
		  (ex grow or shrink it), the kernel must arrange that
		  other CPUs that run threads of the same process
		  update their hardware page tables to reflect the
		  change in the address space.
		  On x86 this involves shooting dow the translation
		  look-aside buffer (TLB) of other CPUs using
		  inter-processor interrupts (IPIs)


	~~~ ... ~~~

	. Locks can be expensive in many CPUs try to acquire the
	  same lock at the same time
	. If one CPU has the lock cached in its local cache, and
	  another CPU must acquire the lock, then the atomic
	  instruction to update the cache line that holds the
	  lock must move the ... from one processor's cache to the
	  other processor's cache ... Fetching a cache line from
	  another process is expensive...


---------------------------------------------------------------------------------------------
Scheduling
---------------------------------------------------------------------------------------------

Intro

	. An OS is likely to run with more processes than the
	  computer has processors
	. A plan is needed to time-share the processors among
	  the processes
	. Ideally sharing would be transparent to user processes.
	  A common approach is to provide each process with the
	  illusion that it has its own virtual CPU by multiplexing
	  the processes onto ?


Multiplexing

	. Multiplexing creates the illusion that each process has
	  its own CPU
	. Xv6 multiplexes by switching each CPU from one process
	  to another in two situations:
		. 'sleep' and 'wakeup'
		. periodically when a process is executing user instructions

	. Implementing multiplexing poses a few challenges:
		. How to switch from one process to another
			. Xv6 uses the standard mechanism of context switching?
			. Although the idea is simple, the implementation is
			  not straightforward
		. How to do context switching transparently?
			. Xv6 uses the standard technique of using the timer
			  interrupt handler to drive context switches
		. Many CPUs may be switching amoung processes concurrently.
		  A locking plan is necessary to avoid races.
		. When a process has exited, its memory and other
		  resources must be freed, but it cannot do all of this
		  itself because (for example) it cannot free its own
		  kernel stack while still using it?
		. When a CPU switches from one process to another, it must
		  know which process it is running so that it can save its
		  state in the correct proc structure...

	. Xv6 must provide ways for processes to coordinate among
	  themselves
	. For example:
		. a parent process may neeed to wait for one of
	      its children to exit
	    . a process reading a pipe may need to wait for some
	      other process to write the pipe
	. Rather than making the waiting process waste CPU by
	  repeatedly checking whether the desired event has happened,
	  Xv6 allows a process to give up the CPU and sleep waiting
	  for an event.


Context switching

	. Steps involved in switching from one user processor to
	  another:
		1. user-kernel transition (system call or interrupt) to
		   the old process's kernel thread
		2. context switch to the local CPU's scheduler thread
		3. context switch to the new process's kernel thread
		4. a trap return to the user-level of the new process

	. For example:

		shell (user)
		|
		| ? save
		v
		shell (kernel)
		|
		| swtch
		v
		scheduler (kernel)
		|
		| swtch
		v
		cat (kernel)
		|
		| ? restore
		v
		cat (user)


	. Xv6 uses two context switches because the scheduler runs
	  on its own stack in order to simplify cleaning up the
	  user processes (as we will see when looking at 'exit'
	  and 'kill')

	. Every Xv6 process has its own kernel stack and register set
	. Each CPU has a separate scheduler thread for use when
	  it is executing the scheduler rather than using any
	  process's kernel thread
	. Switching from one thread to another involves:
		. saving the old thread's CPU registers, and
		. restoring the previously-saved registers of the new thread
	. The fact that %esp and %eip are saved and restored means
	  that the CPU will switch stacks and switch what code is
	  executing


	~~~ swtch ~~~

	. 'swtch' doesn't directly know about threads
	. It just saves and restores register sets, called contexts
	. When it is time for a process to give up the CPU,
	  the process's kernel thread calls swtch to save its own
	  context and  return to the scheduler context

	. Each context is represented by a "struct context*", a
	  pointer to a structure stored on the kernel stack involved

		struct context
		{
			uint edi;
			uint esi;
			uint ebx;
			uint ebp;
			uint eip;
		};

	. swtch takes two arguments:
		. "struct context **old"
		. "struct context *new"
	. It,
		. pushes the current CPU register onto the stack,
	  	. saves the stack pointer in *old,
	  	. then copies 'new' to %esp,
	  	. pops previously saved registers,
	  	. and returns


		# void swtch ( struct context **old, struct context *new );
		swtch:

			...

			# Save old callee-saved registers
			pushl  %ebp
			pushl  %ebx
			pushl  %esi
			pushl  %edi

			# Switch stacks
			movl   %esp, ( %eax )  # [old] = esp
			movl   %edx, %esp      # esp = new

			# Load new callee-saved registers
			popl   %edi
			popl   %esi
			popl   %ebx
			popl   %ebp

			ret


	. 'swtch' pushes (saves) register states (ebp, ebx, esi, edi)
	  creating a "struct context" on the current stack
	. %eip has already been saved on the stack by the caller
	. swtch saves %esp indirectly as the (struct context)
	  address pointed to by 'old'

		pushl ...

		movl %esp, ( %eax )  # [old] = esp

	. Having saved the old context, swtch moves to the new one
	. It moves the pointer to the new context into %esp
	. It pops the values from the (struct context in the) stack
	  of the new process onto registers (i.e. restores state)

		movl %edx, %esp  # esp = new

		popl ...

	. 'yield' calls 'sched' which calls 'swtch' to:
		. save the current context in proc->context, and
		. switch to the scheduler context previously saved
		  in cpu->scheduler
	. cpu->scheduler was saved by the call 'scheduler'
	  previously made to swtch


		void yield ( void )
		{
			myproc()->state = RUNNABLE;

			sched();

			...
		}

		void sched ( void )
		{
			...

			swtch( &p->context, mycpu()->scheduler );

			...
		}

		void scheduler ( void )
		{
			...

			swtch( &( c->scheduler ), p->context );

			...
		}

	. swtch returns on the scheduler's stack as though
	  scheduler's swtch had returned


Scheduling

	. A process that wants to give up the CPU must:
		. acquire the process table lock, ptable->lock
		. release any other locks it is holding
		. update its own state (proc->state)
		. then call 'sched'
	. 'yield, 'sleep', and 'exit' follow this convention

		void yield ( void )
		{
			acquire( &ptable.lock );

			myproc()->state = RUNNABLE;

			sched();

			release( &ptable.lock );
		}

		void sleep ( void *chan, struct spinlock *lk )
		{
			...

			if ( lk != &ptable.lock )
			{
				acquire( &ptable.lock );
				release( lk );
			}

			...

			p->state = SLEEPING;

			sched();

			...
		}

		void exit ( void )
		{
			...

			acquire( &ptable.lock );

			...

			curproc->state = ZOMBIE;

			sched();

			...
		}


	. sched double checks these conditions

		if ( ! holding( &ptable.lock ) )
		{
			panic( "sched ptable.lock" );
		}

		if ( mycpu()->ncli != 1 )
		{
			panic( "sched locks" );
		}

		if ( p->state == RUNNING )
		{
			panic( "sched running" );
		}

	. Since a lock is held, the CPU should be running with
	  interrupts disabled

		if ( readeflags() & FL_IF )
		{
			panic( "sched interruptible" );
		}

	. sched then calls swtch
	. swtch returns on the scheduler's stack as though
	  scheduler's swtch had returned
	. scheduler continues the for loop,
	  finds a process to run, switches to it, and the cycle repeats

		for ( ;; )
		{
			sti();

			acquire( &ptable.lock );

			for ( p = ptable.proc; p < &ptable.proc[ NPROC ]; p += 1 )
			{
				if ( p->state != RUNNABLE )
				{
					continue;
				}

				c->proc = p;

				switchuvm( p );

				p->state = RUNNING;

				swtch( &( c->scheduler ), p->context );

				switchkvm();

				c->proc = 0;
			}

			release( &ptable.lock );
		}

	. Something about why when using swtch, control of the
	  ptable->lock is passed to switched-to code...

	. A kernel thread always gives up its processor in sched,
	  and always switches to the same location in scheduler
	. scheduler then almost (almost) always switches to some
	  kernel thread that previously called swtch
	. sched and scheduler are said to be "co-routines" of each other

	. There is one case where scheduler's call to swtch does
	  not end up in sched
	. When a new process is first scheduled, it begins at forkret
	. forkret exists to release the ptable->lock. Otherwise, the
	  new process could start at trapret

	. scheduler runs a simple loop:
		. find a process to run
		. run it until it stops
		. repeat
	. It holds ptable->lock for most of its actions

	. It releases the lock (and explicitly) enables interrupts
	  once in each iteration of its outer loop
	. This is important for the special case in which the CPU
	  is idle (can find no RUNNABLE process)
	. If an idling scheduler looped with the lock continously
	  held, no other CPU that was running could ever,
		. perform a context switch
		. perform a process-related system call (see sysproc.c)
		. mark a process as RUNNABLE so as to break the idling
		  CPU out of its scheduling loop
	. Interrupts are periodically enabled on an idling CPU
	  because it might be the case that existing processes
	  are not RUNNABLE because they are waiting on IO

	. Something about invariants ptable->lock protects...
	. revisit...


mycpu and myproc

	. In many places in Xv6, a CPU? must identify which
	  process it is running
	. To accomplish this, Xv6 relies on hardware support
	. It maintains an array of "struct cpu"
	. Each entry contains per-CPU state such as
		. the currently running process
		. the CPU's hardware identifier (apicid)
	. When a CPU needs to find its state, it reads its
	  identifier from its local APIC and uses that identifier
	  to find its state in the array

		/// mp.c ///

		struct cpu cpus [ NCPU ];


		/// proc.h ///

		struct cpu
		{
			uchar             apicid;         // Local APIC ID
			struct context   *scheduler;      // swtch() here to enter scheduler
			struct taskstate  ts;             // Used by x86 to find stack for interrupt
			struct segdesc    gdt [ NSEGS ];  // x86 global descriptor table
			volatile uint     started;        // Has the CPU started?
			int               ncli;           // Depth of pushcli nesting.
			int               intena;         // Were interrupts enabled before pushcli?
			struct proc      *proc;           // The process running on this cpu or null
		};


	. The kernel uses 'mycpu' to find its apicid
	. mycpu in turn calls 'lapicid'
	. lapicid returns the hardware identifier for the CPU
	  and mycpu uses it to find its "struct cpu"


		/// proc.c ///

		struct cpu* mycpu ( void )
		{
			int apicid, i;

			...

			apicid = lapicid();

			for ( i = 0; i < ncpu; ++i )
			{
				if ( cpus[ i ].apicid == apicid )
				{
					return &cpus[ i ];
				}
			}

			...
		}


		/// lapic.c ///

		int lapicid ( void )
		{
			...

			return lapic[ ID ] >> 24;
		}


		/// mp.c ///

		void mpinit ( void )
		{
			struct mpconf   *conf;

			...

			conf = mpconfig( &mp )

			...

			lapic = ( uint* )conf->lapicaddr;

			...
		}


	. The kernel uses 'myproc' to find the "struct proc"
	  of the process that is running on the CPU
	. When a CPU switches to a new process in scheduler,
	  it sets c->proc to the new process's "struct proc"

		struct proc* myproc ( void )
		{
			...

			c = mycpu();
			p = c->proc;

			...
		}


sleep and wakeup

	. Scheduling and locks help conceal the existence of one
	  process from another, but so far we have no abstractions
	  that help processes intentionally interact
	. sleep and wakeup fill that void, allowing one process to
	  sleep waiting for an event and another process to wake it
	  up once that event has happened


	~~~ raison d'etre ~~~

	. For example, consider a simple producer/consumer queue.
	. The queue allows one process to send a nonzero pointer to
	  another process
	. If there was only one sender, one receiver, and they executed
	  on different CPUs, then the following implementation would
	  be correct:

		struct queue
		{
			void *ptr;
		}

		void* send ( struct queue *q, void *ptr )
		{
			// Loop until the queue is empty
			while ( q->ptr != 0 )
			{
				//
			}

			// Put ptr in queue
			q->ptr = ptr;
		}

		void* receive ( struct queue *q )
		{
			void *ptr;

			// Loop until the queue is not empty
			while ( q->ptr == 0 )
			{
				//
			}

			// Take ptr out of queue
			ptr = q->ptr;

			q->ptr = 0;

			return p;
		}

	. Even though both modify q->ptr, it works because send
	  only writes the pointer when it is zero, and receive when
	  it is non-zero, so no updates are lost

	. The implementation is expensive. If the sender rarely
	  sends, the receiver will spend most of its time spinning
	  in the while loop hoping for a pointer.
	. The receiver's CPU could be doing other useful work instead
	  of busy waiting
	. Avoiding busy waiting requires a way for the receiver to
	  yield the CPU and resume only when send delivers

	. _sleep( chan )
		. puts calling process to sleep, releasing CPU for other work
	. _wakeup( chan )
		. wakes all processes sleeping on chan, causing their sleep
		  calls to return

		void* send ( struct queue *q, void *ptr )
		{
			// Loop until the queue is empty
			while ( q->ptr != 0 )
			{
				//
			}

			// Put ptr in queue
			q->ptr = ptr;

			_wakeup( q );
		}

		void* receive ( struct queue *q )
		{
			void *ptr;

			// Loop until the queue is not empty
			while ( q->ptr == 0 )
			{
				_sleep( q );
			}

			// Take ptr out of queue
			ptr = q->ptr;

			q->ptr = 0;

			return p;
		}

	. receive now gives up the CPU instead of spinning
	. something about ... ?? deadlock

		struct queue
		{
			struct spinlock  lock;
			void            *ptr;
		}

		void* send ( struct queue *q, void *ptr )
		{
			acquire( &q->lock );

			// Loop until the queue is empty
			while ( q->ptr != 0 )
			{
				//
			}

			// Put ptr in queue
			q->ptr = ptr;

			_wakeup( q );

			release( &q->lock );
		}

		void* receive ( struct queue *q )
		{
			void *ptr;

			acquire( &q->lock );

			// Loop until the queue is not empty
			while ( q->ptr == 0 )
			{
				_sleep( q );
			}

			// Take ptr out of queue
			ptr = q->ptr;

			q->ptr = 0;

			release( &q->lock );

			return p;
		}

	. Incorrect because ghgjhgj
	. ghgjhgj

		struct queue
		{
			struct spinlock  lock;
			void            *ptr;
		}

		void* send ( struct queue *q, void *ptr )
		{
			acquire( &q->lock );

			// Loop until the queue is empty
			while ( q->ptr != 0 )
			{
				//
			}

			// Put ptr in queue
			q->ptr = ptr;

			_wakeup( q );

			release( &q->lock );
		}

		void* receive ( struct queue *q )
		{
			void *ptr;

			acquire( &q->lock );

			// Loop until the queue is not empty
			while ( q->ptr == 0 )
			{
				_sleep( q, &q->lock );
			}

			// Take ptr out of queue
			ptr = q->ptr;

			q->ptr = 0;

			release( &q->lock );

			return p;
		}

	. hkjhhk
	. revisit...


	~~~ Xv6 implementation ~~~

	. Basic idea:
		. sleep marks the current process as SLEEPING and then
		  calls sched to release the CPU
		. wakeup looks for a process sleeeping on the given ?
		  and marks it as RUNNABLE
		. callers of sleep and wakeup can use any mutually
		  convenient number as the ?
		  Xv6 often uses the address of a kernel data structure
		  involved in the waiting?

	. sleep begins with a few sanity checks:
		. there must be a current process
		. sleep must have been passed a lock

		struct proc *p = myproc();

		if ( p == 0 )
		{
			panic( "sleep" );
		}

		if ( lk == 0 )
		{
			panic( "sleep without lk" );
		}


	. sleep then acquires ptable->lock
	. Now the process going to sleep holds both ptable->lock and lk

		if ( lk != &ptable.lock )
		{
			acquire( &ptable.lock );
			release( lk );
		}

	. Because sleep now holds ptable->lock, it is safe to release lk
	. Some other process may start a call to wakeup(chan)
	  but wakeup will not run until it can acquire ptable->lock
	. This keeps wakeup from missing the sleep, because wakeup must
	  wait until sleep has finished putting the process to sleep

	. Now that sleep holds ptable->lock, it can put the process
	  to sleep by recording the sleep channel, changing the process
	  state, and calling sched

		p->chan  = chan;
		p->state = SLEEPING;

		sched();

	. At some point later, a process will call wakeup(chan)
	. wakeup acquires ptable->lock and calls wakeup1 which
	  does the real work

		void wakeup ( void *chan )
		{
			acquire( &ptable.lock );

			wakeup1( chan );

			release( &ptable.lock );
		}

	. wakeup1 is a separate function because sometimes the
	  scheduler needs to execute a wakeup when it already
	  holds ptable->lock
	. wakeup1 loops over the process table.
	. When it finds a process in state SLEEPING with a matching
	  'chan', it changes that process's state to RUNNABLE.
	. The next time the scheduler runs, it will see that the
	  process is ready to run.

		for ( p = ptable.proc; p < &ptable.proc[ NPROC ]; p += 1 )
		{
			if( p->state == SLEEPING && p->chan == chan )
			{
				p->state = RUNNABLE;
			}
		}

	. Xv6 always calls wakeup while holding the lock that guards
	  the sleep condition
	. gjhjtyfyfjg

	. gjhjtyfyfjg


Pipes

	. The queue shown earlier is a simple example
	. Xv6 has two queues that use sleep and wakeup to synchronize
	  readers and writers:
		. IDE driver
			. a process adds a disk request to a queue and then
			  calls sleep
			. the IDE interrupt handler uses wakeup to alert the
			  process that its request has completed
		. Pipes

	. Each pipe is represented by a "struct pipe", which contains
	  a lock and a data buffer
	. The fields 'nread' and 'nwrite' count the number of bytes
	  read from and written to the buffer

		struct pipe {

			struct spinlock lock;
			char            data [ PIPESIZE ];
			uint            nread;      // number of bytes read
			uint            nwrite;     // number of bytes written
			int             readopen;   // read fd is still open
			int             writeopen;  // write fd is still open
		};

	. The buffer wraps around: the next byte written after
	  [PIPESIZE - 1] is [0]
	. The counts do not wrap
	. This convention allows identifying:
		. a full buffer   (nwrite == nread + PIPESIZE)
		. an empty buffer (nwrite == nread)
	. Indexing into the buffer must use [nread % PIPESIZE] instead of
	  just [nread]. Ditto nwrite


	~~~ piperead and pipewrite ~~~

	. Suppose 'pipwrite' and 'piperead' are running simultaneously on
	  two different CPUs
	. pipewrite begins by acquiring a pipe's lock, which protects
	  its counts, data, and associated invariants
	. piperead then tries to acquire the lock too, but cannot.
	  It spins in 'acquire' waiting for the lock

	. While piperead waits, pipewrite loops over the bytes being
	  written, adding each to the pipe in turn
	. During this loop, it could happen that the buffer fills.
	. In this case, pipewrite calls wakeup to alert any sleeping
	  readers to the fact that there is data waiting in the buffer
	. piperead then sleeps on &p->nwrite to wait for a reader to
	  take some bytes our of the buffer
	. sleep releases p->lock as part of putting pipewrite's process
	  to sleep

		for ( i = 0; i < n; i += 1 )
		{
			// If buffer is full, wait for bytes to be read off it
			while ( p->nwrite == p->nread + PIPESIZE )
			{
				// ...
				if ( p->readopen == 0 || myproc()->killed )
				{
					release( &p->lock );

					return - 1;
				}

				// Alert any sleeping readers that there is data waiting to be read
				wakeup( &p->nread );

				// Sleep, waiting for a reader to take some bytes off the buffer
				sleep( &p->nwrite, &p->lock );
			}

			// Otherwise, write byte to buffer
			p->data[ p->nwrite % PIPESIZE ] = addr[ i ];

			p->nwrite += 1;
		}

		// Alert any sleeping readers that there is data waiting to be read
		wakeup( &p->nread );

		release( &p->lock );


	. Now that p->lock is available, piperead manages to acquire it
	  and enters its critical section.
	. It finds that the buffer is not empty (p->nread != p->nwrite) as
	  pipewrite went to sleep because the buffer was full
	. piperead thus falls through to the for loop,
	  copies data out of the pipe,
	  and increments nread by the number of bytes copied

		// Otherwise, read bytes from buffer
		for ( i = 0; i < n; i += 1 )
		{
			if ( p->nread == p->nwrite )
			{
				break;
			}

			addr[ i ] = p->data[ p->nread % PIPESIZE ];

			p->nread += 1;
		}

	. The number of bytes read are now available for writing, so
	  piperead calls wakeup to wake any sleeping writers, before
	  it returns to its caller
	. wakeup finds a process sleeping on &p->write, the process
	  that was running pipewrite but stopped when the buffer filled.

		// Alert any sleeping writers that some bytes in the buffer have been freed
		wakeup( &p->nwrite );

		release( &p->lock );


	. The pipe code uses separate sleep channels for reader and
	  writer (p->nread, p->nwrite)
	. This might make the system more efficient in the unlikely event
	  that there are lots of readers and writers waiting on the same
	  pipe...
	. The pipe code sleeps inside a loop checking the sleep condition
	. If there are multipler readers or writers, only the first
	  process to wake up will see the condition is no longer true.
	  The rest will continue to sleep?


wait, exit, and kill


	. sleep and wakeup can be used for many kinds of waiting
	. One example is the 'wait' system call that a parent process
	  uses to wait for a child to exit


	~~~ exit ~~~

	. exit acquires ptable->lock and then wakes up any process
	  sleeping on a wait channel equal to the current process's
	  parent proc...

		/// exit /// 

		acquire( &ptable.lock );

		// Parent might be sleeping in wait()
		wakeup1( curproc->parent );


		/// wait /// 

		// Wait for children to exit
		sleep( curproc, &ptable.lock );


	. Something about above parent wakeup before changing child
	  state works cause lock still held...


	. Before exit reschedules, it reparents all of the exiting
	  process's children, passing them to initproc (the first user
	  process)...

		// Pass abandoned children to init.
		for ( p = ptable.proc; p < &ptable.proc[ NPROC ]; p += 1 )
		{
			if ( p->parent == curproc )
			{
				p->parent = initproc;

				if ( p->state == ZOMBIE )
				{
					wakeup1( initproc );
				}
			}
		}


	. init waits on the abandoned children, so that every child
	  has a parent to clean up after it

		while ( ( wpid = wait() ) >= 0 && wpid != pid )
		{
			printf( 1, "zombie!\n" );
		}


	. When a process exits, it does not die immediately.
	. Instead, it changes the process state to ZOMBIE until its
	  parent calls 'wait' to learn of the exit
	. The parent is then responsible for freeing the memory
	  associated with the process and preparing the "struct proc"
	  for reuse

		curproc->state = ZOMBIE;


	. Finally, exit calls sched to relinquish the CPU

		sched();


	~~~ wait ~~~

	. wait begins by acquiring a ptable->lock
	. It then scans the process table looking for children
	. If wait finds the current process has children but that
	  none have exited, it calls sleep to wait for one of them
	  to exit... and scans again

		for ( ;; )
		{
			// Scan through table looking for exited children.
			havekids = 0;

			for ( p = ptable.proc; p < &ptable.proc[ NPROC ]; p += 1 )
			{
				if ( p->parent != curproc )
				{
					continue;
				}

				havekids = 1;

				// Found one
				if ( p->state == ZOMBIE )
				{
					...
				}
			}

			// No point waiting if we don't have any children.
			if ( ! havekids || curproc->killed )
			{
				release( &ptable.lock );

				return - 1;
			}

			// Wait for children to exit. (See wakeup1 call in proc_exit.)
			sleep( curproc, &ptable.lock );
		}


	. If wait finds a child that has exited, it:
		. records the child's pid,
		. then cleans up the child's "struct proc", freeing
		  the memory associated with the process

		if ( p->state == ZOMBIE )
		{
			pid = p->pid;

			kfree( p->kstack );

			p->kstack = 0;

			freevm( p->pgdir );

			p->pid       = 0;
			p->parent    = 0;
			p->name[ 0 ] = 0;
			p->killed    = 0;
			p->state     = UNUSED;

			release( &ptable.lock );

			return pid;
		}

	. Cleanup is done by the parent because p->kstack and p->pgdir
	  can only be freed when the child has finished running...


	~~~ kill ~~~

	. While exit allows a process to terminate itself, 'kill'
	  lets one process request that another be terminated
	. kill just:
		. sets the victim's p->killed
		. and if the victim is sleeping, wakes it up

		for ( p = ptable.proc; p < &ptable.proc[ NPROC ]; p += 1 )
		{
			if ( p->pid == pid )
			{
				p->killed = 1;

				// Wake process from sleep if necessary.
				if( p->state == SLEEPING )
				{
					p->state = RUNNABLE;
				}

				...
			}
		}


	. Eventually the victim will enter or leave the kernel
	  (for ex. via a system call or timer interrupt), at
	  which point code in trap will call exit if p->killed is set

		if ( myproc() && myproc()->killed && ( tf->cs & 3 ) == DPL_USER )
		{
			exit();
		}


	. If the victim process is in sleep, the call to wakeup?? will
	  cause the victim to return from sleep
	. This is potentially dangerous ...
	. Xv6 calls to sleep are always wrapped in a while loop that
	  re-tests the condition after sleep returns

	. fdsfd delay killing in thte middle of a multi-step...


Real world

	. Xv6 scheduler is round robin. Most OSs use priority

	. Preventing lost wakeups...

	. Scanning entire process list in 'wakeup' for processes with
	  a matching 'chan' is inefficient
	. A better solution is to replace 'chan' with a data structure
	  that holds a list of processes sleeping on that structure

	. Thundering herd...
	. 'signal/broadcast' condition for 'wakeup'... wakeup one or all
	  waiting on chan

	. Semaphores...


---------------------------------------------------------------------------------------------
File system
---------------------------------------------------------------------------------------------

Intro

	. A file system must address several challenges:
		. it needs on-disk data structures to:
			. represent the tree of named directories and files
			. record the identities of the blocks that hold each
			  file's content
			. record which areas of disk are free
		. it must support crash recovery.
		  If a crash occurs (ex. power failure), the fs must still
		  work correctly after a restart.
		  The risk is that a crash might interrupt a sequence of
		  updates and leave inconsistent on-disk data structure
		  (ex. a block that is both used in a file and marked free)
		. it must coordinate to maintain invariants as different
		  processes may operate on the fs at the same time.
		. it must maintain an in-memory cache of popular blocks as
		  accessing a disk is orders of magnitude slower than memory


Overview

	. The Xv6 file system implementation is organized in seven layers:

		file descriptor
		---------------
		pathname
		---------------
		directory
		---------------
		inode
		---------------
		logging
		---------------
		buffer cache
		---------------
		disk
		---------------

	. The disk layer reads and writes blocks on an IDE hard drive
	. The buffer cache layer:
		. caches disk blocks and,
		. synchronizes access to them, making sure that only one
		  kernel process at a time can modify the data stored in
		  any particular block
	. The logging layer:
		. allows higher layers to wrap updates to several blocks
		  in a "transaction", and
		. ensures that the blocks are updated atomically in the
		  face of crashes (i.e. all updated or none)
	. The inode layer provides indivdual files, each represented
	  as an inode with a unique i-number and some blocks holding
	  the file's data
	. The directory layer implements each directory as a special
	  kind of inode whose content is a sequence of directory
	  entries, each of which contains a file's name and i-number
	. The pathname layer provides hierarchical path names like
	  "/usr/foo/bar.c", and resolves them with recursive lookup
	. The file descriptor layer abstracts many Unix resources
	  (ex. pipes, devices, files) using the file system interface


	. The fs must have a plan for where it stores inodes and content
	  blocks on the disk.
	. To do so, Xv6 divides the disk into several sections:

		            ------------
		            data blocks
		block ? ->  ------------
		            bit map
		block ? ->  ------------
		            inode blocks
		block ? ->  ------------
		            log blocks
		block 2 ->  ------------
		            super block
		block 1 ->  ------------
		            boot block
		block 0 ->  ------------


	. The fs does not use block 0 as it holds the boot sector

	. Block 1 is called the "superblock"
	. It contains metadata about the filesystem such as:
		. the fs size in blocks
		. the number of data blocks
		. the number of inodes
		. the number of locks in the log?

		struct superblock
		{
			uint size;         // Size of file system image (blocks)
			uint nblocks;      // Number of data blocks
			uint ninodes;      // Number of inodes.
			uint nlog;         // Number of log blocks
			uint logstart;     // Block number of first log block
			uint inodestart;   // Block number of first inode block
			uint bmapstart;    // Block number of first free map block
		};

	. It is filled in by a serparate program ("mkfs.c"), which
	  builds the initial file system

	. Blocks starting at 2 hold the log

	. After the log are the inodes, with multiple inodes per block

	. After the inodes are the bitmap blocks which track which
	  data blocks are in use

	. The remaining blocks are data blocks.
	. Each is either marked free in the bitmap block, or holds
	  content for a file or directory


Buffer cache layer

	. The buffer cache has two jobs:
		. synchronize access to disk blocks to ensure that:
			. only one copy of a block is in memory
			. only one kernel thread at a time uses that copy
		. cache popular blocks so that they don't need to be
		  re-read from the slow disk

	. The main interface exported by the buffer cache consists
	  of 'bread' and 'bwrite'
	. bread obtains a 'buf' containing a copy of a block which
	  can be read and modified in memory
	. bwrite writes a modified buffer to the appropriate block
	  on the disk
	. A kernel thread must release a buffer by calling 'brelse'
	  when it is done with it

	. The buffer cache uses a per-buffer sleeplock (buf->lock) to
	  ensure that only one thread at a time uses each buffer (and
	  thus each disk block)
	. bread returns a locked buffer
	. brelse releases the lock

	. The buffer cache has a fixed number of buffers to hold disk blocks
	. This means that if the fs asks for a block that is not already
	  in cache, the buffer cache must recycle a buffer currently
	  holding some other block
	. The buffer cache recyles the least recently used (LRU) buffer
	  for the new block

	. The buffer cache is a doubly-linked list of buffers
	. 'binit' (called by main) initializes the list with the NBUF
	  buffers in the static array bcache->buf
	. All other access to the buffer cache refer to the linked list
	  via bcache->head, not the buf array...

		/// buf.h ///

		struct buf {

			int               flags;
			uint              dev;
			uint              blockno;
			struct sleeplock  lock;
			uint              refcnt;
			struct buf       *prev;    // LRU cache list
			struct buf       *next;    // MRU cache list
			struct buf       *qnext;   // disk queue
			uchar             data [ BSIZE ];
		};


		/// bio.c ///

		struct {

			struct spinlock lock;
			struct buf      buf [ NBUF ];
			struct buf      head;

		} bcache;


		void binit ( void )
		{
			struct buf *b;

			initlock( &bcache.lock, "bcache" );

			// Create linked list of buffers
			bcache.head.prev = &bcache.head;
			bcache.head.next = &bcache.head;

			for ( b = bcache.buf; b < bcache.buf + NBUF; b += 1 )
			{
				b->next = bcache.head.next;
				b->prev = &bcache.head;

				initsleeplock( &b->lock, "buffer" );

				bcache.head.next->prev = b;
				bcache.head.next       = b;
			}
		}


	. A buffer has two state bits associated with it:
		. B_VALID - indicates that the buffer contains a copy of
		            the block
		. B_DIRTY - indicates that the buffer content has been
		            modified and needs to be written to disk


	~~~ bread and bget ~~~

	. bread calls 'bget' to get a buffer for the given sector

		struct buf* bread ( uint dev, uint blockno )
		{
			struct buf *b;

			b = bget( dev, blockno );

			...
		}

	. bget scans the buffer list (MRU order) for a buffer with
	  the given device and sector numbers
	. If there is such a buffer, bget acquires the sleeplock
	  for the buffer and returns the locked buffer

		for ( b = bcache.head.next; b != &bcache.head; b = b->next )
		{
			if ( b->dev == dev && b->blockno == blockno )
			{
				b->refcnt += 1;

				release( &bcache.lock );

				acquiresleep( &b->lock );

				return b;
			}
		}


	. If there is no cached buffer for the given sector, bget must
	  make one
	. It scans the buffer list a second time (LRU order) looking for
	  a buffer that is not locked and not dirty
	. If found, bget edits the buffer metadata to record the new
	  device and sector number
	. It then acquires the buffer's sleeplock and returns the locked
	  buffer

		for ( b = bcache.head.prev; b != &bcache.head; b = b->prev )
		{
			if ( b->refcnt == 0 && ( b->flags & B_DIRTY ) == 0 )
			{
				b->dev     = dev;
				b->blockno = blockno;
				b->flags   = 0;
				b->refcnt  = 1;

				release( &bcache.lock );

				acquiresleep( &b->lock );

				return b;
			}
		}


	. Setting buf->flags to zero clears B_VALID, ensuring that
	  bread will read the block data from disk rather than
	  incorrectly using the buffer's previous contents

		if ( ( b->flags & B_VALID ) == 0 )
		{
			iderw( b );
		}


	. If all the buffers are busy, then too many processes are
	  simulataneously executing file system calls, so bget panics
	. A more graceful response might be to sleep until a buffer
	  becomes free, though there would then be a possibility of
	  deadlock

		panic( "bget: no buffers" );


	. A non-zero value for buf->refcnt prevents the buffer from
	  being re-used for a different disk block...
	. The sleeplock buf->lock protects reads and writes of the
	  block's buffered content...
	. The spinlock bcache->lock protects information about which
	  blocks are cached...


	~~~ bwrite ~~~

	. Once bread has read the disk (if needed) and returned the
	  buffer to its caller, the caller has exclusive use of the
	  buffer and can read or write the data bytes

	. If the caller modifies the buffer, it must call bwrite to
	  to write the changed data to disk before releasing the buffer
	. bwrite calls 'iderw' to talk to the disk hardware, after
	  setting B_DIRTY to indicate that iderw should write (rather
	  than read)

		void bwrite ( struct buf *b )
		{
			if ( ! holdingsleep( &b->lock ) )
			{
				panic( "bwrite" );
			}

			b->flags |= B_DIRTY;

			iderw( b );
		}


	~~~ brelse ~~~

	. When the caller is done with a buffer, it must call brelse
	  to release it
	. brelse releases buf->lock and moves the buffer to the
	  front of the linked list

		void brelse ( struct buf *b )
		{
			...

			releasesleep( &b->lock );

			acquire( &bcache.lock );

			b->refcnt -= 1;

			if ( b->refcnt == 0 )
			{
				// no one is waiting for it.
				b->next->prev = b->prev;
				b->prev->next = b->next;

				b->next = bcache.head.next;
				b->prev = &bcache.head;

				bcache.head.next->prev = b;
				bcache.head.next       = b;
			}

			release( &bcache.lock );
		}


	. Moving the buffer causes the list to be ordered by how
	  recently the buffers were used (released)
	. The first buffer in the list is the most recently used, and
	  the last is the least recently used
	. The two loops in bget take advantage of this:
		. The scan for an existing buffer must process the entire
	      list in the worst case, but checking the most recently
	      used (MRU) buffers first (start at head and follow next
	      pointers) will reduce scan time when there is locality of
	      reference
	    . The scan to pick a buffer to reuse picks the least
	      recently used (LRU) buffer by scanning backward (start at
	      tail and follow prev pointers)


Logging layer

	. One of the most interesting problems in fs design is crash recovery
	. The problem arises because many fs operations involve multiple
	  write to the disk, and a crash after a subset of the writes
	  may leave the on-disk file system in an incosistent state

	. For example, suppose a crash occurs during file truncation
	  (setting the length of a file to zero and freeing its content
	  blocks)
	. Depending on the order of the disk writes, the crash may leave:
		. an inode with a reference to a content block that is
		  marked free
		. an allocated but unreferenced content block

	. An inode that referes to a freed block is likely to cause
	  serious problems after a reboot.
	. The kernel might allocate that block to another file, and
	  now we have tow different files unintentionally pointing to
	  the same block
	. If Xv6 supported multiple users, this situation could also be
	  a security problem

	. Xv6 solves the problem of crashes during fs operations with
	  a simple form of logging
	. An Xv6 system call does not directly write the on-disk fs
	  data structures.
	. Instead:
		. It places a description of all the disk writes it
	      wishes to make in a log on the disk
		. Once it has logged all of its writes, it writes a
	      special commit record to the disk indicating that
	      the log contains a complete operation
		. It now copies the writes to the on-disk fs data structures
		. After those writes have completed, it erases the log on disk

	. If the system should crash and reboot, the fs code recovers
	  from the crash as follows, before running any processes:
		. If the log is marked as containing a complete operation,
		  then the recovery code copies the writes where they
		  belong in the on-disk fs.
		. If the log is not marked as containing a complete operation,
		  then the recovery code ignores the log
		. The recovery code finishes by erasing the log

	. Why does this approach solve the problem of crashes?
	. If the crash occurs before the operation commits, then:
		. the log on disk will not be marked as complete
		. no writes are made to disk
		. the recovery code ignores the log
	. If the crash occurs after the operation commits, then:
		. the recovery will replay all of the operation's writes,
		  perhaps repeating them if the operation had started to
		  write them to the on-disk data structure
	. With this approach, either all of the operation's writes appear
	  on the disk or none of them


	~~~ log header ~~~

	. The log resides in a known fixed location, specified in the
	  superblock (sb->logstart)

		struct log
		{
			struct spinlock  lock;
			int              start;
			int              size;
			int              outstanding;  // how many FS sys calls are executing.
			int              committing;   // in commit(), please wait.
			int              dev;
			struct logheader lh;
		};

		void initlog ( int dev )
		{
			...

			readsb( dev, &sb );

			log.start = sb.logstart;
			log.size  = sb.nlog;
			log.dev   = dev;

			...
		}

	. It consists of a header block, followed by a sequence of
	  updated block copies ("logged blocks") ??

	. The header block contains an array of sector numbers,
	  one for each of the logged blocks ??
	. The header block also contains the count of logged blocks

		struct logheader
		{
			int n;                  // n logged blocks
			int block [ LOGSIZE ];  // ?
		};


	. Xv6 writes the header block when a transaction commits... ??
	. It sets the count to zero after copying the logged blocks
	  to the fs
	. Thus a crash midway through a transaction will result in a
	  count of zero in the log's header block ???
	. And a crash after a commit will result in a non-zero count ???


	~~~ group commits ~~~

	. Each system call's code indicates the start and end of the
	  sequence of writes that must be atomic with respect to crashes...

	. To allow concurrent execution of fs operations by different
	  processes, the logging system can accumulate the writes of
	  multiple system calls into one transaction...
	. Thus a single commit may involve the writes of multiple
	  complete system calls

	. To avoid splitting a system call across transactions, the
	  logging system only commits when no fs calls are underway... ??

	. The idea of committing several transactions together is known
	  as a group commit
	. Group commits reduce the number of disk operations because...
	. They also hand the disk more concurrent writes, allowing the
	  disk to write them all during a single rotation... ?
	. Xv6's IDE driver doesn't support this kind of batching, but
	  the file system design does


	~~~ log space ~~~

	. Xv6 dedicates a fixed amount of space on the disk to hold
	  the log
	. The total number of blocks written by system calls in a
	  transaction must fit in that space.

		#define MAXOPBLOCKS 10                   // max # of blocks any FS op writes
		#define LOGSIZE     ( MAXOPBLOCKS * 3 )  // max data blocks in on-disk log


	. This has two consequences:
		. The logging system cannot allow a system call to start
		  unless it is certain that the system call's writes will
		  fit in the space remaining in the log
		. No single system call can be allowed to write more
		  distinct blocks than there is space in the log

	. 'write' and 'unlink' can potentially write more blocks
	  than ...
	. A large file write may write many data and bitmap blocks,
	  as well as an inode block...
	. Unlinking a large file might write many bitmap blocks and
	  an inode block...  
	. Xv6's write system call breaks up large writes into
	  multiple smaller writes that fit into the log
	. Xv6's unlink system call doesn't cause problems because Xv6
	  only uses one bitmap block


	~~~ ... ~~~

	. A typical use of the log in a system call looks like this:

		begin_op();

		...

		bp = bread( ... );

		bp->data[ ... ] = ...;

		log_write( bp );

		...

		end_op();


	~~~ log_write ~~~

	. 'log_write' acts as a proxy for bwrite ??
	. It records the block's sector number in memory, reserving it
	  a slot in the log on disk ??

		log.lh.block[ i ] = b->blockno;

	. It also marks the buffer B_DIRTY to prevent the block cache
	  from evicting it
	. The block must stay in the cache until committed because
	  until then, the cached copy is the only record of the
	  modification

		b->flags |= B_DIRTY;  // prevent eviction


	. log_write notices when a block is written multiple times
	  during a single transaction?? and allocates that block
	  the same slot in the log
	. This optimization is often called absorption

	. It is common that for example, the disk block containing
	  inodes of several files is written several times within a
	  transaction
	. By absorbing several disk writes into one, the fs can save
	  log space and can achieve better performance because only
	  one copy of the disk block is written to disk

		for ( i = 0; i < log.lh.n; i += 1 )
		{
			if ( log.lh.block[ i ] == b->blockno )  // log absorbtion
			{
				break;
			}
		}

		log.lh.block[ i ] = b->blockno;

		if ( i == log.lh.n )
		{
			log.lh.n += 1;  // only if unique blockno
		}


	~~~ begin_op ~~~

	. 'begin_op' waits until:
		. the logging system is not currently committing and,
		. there is enough free log space to hold the writes from
		  this call and all currently executing system calls

		if ( log.committing )
		{
			sleep( &log, &log.lock );
		}
		else if ( log.lh.n + MAXOPBLOCKS * ( log.outstanding + 1 ) > LOGSIZE )
		{
			sleep( &log, &log.lock );
		}

	. log->outstanding counts the number of system calls
	. Incrementing log->outstanding:
		. reserves space ??
		. prevents a commit from occuring during this system call ??
	. The code is conservative, and assumes that each system call
	  might write up to MAXOPBLOCKS distinct blocks

		else
		{
			log.outstanding += 1;

			release( &log.lock );

			break;
		}


	~~~ end_op ~~~

	. 'end_op' first decrements log->outstanding
	. If log->outstanding is now zero, it commits the current
	  transaction by calling 'commit' ??

		void end_op ( void )
		{
			int do_commit = 0;

			...

			log.outstanding -= 1;

			...

			if ( log.outstanding == 0 )
			{
				do_commit = 1;

				log.committing = 1;
			}
			else
			{
				...
			}

			...

			if ( do_commit )
			{
				commit();

				...

				log.committing = 0;

				...
			}
		}

	. hjkhj


	~~~ commit ~~~~

	. 'commit' has four stages:

		. write the modified blocks from cache to the log
			. via 'write_log'

		. write the log header to disk
			. via 'write_head'
			. This is the true point at which the current transaction
			  commits

		. write the modified blocks from the log to their intended
		  destination in the fs
			. via 'install_trans'

		. erase the transaction from the log
			. via clearing 'log.lh.n' and calling 'write_head' ??

		static void commit ()
		{
			if ( log.lh.n > 0 )
			{
				write_log();

				write_head();

				install_trans();

				log.lh.n = 0;

				write_head();
			}
		}


	~~~ write_log ~~~

	. write_log copies each modified block from its buffer cache ??
	  to the log

		static void write_log ( void )
		{
			int tail;

			for ( tail = 0; tail < log.lh.n; tail += 1 )
			{
				struct buf *from = bread( log.dev, log.lh.block[ tail ] );  // cache block
				struct buf *to   = bread( log.dev, log.start + tail + 1 );  // log block

				memmove( to->data, from->data, BSIZE );

				bwrite( to );  // write log to disk

				brelse( from );
				brelse( to );
			}
		}


	~~~ install_trans ~~~

	. install_trans reads each (committed) block from the log
	  and writes it to the proper place in the fs

		static void install_trans ( void )
		{
			int tail;

			for ( tail = 0; tail < log.lh.n; tail += 1 )
			{
				struct buf *from = bread( log.dev, log.start + tail + 1 );  // log block
				struct buf *to   = bread( log.dev, log.lh.block[ tail ] );  // dst

				memmove( to->data, from->data, BSIZE );  // copy log block to dst

				bwrite( to );  // write dst to disk

				brelse( from );
				brelse( to );
			}
		}


	~~~ write_head ~~~

	. write_head writes the in-memory log header to disk

	. This is the true point at which the current transaction commits
	. A crash after write_head will result in recovery replaying the
	  transaction's writes

		static void write_head ( void )
		{
			int i;

			struct buf *buf = bread( log.dev, log.start );

			struct logheader *lh = ( struct logheader * ) ( buf->data );

			lh->n = log.lh.n;

			for ( i = 0; i < log.lh.n; i += 1 )
			{
				lh->block[ i ] = log.lh.block[ i ];
			}

			bwrite( buf );  // write to disk

			brelse( buf );
		}


	~~~ read_head ~~~

	. read_head reads the in-disk log header to memory

		static void read_head ( void )
		{
			int i;

			struct buf *buf = bread( log.dev, log.start );

			struct logheader *lh = ( struct logheader * ) ( buf->data );

			log.lh.n = lh->n;

			for ( i = 0; i < log.lh.n; i += 1 )
			{
				log.lh.block[ i ] = lh->block[ i ];
			}

			brelse( buf );
		}


	~~~ recover_from_log ~~~

	. 'recover_from_log' is called from 'initlog'
	. initlog is called during boot before the first user process runs

		/// log.c ///

		void initlog ( int dev )
		{
			...

			recover_from_log();
		}


		/// proc.c ///

		void forkret ( void )
		{
			...

			if ( first )
			{
				...

				iinit( ROOTDEV );

				initlog( ROOTDEV );
			}
		}

	. recover_from_log reads the log header
	. If the header indicates that the log contains a committed
	  transaction (log.lh.n > 0), then its subsequent call to
	  install_trans copies the comitted blocks from the log to
	  the file system

		static void recover_from_log ( void )
		{
			read_head();

			install_trans();  // if committed, copy from log to disk

			log.lh.n = 0;

			write_head();     // clear the log
		}


	~~~ ... ~~~

	. An example use of logging occurs in 'filewrite'
	. The transaction looks like:

		int maxn = MAXOPBLOCKS ...
		int i    = 0;

		while ( i < n )
		{
			n1 = min( n - i, maxn );

			begin_op();

			ilock( f->ip );

			r = writei( f->ip, ..., n1 );

			iunlock( f->ip );

			end_op();

			i += r;
		}


	. The code is wrapped in a loop that breaks up large
	  writes into individual transactions of just a few sectors
	  at a time

	. The call to 'writei' writes many blocks as part of this
	  transaction:
		. the file's inode
		. one or more bitmap blocks
		. some data blocks


Block allocator

	. File and directory content is stored in disk blocks,
	  which must be allocated from a free pool ??

	. Xv6's block allocator maintains a free bitmap on disk,
	  with one bit per block
	. A zero indicates the corresponding block is free,
	  a one that it's in use

	. The program "mkfs.c" sets the bits correspoding to the:
		. boot sector
		. super block
		. log blocks
		. inode blocks
		. bitmap blocks

{{}}


	~~~ balloc ~~~

	. 'balloc' allocates a new disk block

	. The loop in balloc considers every block, starting at
	  zero up to sb->size (the number of blocks in the fs)
	. It looks for a block whose bitmap is zero (free)
	. If it finds such a block, it updates the bitmap (sets to one)
	  and returns the block

		/// param.h ///

		#define FSSIZE 1000  // size of file system in blocks


		/// fs.h ///

		// Bitmap bits per block
		#define BPB ( BSIZE * 8 )

		// Block of free map containing bit for block b
		// JK - Because FSSIZE is 1000 and BPB is 4096,
		//      this will always evaluate to 0 + sb.bmapstart
		//      i.e. one bitmap block
		#define BBLOCK( b, sb ) ( b / BPB + sb.bmapstart )


		/// fs.c ///

		static uint balloc ( uint dev )
		{
			...

			bp = 0;

			for ( b = 0; b < sb.size; b += BPB )  // for every block in the fs
			{
				bp = bread( dev, BBLOCK( b, sb ) );  // get the corresponding bitmap block

				for ( bidx = 0; bidx < BPB && ( b + bidx < sb.size ); bidx += 1 )  // for every bit in the bitmap block
				{
					bitmask = 1 << ( bidx % 8 );

					if ( ( bp->data[ bidx / 8 ] & bitmask ) == 0 )  // Is block free?
					{
						bp->data[ bidx / 8 ] |= bitmask;  // Mark block in use.

						log_write( bp );

						brelse( bp );

						bzero( dev, b + bidx );  // zero the block

						return b + bidx;
					}
				}

				brelse( bp );
			}

			...
		}


	~~~ bfree ~~~

	. 'bfree' frees a disk block

	. It finds the right bitmap block and clears the right bit

		static void bfree ( int dev, uint b )
		{
			...

			bp = bread( dev, BBLOCK( b, sb ) );

			bidx = b % BPB;

			bitmask = 1 << ( bidx % 8 );

			...

			bp->data[ bidx / 8 ] &= ~ bitmask;  // Mark block as free

			log_write( bp );

			brelse( bp );
		}


Inode layer

	. The term inode can have one of two related meanings:
		. the on-disk data strucutre containing a file's size and
		  list of data block numbers
		. an in-memory inode? which contains a copy of the on-disk
		  inode? as well as extra information needed within the kernel

	. The on-disk inodes are packed into a contiguous area of disk
	  called the inode blocks.
	. Every inode is the same size. As such, it is easy to find
	  the nth inode on the disk
	. This number 'n' is called the inode number or i-number

	. The on-disk inode is defined by a "struct dinode"

		struct dinode
		{
			short type;                   // File type
			short major;                  // Major device number (T_DEV only)
			short minor;                  // Minor device number (T_DEV only)
			short nlink;                  // Number of links to inode in file system
			uint  size;                   // Size of file (bytes)
			uint  addrs [ NDIRECT + 1 ];  // Data block addresses
		};

	. dinode->type
		. Distinguishes between files, directories, and
		  special files (devices)
		. A type of zero indicates that an on-disk inode is free...
	. dinode->nlink
		. Counts the number of directory entries that
		  refer to this inode
		. It is used to determine whether the dinode and its data
		  blocks should be freed
	. dinode->size
		. Records the number of bytes of content in the file
	. dinode->addrs
		. Array records the block numbers of the disk blocks
		  holding the file's contents

	. The kernel keeps the set of active inodes in memory
	. "struct inode" is the in-memory copy of a "struct dinode" that
	  is on-disk
	. The kernel stores an inode in memory only if there are
	  C pointers referring to that inode

		struct inode
		{
			uint             dev;    // Device number
			uint             inum;   // Inode number
			int              ref;    // Reference count
			struct sleeplock lock;   // protects everything below here
			int              valid;  // inode has been read from disk?

			// copy of disk inode
			short            type;
			short            major;
			short            minor;
			short            nlink;
			uint             size;
			uint             addrs [ NDIRECT + 1 ];
		};

	. inode->ref
		. Counts the number of C pointers referring to the
		  in-memory inode
		. The kernel discards the inode from memory if the count
		  drops to zero, and re-uses the cache entry for a different
		  inode

	. 'iget' and 'iput' functions acquire and release pointers to
	  an inode, modifying inode->ref count
	. Pointers to an inode can come from file descriptors, current
	  working directories, and transient kernel code such as exec ?

	. inode->lock ensures exclusive access to the inode's fields
	  and to the inode's file or directory content blocks

	. icache->lock protects the invariant that:
		. an inode is present in the cache at most once
		. a cached inode's ref counts the number of in-memory
		  pointers to the cached inode...

		struct {

			struct spinlock lock;
			struct inode    inode [ NINODE ];

		} icache;


	. The main job of the inode cache is synchronizing access by
	  multiple processes; caching is secondary
	. If an inode is used frequently, the buffer cache will
	  probably keep it in memory if it isn't kept by the inode cache ??
	. The inode cache is write-through, which means that code that
	  modifies a cached inode must immediately write it to disk with
	  'iupdate'


	~~~ iget ~~~

	. A "struct inode" pointer returned by iget is guaranteed to be
	  valid until the corresponding call to iput.
	. That is, the inode won't be deleted, and the memory referred
	  to by the pointer won't be re-used for a different inode

	. iget provides non-exclusive access to an inode, so that there
	  can be many pointers to the same inode
	. Many parts of the fs code depend on this behaviour, both to
		. hold long-term references to inodes (as open files and
		  directories)
		. prevent races while avoiding deadlock in code that
		  manipulates multiple inodes (such as pathname lookup) ??

	. The "struct inode" pointer returned by iget may not have
	  useful content
	. In order to ensure that it holds a copy of the on-disk inode,
	  code must call 'ilock'
	. ilock locks the inode and reads the inode from the disk, if
	  it has not already been read
	. 'iunlock' releases the lock
	. Separating acquisition of inode pointers from locking helps
	  avoid deadlock in some situations (ex. during directory lookup)
	. Multiple processes can hold a C pointer to an inode, but only
	  one process can lock the inode at a time...


	~~~ ialloc ~~~

	. 'ialloc' is used to allocate a new inode (ex. when creating
	  a file)
	. ialloc is similar to balloc
	. It loops over the inode structures on the disk, one block at
	  a time, looking for one that is marked free
	. When it finds one, it claims it by writing the new type to
	  the disk
	. It then returns an entry from the inode cache (via iget)

		/// fs.h ///

		// Inodes per block.
		#define IPB ( BSIZE / sizeof( struct dinode ) )

		// Block containing inode i
		#define IBLOCK( i, sb ) ( ( i ) / IPB + sb.inodestart )


		/// fs.c ///

		struct inode* ialloc ( uint dev, short type )
		{
			int            inum;
			struct buf    *bp;
			struct dinode *dip;

			for ( inum = 1; inum < sb.ninodes; inum += 1 )  // for each inode
			{
				bp = bread( dev, IBLOCK( inum, sb ) );

				dip = ( struct dinode* )bp->data + ( inum % IPB );

				// a free inode
				if ( dip->type == 0 )
				{  
					memset( dip, 0, sizeof( *dip ) );  // clear contents

					dip->type = type;

					log_write( bp );   // mark it allocated on the disk

					brelse( bp );

					return iget( dev, inum );  // return in-memory copy
				}

				brelse( bp );
			}

			...
		}

	. ialloc depends on the fact that only one process at a time
	  can be holding a reference to bp ...
	. The prevents another process from simultaneously seeing that
	  the inode is available and try to claim it...


	~~~ ilock ~~~

	. Code must lock the inode before reading or writing its 
	  metadata or content
	. ilock uses a sleeplock for this purpose
	. Once ilock has exclusive access to the inode, it reads the
	  inode from disk (more likely the buffer cache?) if needed

		void ilock ( struct inode *ip )
		{
			...

			acquiresleep( &ip->lock );

			if ( ip->valid == 0 )
			{
				bp = bread( ip->dev, IBLOCK( ip->inum, sb ) );

				dip = ( struct dinode* )bp->data + ( ip->inum % IPB );

				ip->type  = dip->type;
				ip->major = dip->major;
				ip->minor = dip->minor;
				ip->nlink = dip->nlink;
				ip->size  = dip->size;

				memmove( ip->addrs, dip->addrs, sizeof( ip->addrs ) );

				brelse( bp );

				ip->valid = 1;

				...
			}
		}


	~~~ iunlock ~~~

	. iunlock releases the inode's sleeplock
	. This may cause any processes sleeping on it to wakeup ??

		void iunlock ( struct inode *ip )
		{
			...

			releasesleep( &ip->lock );
		}


	~~~ iget ~~~

	. iget returns an in-memory copy of an on-disk inode
	. It looks through the inode cache for an active entry
	  (inode->ref > 0), which has the desired device and inode number
	. If it finds one, it returns a new reference to the inode

	. As it scans, it records the position of the first empty slot
	. If iget doesn't find a match, it uses the empty slot to
	  create a new cache entry

		static struct inode* iget ( uint dev, uint inum )
		{
			...

			empty = 0;

			// Is the inode already cached?
			for ( ip = &icache.inode[ 0 ]; ip < &icache.inode[ NINODE ]; ip += 1 )
			{
				if ( ip->ref > 0 && ip->dev == dev && ip->inum == inum )
				{
					ip->ref += 1;

					release( &icache.lock );

					return ip;
				}

				if ( empty == 0 && ip->ref == 0 )  // Remember empty slot.
				{
					empty = ip;
				}
			}

			// Recycle an inode cache entry.
			if ( empty == 0 )
			{
				panic( "iget: no inodes" );
			}

			ip = empty;

			ip->dev   = dev;
			ip->inum  = inum;
			ip->ref   = 1;
			ip->valid = 0;

			release( &icache.lock );

			return ip;
		}


	~~~ iput ~~~

	. iput releases a C pointer to an inode by decrementing the
	  reference count

	. If this is the last reference, the inode cache is now free
	  and can be re-used for a different inode

	. If iput sees no C pointer references to an inode, and that
	  the inode has no links to it, then the inode and its data
	  blocks must be freed on disk
	. iput calls 'itrunc' to truncate the file size to zero bytes,
	  freeing the data blocks
	. It then sets the inode type to 0 (unallocated)
	. Then writes the changes to disk with iupdate

		void iput ( struct inode *ip )
		{
			...

			if ( ip->valid && ip->nlink == 0 )
			{
				...

				int r = ip->ref;

				...

				// inode has no links and no other references: truncate and free.
				if ( r == 1 )
				{
					itrunc( ip );

					ip->type = 0;

					iupdate( ip );

					ip->valid = 0;
				}
			}

			...

			ip->ref -= 1;

			...
		}


	. Something about the locking protocol used when iput frees
	  an inode...
	. Something concurrent thread might be waiting in ilock to
	  use the inode iput is about to free ...
	. Something concurrent thread calling ialloc might choose
	  same inode about to free ...

	. Something about all system call that use the fs must be
	  wrapped in transactions...


	~~~ ... ~~~

	. A challenging interaction arises between iput and crashes
	. iput doesn't truncate a file immediately when the link
	  count for the file drops to zero because some process might
	  still hold a reference to it (ex. open file or is current
	  working directory)
	. If a crash happens before the last process closes the
	  file descriptor, then the file will be marked allocated on
	  disk but no directory entry (link) points to it
	. Two possible solutions follow

	. The simple solution is on recovery, after reboot, the fs
	  scans the whole fs for files that are marked allocated but
	  have no directory entry pointing to them
	. If such files exist, they are freed

	. Another solution that does not require scanning the entire
	  fs is as follows
	. The fs records on disk (ex. in the super block) the inode
	  number of a file whose link count drops to zero but whose
	  reference count is not zero
	. When the file's reference count reaches zero, the fs frees
	  it from disk as usual, but also removes the inode number
	  from wherever it was tracking it
	. On recovery, files still on the tracking list are freed

	. Xv6 implements neither solution
	. Over time, it runs the risk of running out of disk space,
	  as inodes on disk may be marked allocated even though they
	  are not in use anymore


Inode content

	. on-disk inode structure...

	. The inode's data is found in the blocks listed in the
	  dinode->addrs array

	. The first 6 KBytes (NDIRECT x BSIZE) of a file can be
	  loaded from blocks listed in the inode
	. While the next 64 KBytes (NINDIRECT x BSIZE) can only be
	  read after consulting the indirect block


		#define NDIRECT   12
		#define NINDIRECT ( BSIZE / sizeof( uint ) )


		         -->  ------------
		        |     type
		        |     ------------
		        |     major
		        |     ------------
		        |     minor
		 dinode |     ------------
		        |     nlink
		        |     ------------
		        |     size
		        |     ------------  <--      <-----
		        |     address 1        |           |
		        |     ------------     |           |
		        |     ...              | direct    |
		        |     ------------     | blocks    | addrs
		        |     address 12       |           |
		        |     ------------  <--            |
		        |     indirect ptr                 |
		         -->  ------------  <--------------



		              ------------  <--
		              address 1        |
		              ------------     |
		              ...              | indirect blocks
		              ------------     |
		              address 128      |
		              ------------  <--


	. The function 'bmap' manages this representation so that
	  higher-level routines don't have to deal with it


	~~~ bmap ~~~

	. bmap returns the disk block number of the n'th data block
	  of the inode
	. If the inode does not have such a block yet, bmap allocates one

	. bmap begins by picking off the easy case: the first NDIRECT
	  blocks are listed in the inode itself

		if ( bn < NDIRECT )
		{
			if ( ( addr = ip->addrs[ bn ] ) == 0 )
			{
				addr = balloc( ip->dev );

				ip->addrs[ bn ] = addr;
			}

			return addr;
		}


	. If indirect, bmap reads the indirect block.
	. It then reads a block number from it

		bn -= NDIRECT;

		if ( bn < NINDIRECT )
		{
			// Load indirect block, allocating if necessary.
			if ( ( addr = ip->addrs[ NDIRECT ] ) == 0 )
			{
				addr = balloc( ip->dev );

				ip->addrs[ NDIRECT ] = addr;
			}

			bp = bread( ip->dev, addr );

			//
			a = ( uint* )bp->data;

			if ( ( addr = a[ bn ] ) == 0 )
			{
				addr = balloc( ip->dev );

				a[ bn ] = addr;

				log_write( bp );  // ??
			}

			brelse( bp );

			return addr;
		}


	. bmap allocates blocks as needed
	. An ip->addrs or indirect entry of zero indicates that no
	  block is allocated
	. As bmap encounters zeroes, it replaces them with fresh blocks
	  allocated on demand


	~~~ itrunc ~~~

	. itrunc frees a file's blocks, resetting the inode's size
	  to zero
	. It starts by freeig the direct blocks, then the ones listed
	  in the indirect block, and finally the indirect block itself

		static void itrunc ( struct inode *ip )
		{
			...

			// Free direct blocks
			for ( i = 0; i < NDIRECT; i += 1 )
			{
				if ( ip->addrs[ i ] )
				{
					bfree( ip->dev, ip->addrs[ i ] );

					ip->addrs[ i ] = 0;
				}
			}

			// Free blocks listed in indirect block
			if ( ip->addrs[ NDIRECT ] )
			{
				bp = bread( ip->dev, ip->addrs[ NDIRECT ] );

				a = ( uint* )bp->data;

				for ( j = 0; j < NINDIRECT; j += 1 ){

					if ( a[ j ] )
					{
						bfree( ip->dev, a[ j ] );
					}
				}

				brelse( bp );

				// Free the indirect block itself
				bfree( ip->dev, ip->addrs[ NDIRECT ] );

				ip->addrs[ NDIRECT ] = 0;
			}

			ip->size = 0;  // reset inode size

			iupdate( ip );
		}


	~~~ readi ~~~

	. 'readi' reads data from an inode

	. readi begins by checking for ip->type == T_DEV
	. This case handles special devices whose data does not
	  live in the file system

		if ( ip->type == T_DEV )
		{
			...

			return devsw[ ip->major ].read( ip, dst, n );
		}

	. readi then checks that the offset and count are
	  not beyond the end of the file
	. Reads that start beyond EOF return an error
	. Reads that start at? or cross beyond the EOF return fewer
	  bytes than requested

		// Read starts beyond EOF, or (n < 1)
		if ( off > ip->size || off + n < off )
		{
			return - 1;
		}

		// Read crosses EOF
		if ( off + n > ip->size )
		{
			n = ip->size - off;
		}

	. The main loop processes each block of the file, copying data
	  from the inode into dst

		for ( tot = 0; tot < n; tot += m )
		{
			bp = bread( ip->dev, bmap( ip, off / BSIZE ) );

			m = min( n - tot, BSIZE - ( off % BSIZE ) );

			memmove( dst, bp->data + ( off % BSIZE ), m );

			brelse( bp );

			off += m;
			dst += m;
		}


	~~~ writei ~~~

	. 'writei' writes data to an inode

	. writei is almost identical to readi

	. A notable difference is that writes that start at or
	  cross the EOF *grow* the file up to the maximum file size
	. If the write has extended the file, writei must
	  update the file's size

		/// fs.h ///

		#define MAXFILE ( NDIRECT + NINDIRECT )


		/// fs.c ///

		// Write crossed EOF, update file size
		if ( n > 0 && off > ip->size )
		{
			ip->size = off;

			iupdate( ip );
		}


	~~~ stati ~~~

	. 'stati' copies an inode's metadata into a "struct stat"
	. It is exposed to user programs via the fstat system call

		/// stat.h ///

		struct stat
		{
			short type;   // Type of file
			int   dev;    // File system's disk device
			uint  ino;    // Inode number
			short nlink;  // Number of links to file
			uint  size;   // Size of file in bytes
		};

		/// fs.c ///
		void stati ( struct inode *ip, struct stat *st )
		{
			st->dev   = ip->dev;
			st->ino   = ip->inum;
			st->type  = ip->type;
			st->nlink = ip->nlink;
			st->size  = ip->size;
		}


Directory layer (TODO)

	. A directory is implemented internally much like a file ??

		struct file
		{
			enum {

				FD_NONE,
				FD_PIPE,
				FD_INODE

			} type;

			int           ref;       // reference count
			char          readable;
			char          writable;
			struct pipe  *pipe;
			struct inode *ip;
			uint          off;
		};

	. Its inode has type T_DIR whose data (inode->addrs) is a
	  sequence of directory entries (dirent) ??

		struct inode
		{
			uint             dev;    // Device number
			uint             inum;   // Inode number
			int              ref;    // Reference count
			struct sleeplock lock;   // protects everything below here
			int              valid;  // inode has been read from disk?

			// copy of disk inode
			short            type;
			short            major;
			short            minor;
			short            nlink;
			uint             size;
			uint             addrs [ NDIRECT + 1 ];
		};

	. Each entry is a "struct dirent" which contains a name and
	  an inode number

		struct dirent
		{
			ushort inum;
			char   name [ DIRNAMESZ ];
		};

	. The name is at most DIRNAMESZ (14) characters. If shorter,
	  it is terminated by a NULL (0) byte
	. Directory entries with an inode number of zero are free


	~~~ dirlookup ~~~

	. 'dirlookup' searches a directory for an entry with the
	  given name

	. If it finds one:
		. It sets "*poff" to the byte offset of the entry within
	      the directory in case the caller wishes to edit it
		. And returns a pointer to the corresponding unlocked
		  inode (via iget)

		for ( off = 0; off < dp->size; off += sizeof( de ) )
		{
			readi( dp, ( char* )&de, off, sizeof( de ) )

			...

			if ( de.inum == 0 )  // unallocated dirent
			{
				continue;
			}

			if ( namecmp( name, de.name ) == 0 )
			{
				if ( poff )
				{
					*poff = off;
				}

				inum = de.inum;

				return iget( dp->dev, inum );
			}
		}

	. Something about why caller is the one who holds the lock...


	~~~ dirlink ~~~

	. 'dirlink' writes a new directory entry with the given name
	  and inode number into the directory

	. If the name already exists, dirlink returns an error

		if ( ( ip = dirlookup( dp, name, 0 ) ) != 0 )
		{
			iput( ip );

			return - 1;
		}

	. The main loop reads directory entries looking for an
	  unallocated entry
	. When it finds one, it stops the loop early, with "off" set
	  to the offset of the available entry
	. Otherwise the loop ends with "off" set to dp->size ??
		. What is the implication of this?
		. writei will grow the file up to max file size...


		// Look for an empty dirent.
		for ( off = 0; off < dp->size; off += sizeof( de ) )
		{
			readi( dp, ( char* )&de, off, sizeof( de ) )

			...

			if ( de.inum == 0 )
			{
				break;
			}
		}

		// Write the new dirent
		strncpy( de.name, name, DIRNAMESZ );

		de.inum = inum;

		writei( dp, ( char* )&de, off, sizeof( de ) )

		...


Path names

	. Path name lookup involves a succession of call to dirlookup,
	  one for each path component

	. 'namei' evaluates "path" and returns the corresponding inode

	. 'nameiparent' is a variant of 'namei'.
	. It stops before the last element, returning the inode of
	  the parent directory, and copying the last element into "name"

		struct inode* namei ( char *path )
		{
			char name [ DIRNAMESZ ];

			return namex( path, 0, name );
		}

		struct inode* nameiparent( char *path, char *name )
		{
			return namex( path, 1, name );
		}


	. namei and nameiparent call 'namex' to do the real work


	~~~ namex ~~~

	. namex starts by deciding where the path evaluation begins.
	. If the path begins with a '/', evaluation begins at root.
	  Otherwise it begins at the current directory

		if ( *path == '/' )
		{
			ip = iget( ROOTDEV, ROOTINO );
		}
		else
		{
			ip = idup( myproc()->cwd );
		}

	. In the main loop:

		. namex uses 'skipelem' to consider each element of
		  the path in turn

		. If the call is nameiparent, the loop stops early
		. The final element has already been copied into "name",
		  so namex returns the unlocked inode (parent directory)

		. The next inode is retrieved by a call to dirlookup

	. When the loop runs out of path elements, namex
	  returns the final inode

		while ( ( path = skipelem( path, name ) ) != 0 )
		{
			if ( ip->type != T_DIR )
			{
				...

				return 0;
			}

			if ( nameiparent && *path == '\0' )
			{
				...

				return ip;
			}

			next = dirlookup( ip, name, 0 );

			...

			ip = next;
		}

		...

		return ip;


	. namex may take a long time to complete.
	. It could involve several disk operations to read inodes and
	  directory blocks for the directories traversed in the
	  pathname (if they are not in the buffer cache)
	. namex is designed so that if a call of namex in one kernel
	  thread is blocked on a disk IO, another kernel thread
	  looking up a different pathname can still proceed concurrently
	. namex accomplishes this by locking each directory in the path
	  separately...

	. This concurrency introduces some challenges
	. Something about locks...


File description layer

	. In Unix, most resources are represented as files
	. The file description layer is the layer that achieves this
	  uniformity

	. Xv6 gives each process its own table of open
	  files (file descriptors ?)
	. Each open file is represented by a "struct file",
	  which is a wrapper around either an inode or pipe, plus an
	  IO offset...

		struct file
		{
			enum {

				FD_NONE,
				FD_PIPE,
				FD_INODE

			} type;

			int           ref;       // reference count
			char          readable;
			char          writable;
			struct pipe  *pipe;
			struct inode *ip;
			uint          off;
		};

	. Each call to open creates a new open file (a new
	  "struct file")
	. If multiple processes open the same file independently,
	  the different instances will have different IO offsets ??

	. A single open file (the same "struct file") can:

		. appear multiple times in one process's file table 
			. This would happen if a process used 'open'
			  to open the file and then created aliases
			  using 'dup'

		. appear in the table of multiple processes
			. This would happen if it shared the file with a child
			  using 'fork'

	. A reference count file->ref tracks the number of references
	  to a particular open file

	. A file can be open for reading or writing or both.
	. file->readable and file->writeable track this


	~~~ ... ~~~

	. All the open files in the system are kept in a global
	  file table, ftable

		/// param.h ///

		#define NFILE 100  // open files per system


		/// file.c ///

		struct {

			struct spinlock lock;
			struct file     file [ NFILE ];

		} ftable;


	. The file table has a function to:
		. allocate a file (filealloc)
		. create a duplicate reference (filedup)
		. release a reference (fileclose)
		. read data (fileread)
		. write data (filewrite)


	~~~ filealloc ~~~~

	. 'filealloc' scans the file table for an unreferenced file
	  (file->ref == 0) and returns it if found

		struct file* filealloc ( void )
		{
			struct file *f;

			...

			for ( f = ftable.file; f < ftable.file + NFILE; f += 1 )
			{
				if ( f->ref == 0 )
				{
					f->ref = 1;

					release( &ftable.lock );

					return f;
				}
			}

			...

			return 0;
		}


	~~~ filedup ~~~~

	. 'filedup' increments the reference count

		struct file* filedup ( struct file *f )
		{
			...

			f->ref += 1;

			...
		}


	~~~ fileclose ~~~~

	. 'fileclose' decrements the reference count
	. When a file's reference count reaches zero, fileclose
	  releases the underlying pipe or inode

		void fileclose ( struct file *f )
		{
			struct file ff;

			...

			f->ref -= 1;

			if ( f->ref > 0 )
			{
				release( &ftable.lock );

				return;
			}

			ff = *f;

			f->ref  = 0;
			f->type = FD_NONE;

			...

			if ( ff.type == FD_PIPE )
			{
				pipeclose( ff.pipe, ff.writable );
			}
			else if ( ff.type == FD_INODE )
			{
				begin_op();

				iput( ff.ip );

				end_op();
			}
		}


	~~~ filestat ~~~~

	. 'filestat' returns the metadata of a file
	. filestat is only allowed on inodes and calls 'stati'

		int filestat ( struct file *f, struct stat *st )
		{
			if ( f->type == FD_INODE )
			{
				...

				stati( f->ip, st );

				...
			}

			return - 1;
		}


	~~~ fileread ~~~~

	. 'fileread' implements the read operation in files
	. fileread checks that the operation is allowed by the open mode
	. It then passes the call through to either the pipe or
	  inode implementation

	. If the file represents an inode, fileread uses the IO offset
	  as the offset for the operation then advances it
	. Pipes have no concept of offsets...

		int fileread ( struct file *f, char *addr, int n )
		{
			int r;

			if ( f->readable == 0 )
			{
				return - 1;
			}

			if ( f->type == FD_PIPE )
			{
				return piperead( f->pipe, addr, n );
			}

			if ( f->type == FD_INODE )
			{
				...

				if ( ( r = readi( f->ip, addr, f->off, n ) ) > 0 )
				{
					f->off += r;
				}

				...

				return r;
			}

			...
		}


	~~~ filewrite ~~~~

	. 'filewrite' implements the write operation in files
	. Implementation is almost identical to fileread
	. However, filewrite has logic that breaks down the
	  number of blocks written at a time. See earlier.

	. Inode locking has the convenient side effect that read
	  and write offsets are updated atomically, so that multiple
	  processes writing to the same file simultaneously cannot
	  overwrite each other's data


File system calls

	. With the functions that the lower layers provide, the
	  implementation of most file system calls (sysfile.c) is trivial
	. A few however, deserve a closer look

	~~~ sys_link ~~~~

	. 'sys_link' and 'sys_unlink' edit directories, creating or
	  removing references to inodes.

	. sys_link creates a new name for an existing inode

	. sys_link begins by fetching its arguments, strings "old" and "new"

		argstr( 0, &old )
		argstr( 1, &new )


	. If "old" exists and it is not a directory, sys_link increments
	  its inode->nlink count

		ip = namei( old )

		..

		if ( ip->type == T_DIR )
		{
			...

			return - 1;
		}

		ip->nlink += 1;

		iupdate( ip );


	. sys_link then calls nameiparent to find the parent directory
	  and final path element of "new"

		char name [ DIRNAMESZ ];

		...

		dp = nameiparent( new, name )


	. It then creates a new directory entry pointing at "old"'s inode
	. The new parent directory must exist and be on the same device
	  as the existing inode since inode numbers only have a unique
	  meaning on a single disk

		if ( dp->dev != ip->dev || dirlink( dp, name, ip->inum ) < 0 )
		{
			...

			goto bad;
		}


	. If an error occurs, after sys_link has incremented inode->nlink,
	  it must go back and decrement it

		bad:

			...

			ip->nlink -= 1;

			iupdate( ip );

			...

			return - 1;


	~~~ sys_unlink ~~~~

	. ...


	~~~ create ~~~~

	. While sys_link creates a new name for an *existing* inode,
	  'create' creates a new name for a *new* inode

	. It is a generalization of three file creation system calls:
		. open with the O_CREATE flag makes a new ordinary file
		. mkdir makes a new directory
		. mkdev makes a new device file

	. Like sys_link, create starts by calling nameiparent to get
	  the inode of the parent directory

	  	dp = nameiparent( path, name )


	. It then calls dirlookup to check whether the name already exists
	. If the name already exists, create's behaviour depends on which
	  system call it is being used for:

		. if on behalf of open (type == T_FILE),
			. If the name that exists is itself a regular file, 
			  it is treated as a success and create returns the inode
			. Otherwise it is treated an error
		. if on behalf of mkdir and mkdev
			. Treated as an error

		if ( ( ip = dirlookup( dp, name, &off ) ) != 0 )
		{
			...

			if ( type == T_FILE && ip->type == T_FILE )
			{
				return ip;
			}

			...

			return 0;
		}

	. If the name does not already exist, create allocates
	  a new inode with ialloc

		ip = ialloc( dp->dev, type )

		...

		ip->major = major;
		ip->minor = minor;
		ip->nlink = 1;

		iupdate( ip );


	. If the new inode is a directory, create initializes it with
	  '.' and '..' entries ??

		if ( type == T_DIR )
		{
			dp->nlink += 1;   // for ".."

			iupdate( dp );

			dirlink( ip, ".",  ip->inum )
			dirlink( ip, "..", dp->inum )

			...
		}


	. Finally, now that the data is initialized properly, create
	  can link the new inode into the parent directory

		dirlink( dp, name, ip->inum )

		...

		return ip;


	. With create, it is easy to implement 'sys_open', 'sys_mkdir',
	  and 'sys_mknod'


	~~~ sys_open ~~~

	. sys_open is complex, because creating a new file is only a
	  small part of what it can do...

	. If sys_open is passed the O_CREATE flag, it calls create.
	. Otherwise, it calls namei to open an existing inode

		if ( omode & O_CREATE )
		{
			ip = create( path, T_FILE, 0, 0 );

			...
		}
		else
		{
			ip = namei( path )

			...
		}


	. If an inode was obtained, sys_open allocates a file and a
	  file descriptor

		f = filealloc()

		fd = fdalloc( f )


	. It then fills in the file

		f->type     = FD_INODE;
		f->ip       = ip;
		f->off      = 0;
		f->readable = ! ( omode & O_WRONLY );
		f->writable = ( omode & O_WRONLY ) || ( omode & O_RDWR );

		return fd;


	~~~ sys_mkdir ~~~~

	. calls create with type T_DIR

		ip = create( path, T_DIR, 0, 0 )


	~~~ sys_mknod ~~~~

	. calls create with type T_DEV

		ip = create( path, T_DEV, major, minor )


	~~~ sys_pipe ~~~~

	. 'sys_pipe' connects the implementation of pipe to the
	  file system by providing a way to create a pipe pair ??

	. Its argument is a pointer to space for two integers, where
	  it will record the two new file descriptors

	. sys_pipe allocates the pipe and installs the file descriptors

		int sys_pipe ( void )
		{
			...

			pipealloc( &rf, &wf )

			...

			fd0 = fdalloc( rf )
			fd1 = fdalloc( wf )

			...

			fd[ 0 ] = fd0;
			fd[ 1 ] = fd1;

			...
		}


Real world

	. A more efficient LRU buffer cache would eliminate the
	  linked list, and instead use a hash table for lookups (
	  random access) and a heap (?) for LRU evictions

	. Xv6 logging system is inefficient:
		. A log commit cannot occur concurrently with
		  file system calls...
		. It logs entire blocks, even if only a few bytes in a
		  block are changed
		. It performs synchronous log writes, a block at a time

	. Assumes one disk per file system
	. For example fixed-size arrays of inode blocks


---------------------------------------------------------------------------------------------
The boot loader
---------------------------------------------------------------------------------------------

Intro

	. When a x86 PC boots, it starts executing a program called the BIOS
	  (Basic Input/Output System) which is stored in non-volatile memory
	  on the motherboard
	. The BIOS's job is to prepare the hardware and then transfer control
	  to the OS
	. Specifically, it transfers control to code loaded from the
	  *boot sector* - the first 512 byte sector of the boot disk...
	. The boot sector contains the *boot loader* - instructions that
	  load the kernel into memory

	. The BIOS loads the boot sector at memory address 0x7C00 and then
	  jumps (sets the CPU's instruction pointer) to that address

	. When the boot loader begins executing, the CPU is simulating
	  an Intel 8088
	. The loader's job is to:
		. put the processor in a more modern operating mode,
		. load the Xv6 kernel from disk into memory,
		. and then transfer control to the kernel

	. The Xv6 bootloader comprises two files:
		. "bootasm.S" - written in a combniation of 16bit and 32bit assembly
		. "bootmain.c"

Assembly bootstrap

	. The first instruction in the boot loader is "cli", which disables
	  processor interrupts
	. The BIOS is a tiny OS and it might have setup its own interrupt
	  handlers as part of initializing the hardware
	. When Xv6 is ready, it will re-enable interrupts

	. The processor is in real mode, and is simulating an Intel 8088


	~~~ Real mode addressing ~~~

	. In real mode there are eight 16bit general purpose registeres
	. Since the processor sends 20bits of address to memory,
	  16bit segment registers (cs, ds, es, ss) are used to provide
	  the additional bits
	. Which segment register is used is implied by the type of
	  memory reference:
		. cs - instruction fetches
		. ds - data read and write
		. ss - stack read and write
	. When a program refers to memory, the CPU automatically
	  adds 16 times the value of a segment ergister...
	  The generated address is called the "linear address"

	. Xv6 pretends that an x86 instruction uses a "virtual address"
	  for its memory operands?? but an instruction actually uses
	  a "logical address"??
	. A "logical address" consists of a segment selector and an
	  offset.
	. It is sometimes written as "segment:offset".
	  More often the segment is implicit, and the program only
	  directly manipulates the offset

	. The segmentation hardware transforms the "logical address"
	  into a "linear address"
	. If paging hardware is enabled, it translates linear addresses
	  into "physical addresses".
	  Otherwise the processor uses linear addresses as physical

	  ------------
	  CPU
	  ------------
	       |
	       |       <--- logical address
	       V
	  ------------
	  segmentation
	  hardware
	  ------------
	       |
	       |       <--- linear address
	       V
	  ------------
	  paging
	  hardware
	  ------------
	       |
	       |       <--- physical address
	       V
	  ------------
	  RAM
	  ------------

	. After cli, the next thing the boot loader does is set
	  the segment registers to zero (known state)

		xorw   %ax, %ax   # Set %ax to zero
		movw   %ax, %ds   # -> Data Segment
		movw   %ax, %es   # -> Extra Segment
		movw   %ax, %ss   # -> Stack Segment

	. The next step is some hack to compensate for the fact
	  that a virtual "segment:offset" can yield a 21bit
	  physical address, whereas the Intel 8088 can only address
	  20bits of memory

		seta20.1:
			...

		seta20.2:
			...


	~~~ Switching to protected mode ~~~

	. The next step is to switch to 32bit "protected mode"

	. In protected mode, a segment register is an index into a
	  "segment descriptor table"...
	. Each entry in the table specifies:
		. a base physical address,
	  	. a maximum virtual address called the limit,
	  	. and permission bits for the segment
	. These permissions are the protection in protected mode.
	  The kernel can use them to ensure that a program uses only
	  its own memory

		 ... | ...   | ...      
		-----|-------|------
		base | limit | flags
		-----|-------|------
		base | limit | flags
		-----|-------|------
		base | limit | flags
		--------------------

	. Xv6 makes no use of segments, and uses the paging hardware instead
	. The boot loader sets up the segment descriptor table "gdt"
	  so that all segments:
		. have a base address of zero,
		. and the maximum possible limit (4Gbytes)
	. The table has three entries:??
		. a null entry,
		. one for executable code,
		. one for data
	. The code segment descriptor has a flag set (STA_X) that indicates
	  the code should run in 32bit mode...

	. The boot loader executes an "lgdt" instruction to load
	  the processor's GDT register with the value "gdtdesc"
	  which points to table gdt...

	. Once it has loaded the GDT register, the boot loader
	  enables protected mode by setting the appropriate
	  bit (CR0_PE) in the control register (cr0).

		/// bootasm.S ///

		lgdt  gdtdesc

		movl  %cr0,    %eax
		orl   $CR0_PE, %eax
		movl  %eax,    %cr0

		gdt:

			SEG_NULLASM                                # null seg
			SEG_ASM( STA_X | STA_R, 0x0, 0xffffffff )  # code seg
			SEG_ASM( STA_W,         0x0, 0xffffffff )  # data seg

		gdtdesc:

			.word  ( gdtdesc - gdt - 1 )  # sizeof( gdt ) - 1
			.long  gdt                    # address gdt


		/// asm.h ///

		#define STA_X  0x8  // Executable segment
		#define STA_W  0x2  // Writeable (non-executable segments)
		#define STA_R  0x2  // Readable (executable segments)

		#define SEG_NULLASM   \
			.word 0, 0;       \
			.byte 0, 0, 0, 0

		#define SEG_ASM ( type, base, lim )               \
			.word ( ( ( lim ) >> 12 ) & 0xffff ),         \
			      ( ( base ) & 0xffff );                  \
			.byte ( ( ( base ) >> 16 ) & 0xff ),          \
			      ( 0x90 | ( type ) ),                    \
			      ( 0xC0 | ( ( ( lim ) >> 28 ) & 0xf ) ), \
			      ( ( ( base ) >> 24 ) & 0xff )


	. Setting CR0_PE does not immediately change how the processor
	  translates logical addresses to physical.
	. The change takes effect only when one loads a new value
	  into a segment register...
	  A hack to do this is the following snippet which
	  writes the cs register...

		ljmpl  $( SEG_KCODE << 3 ), $( start32 )

		start32:
			...


	~~~ 32bit mode ~~~

	. The boot loader's first action in 32bit mode is to
	  initialize the data segment register (?) with SEG_KDATA

		movw  $( SEG_KDATA << 3 ), %ax  # Our data segment selector
		movw  %ax, %ds                  # -> DS: Data Segment
		movw  %ax, %es                  # -> ES: Extra Segment
		movw  %ax, %ss                  # -> SS: Stack Segment
		movw  $0,  %ax                  # Zero segments not ready for use
		movw  %ax, %fs                  # -> FS
		movw  %ax, %gs                  # -> GS

	. The next step before executing C code is to set up a stack
	  in an unused region of memory.
	. The boot loader chooses 0x7C00 as the top of the stack.
	  The stack will grow down from here, towards 0x0000 and
	  away from the boot loader

		start:

			cli

			...
		
			movl $start, %esp

			call bootmain


	. Memory looks like this...

		0xFFFF_FFFF -> --------------
		               ?
		0x0040_0000 -> --------------
		               reserved for kernel (Xv6 expects to be loaded here)
		0x0010_0000 -> --------------
		               IO devices?
		0x000A_0000 -> --------------
		               ?
		0x0000_7E00 -> --------------
		               boot loader (512 bytes)
		0x0000_7C00 -> --------------
		               stack
		0x0000_0000 -> --------------


	. The boot loader then calls the C function "bootmain"
	  which will load and run the kernel

C bootstrap

	. bootmain expects to find a copy of the kernel executable
	  on the disk starting at the second sector?
	. The kernel is an ELF format binary
	. To get access to the ELF headers, bootmain loads
	  the first 4096 bytes of the binary.
	  It places the in memory copy at address 0x0001_0000

		// ?
		elf = ( struct elfhdr* )0x10000;  // scratch space

		// Read 1st page off disk
		readseg( ( uchar* )elf, 4096, 0 );


	. The next step is a quick check that the ELF is a binary
	  and not an unitialized disk

		if ( elf->magic != ELF_MAGIC )
		{
			return;  // let bootasm.S handle error
		}


	. Bootmain then loads the content after the ELF header
	  into the memory address specified in kernel.ld
	. And zeros the remainder of the segment...

	. The kernel has been compiled and linked so that it
	  expects to find itself at virtual addresses starting
	  at 0x8010_0000
	. This virtual address is configured in kernel.ld
	. Once the kernel starts executing, it will set up the
	  paging hardware to map virtual addresses starting
	  at 0x8010_0000 to physical addresses starting at
	  0x0010_0000
	. This physical address is configured in kernel.ld
	. The boot loader uses this physical address
	  as where to load the kernel into memory

		ph = elf + elf->phoff;  // get program header

		pa = ph->paddr;         // get physical address of segment...


	. The boot loader's final step is to call the kernel's
	  entry point - the instruction the kernel expects to
	  start executing.
	. For Xv6 this address is 0x0010_000C
	. By convention, the "_start" symbol specifies the ELF
	  entry point
	. For Xv6, this is defined in "entry.S"

		# objdump -f kernel

		kernel:           file format elf32-i386
		architecture:     i386
		flags 0x00000112: EXEC_P, HAS_SYMS, D_PAGED
		start address:    0x0010000c


		// bootmain.c //
		entry = ( void( * )( void ) )( elf->entry );

		entry();


JK Summary

	. Most of this is legacy bloat.
	. Nothing useful happens here apart from the following:
		. load kernel from disk to where it expects to be in memory (RAM),
		. and jump to _start (entry.S)



=============================================================================================
=============================================================================================


---------------------------------------------------------------------------------------------
Other
---------------------------------------------------------------------------------------------

x86 processor supports Xv6 via:

	. kernel and user mode
		. switch between two

		. priviledged instructions
		. detect when user mode trying to execute priviledged

	. page table
		. translate virtual addresses to physical...

		. 'ltr' instruction
		. 'lgdt' instruction

	. interrupt table
		. map interrupts to handlers

		. 'lidt' instruction


---------------------------------------------------------------------------------------------
Other2
---------------------------------------------------------------------------------------------

Makefile - ...

	fs.img -> mkfs -> mkfs.c
	                  fs.h
	                  ulib
	                  uprogs

	Xv6.img -> bootblock -> bootasm.S
	                        bootmain.c
	        -> kernel    -> objs
	                        entry.S
	                        entryother.S
	                        initcode.S


Makefile - ??

	. 'Ttext' linker flag sets start address of .text section.
	. Thus the following:

		bootblock: $(SRCDIR)bootasm.S $(SRCDIR)bootmain.c
			...
			$(LD) $(LDFLAGS) -Ttext 0x7C00 ...
			...

		entryother: $(SRCDIR)entryother.S
			...
			$(LD) $(LDFLAGS) -Ttext 0x7000 ...

		initcode: $(SRCDIR)initcode.S
			....
			$(LD) $(LDFLAGS) -Ttext 0 ...
			....

	. Becomes:

		bin/bootblock.o:

			Disassembly of section .text:

			00007c00 <start>:
			    7c00:       fa                      cli
			    7c01:       31 c0                   xor    %eax,%eax
			    7c03:       8e d8                   mov    %eax,%ds
			    7c05:       8e c0                   mov    %eax,%es
			    7c07:       8e d0                   mov    %eax,%ss

			00007c09 <seta20.1>:
			    7c09:       e4 64                   in     $0x64,%al
			    7c0b:       a8 02                   test   $0x2,%al
			    7c0d:       75 fa                   jne    7c09 <seta20.1>
			...

		bin/bootblockother.o:

			Disassembly of section .text:

			00007000 <start>:
			    7000:       fa                      cli
			    7001:       31 c0                   xor    %eax,%eax
			...

		bin/initcode.out:

			Disassembly of section .text:

			00000000 <start>:
			       0:   68 24 00 00 00              push   $0x24
			       5:   68 1c 00 00 00              push   $0x1c
			...

	. Which is useful for relocation??


Makefile - Creating the disk image

	. Allocates space of size 512 * 10,000 (count) bytes.
	  All the bytes are set to zero.
	. Copy "img/bootblock" to first sector
	. Copy "img/kernel" starting at second sector

		Xv6.img: bootblock kernel

			dd if=/dev/zero          of=$(IMGDIR)Xv6.img count=10000          # zero out 512*count bytes

			dd if=$(IMGDIR)bootblock of=$(IMGDIR)Xv6.img        conv=notrunc  # first sector (512 bytes)
			dd if=$(IMGDIR)kernel    of=$(IMGDIR)Xv6.img seek=1 conv=notrunc  # second sector


EFLAGS register

	. https://en.wikibooks.org/wiki/X86_Assembly/X86_Architecture

	 0 - carry flag
	 1 - x
	 2 - parity flag
	 3 - x
	 4 - adjust flag
	 5 - x
	 6 - zero flag
	 7 - sign flag
	 8 - trap flag
	 9 - interrupt flag
	10 - stream direction flag
	11 - overflow flag
	12 - IO privilege level (IOPL)
	13 - ''' 
	14 - nested task flag
	15 - x
	16 - resume flag
	17 - virtual 8086 mode
	18 - alignment check
	19 - virtual interrupt flag (VIF)
	20 - virtual interrupt pending flag
	21 - identification flag

Contorol registers

	. CRO

	 0 - protected mode enable
	 1 - ?
	 2 - x87 FPU present
	 3 - save x87 task context on task switch
	 4 - external math co-processor
	 5 - enable x87 error reporting
	16 - when set, CPU can't write to read-only pages when privilege level is 0
	18 - alignment mask
	29 - enable write-through caching
	30 - enable memory cache
	31 - enable paging

	. CR1 - reserved...

	. CR2 - page fault linear address
	        When a page fault occcurs, stores the address the program
	        attempted to access

	. CR3 - physical base address of page directory

	. CR4

		. https://en.wikipedia.org/wiki/Control_register
		. https://wiki.osdev.org/CPU_Registers_x86

	 0 - enable VIF in 8086 mode
	 1 - enable VIF in protected mode
	 2 - time stamp disable
	 3 - enable something debug IO
	 4 - page size extension (0 - page size is 4Kib, 1 - 4MiB)
	 5 - physical address extension (translate 32bit addresses into 36bit)
	 6 - blah
	 7 - blah
	 8 - blah
	 9 - blah
	10 - blah
	11 - blah
	12 - blah
	13 - blah
	14 - blah
	15 - x
	16 - blah
	17 - blah
	18 - blah
	19 - x
	20 - blah
	21 - blah
	22 - blah

